{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, ComplementNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import svm\n",
    "import random\n",
    "import math\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = pickle.load(open(\"pickles_data/graph_embedding_mapping.pkl\",'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_to_name = pickle.load(open(\"pickles_data/arnetids_to_papername.pkl\",\"rb\"))\n",
    "name_to_id = pickle.load(open(\"pickles_data/arnetids_to_papername.pkl\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = pickle.load(open(\"pickles_data/baseline_tags.pkl\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset = pickle.load(open(\"pickles_data/testset_for_graph.pkl\",\"rb\"))\n",
    "trainset = pickle.load(open(\"pickles_data/trainset_for_graph.pkl\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in trainset :\n",
    "    data['source_embed'] = mapping[data['acl_paper_arnetid']]\n",
    "    data['dest_embed'] = mapping[data['arnet_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in testset :\n",
    "    data['source_embed'] = mapping[data['acl_paper_arnetid']]\n",
    "    data['dest_embed'] = mapping[data['arnet_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_cue = pickle.load(open(\"pickles_data/weighted_cue_words.pkl\", \"rb\"))\n",
    "bert_embeddings = pickle.load(open(\"pickles_data/bert_embeddings_relu.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "location_feature = pickle.load(open(\"pickles_data/location_feature.pkl\",\"rb\"))\n",
    "title_overlap = pickle.load(open(\"pickles_data/title_overlap.pkl\",\"rb\"))\n",
    "context_count = pickle.load(open(\"pickles_data/context_count.pkl\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_table = pickle.load(open(\"pickles_data/num_table.pkl\",\"rb\"))\n",
    "popularity = pickle.load(open(\"pickles_data/popularity_sent.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_info = pickle.load(open(\"pickles/paper_info (1).pickle\", \"rb\"))\n",
    "fixed_context = pickle.load(open(\"pickles_data/fixed_context.pkl\",\"rb\"))\n",
    "author_feat = pickle.load(open(\"pickles/author_level.pickle\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20896\n",
      "23659\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "cbert = 0\n",
    "count_cc = 0\n",
    "train_set = []\n",
    "for data in trainset :\n",
    "    count+=1\n",
    "    paper = data['paper_name']\n",
    "    key = data['acl_paper_id']\n",
    "    if(key in bert_embeddings) :\n",
    "        for pap in bert_embeddings[key] :\n",
    "            if(pap['paper_name']==paper) :\n",
    "                cbert+=1\n",
    "                data['bert_embed'] = pap['embedding']\n",
    "\n",
    "        for pap in paper_info[key] :\n",
    "            if(pap['paper_name']==paper) :\n",
    "                try: \n",
    "                    data['citation_count'] = int(pap['citation'])\n",
    "                except :\n",
    "                    data['citation_count'] = 1\n",
    "                    count_cc += 1\n",
    "                try :\n",
    "                    data['venue_cit'] = int(pap['venue_cit'])\n",
    "                except :\n",
    "                    data['venue_cit'] = 20\n",
    "\n",
    "                info_found = 1\n",
    "                break\n",
    "\n",
    "\n",
    "        for pap in location_feature[key]:\n",
    "            if(pap['paper_name']==paper) :\n",
    "                data['location_feature'] = pap['location_feature']\n",
    "                break\n",
    "\n",
    "        for pap in author_feat[key] :\n",
    "            if(pap['paper_name']==paper) :\n",
    "                data['author_hindex'] = pap['hindex']\n",
    "                data['author_prod'] = pap['productivity']\n",
    "\n",
    "        for pap in num_table[key]:\n",
    "            if(pap['paper_name']==paper) :\n",
    "                data['num_table'] = pap['num_table']\n",
    "                break\n",
    "\n",
    "        for pap in title_overlap[key]:\n",
    "            if(pap['paper_name']==paper) :\n",
    "                data['title_overlap'] = pap['overlap']\n",
    "                break\n",
    "\n",
    "        for pap in popularity[key]:\n",
    "            if(pap['paper_name']==paper) :\n",
    "                data['popularity'] = pap['popularity']\n",
    "                break\n",
    "\n",
    "        for pap in context_count[key]:\n",
    "            if(pap['paper_name']==paper) :\n",
    "                data['context_count'] = pap['context_count']\n",
    "                break\n",
    "\n",
    "        for pap in weighted_cue[key]:\n",
    "            if(pap['paper_name']==paper) :\n",
    "                max_data = pap['cue_weights_max']\n",
    "                data['wcue_max'] = []\n",
    "                for key1 in max_data :\n",
    "                    data['wcue_max'].append(max_data[key1])\n",
    "                add_data = pap['cue_weights_add']\n",
    "                data['wcue_add'] = []\n",
    "                for key1 in add_data :\n",
    "                    data['wcue_add'].append(add_data[key1])\n",
    "                break\n",
    "\n",
    "\n",
    "        for pap in fixed_context[key]:\n",
    "            if(pap['paper_name']==paper) :\n",
    "                data['fixed_context'] = pap['fixed_context']    \n",
    "                \n",
    "        train_set.append(data)\n",
    "            \n",
    "    \n",
    "\n",
    "\n",
    "print(cbert)\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5185\n",
      "5915\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "cbert = 0\n",
    "count_cc = 0\n",
    "test_set = []\n",
    "for data in testset :\n",
    "    count+=1\n",
    "    paper = data['paper_name']\n",
    "    key = data['acl_paper_id']\n",
    "    if(key in bert_embeddings) :\n",
    "        for pap in bert_embeddings[key] :\n",
    "            if(pap['paper_name']==paper) :\n",
    "                cbert+=1\n",
    "                data['bert_embed'] = pap['embedding']\n",
    "\n",
    "        for pap in paper_info[key] :\n",
    "            if(pap['paper_name']==paper) :\n",
    "                try: \n",
    "                    data['citation_count'] = int(pap['citation'])\n",
    "                except :\n",
    "                    data['citation_count'] = 1\n",
    "                    count_cc += 1\n",
    "                try :\n",
    "                    data['venue_cit'] = int(pap['venue_cit'])\n",
    "                except :\n",
    "                    data['venue_cit'] = 20\n",
    "\n",
    "                info_found = 1\n",
    "                break\n",
    "\n",
    "\n",
    "        for pap in location_feature[key]:\n",
    "            if(pap['paper_name']==paper) :\n",
    "                data['location_feature'] = pap['location_feature']\n",
    "                break\n",
    "\n",
    "        for pap in author_feat[key] :\n",
    "            if(pap['paper_name']==paper) :\n",
    "                data['author_hindex'] = pap['hindex']\n",
    "                data['author_prod'] = pap['productivity']\n",
    "\n",
    "        for pap in num_table[key]:\n",
    "            if(pap['paper_name']==paper) :\n",
    "                data['num_table'] = pap['num_table']\n",
    "                break\n",
    "\n",
    "        for pap in title_overlap[key]:\n",
    "            if(pap['paper_name']==paper) :\n",
    "                data['title_overlap'] = pap['overlap']\n",
    "                break\n",
    "\n",
    "        for pap in popularity[key]:\n",
    "            if(pap['paper_name']==paper) :\n",
    "                data['popularity'] = pap['popularity']\n",
    "                break\n",
    "\n",
    "        for pap in context_count[key]:\n",
    "            if(pap['paper_name']==paper) :\n",
    "                data['context_count'] = pap['context_count']\n",
    "                break\n",
    "\n",
    "        for pap in weighted_cue[key]:\n",
    "            if(pap['paper_name']==paper) :\n",
    "                max_data = pap['cue_weights_max']\n",
    "                data['wcue_max'] = []\n",
    "                for key1 in max_data :\n",
    "                    data['wcue_max'].append(max_data[key1])\n",
    "                add_data = pap['cue_weights_add']\n",
    "                data['wcue_add'] = []\n",
    "                for key1 in add_data :\n",
    "                    data['wcue_add'].append(add_data[key1])\n",
    "                break\n",
    "\n",
    "\n",
    "        for pap in fixed_context[key]:\n",
    "            if(pap['paper_name']==paper) :\n",
    "                data['fixed_context'] = pap['fixed_context']    \n",
    "                \n",
    "        test_set.append(data)\n",
    "            \n",
    "    \n",
    "\n",
    "\n",
    "print(cbert)\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in train_set :\n",
    "    if(data['tag']==1) :\n",
    "        data['label']='baseline'\n",
    "    else :\n",
    "        data['label']='non_baseline'\n",
    "        \n",
    "for data in test_set :\n",
    "    if(data['tag']==1) :\n",
    "        data['label']='baseline'\n",
    "    else :\n",
    "        data['label'] = 'non_baseline'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in train_set :\n",
    "    data['dist'] = cosine_similarity(data['source_embed'].reshape(1,-1),data['dest_embed'].reshape(1,-1))[0][0]\n",
    "    \n",
    "for data in test_set :\n",
    "    data['dist'] = cosine_similarity(data['source_embed'].reshape(1,-1),data['dest_embed'].reshape(1,-1))[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.661919\n"
     ]
    }
   ],
   "source": [
    "for data in train_set :\n",
    "    print(data['dist'])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sanity_check(probs):\n",
    "\n",
    "\tsum = 0\n",
    "\tfor key, value in probs.items():\n",
    "\t\tsum+=value\n",
    "\tsum = round(sum, 7)\n",
    "\treturn sum==1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lm_model(trainset, testset):\n",
    "\n",
    "    word_baseline_frequency = {}\n",
    "    word_non_baseline_frequency = {}\n",
    "    baseline_length = 0\n",
    "    non_baseline_length = 0\n",
    "\n",
    "    for i in trainset:\n",
    "        # if len(i['fixed_context'])>1 and i['label']=='baseline':\n",
    "        # \tcontinue\n",
    "        for context in i['fixed_context']:\n",
    "            if i['label']=='baseline':\n",
    "                baseline_length+=len(context)\n",
    "            else:\n",
    "                non_baseline_length+=len(context)\n",
    "            for word in context:\n",
    "                if word not in word_baseline_frequency:\n",
    "                    word_baseline_frequency[word] = 0\n",
    "                    word_non_baseline_frequency[word] = 0\n",
    "                if i['label']=='baseline':\n",
    "                    word_baseline_frequency[word]+=1\n",
    "                else:\n",
    "                    word_non_baseline_frequency[word]+=1\n",
    "\n",
    "    final_word_baseline_frequency = {}\n",
    "    final_word_baseline_frequency['<unk>'] = 0\n",
    "    word_non_baseline_frequency['<unk>'] = 0\n",
    "\n",
    "    for word in word_baseline_frequency:\n",
    "        if word_baseline_frequency[word]>5:\t\n",
    "            final_word_baseline_frequency[word] = word_baseline_frequency[word]\n",
    "        else:\n",
    "            final_word_baseline_frequency['<unk>'] += word_baseline_frequency[word]\n",
    "            word_non_baseline_frequency['<unk>'] += word_non_baseline_frequency[word]\n",
    "            del word_non_baseline_frequency[word]\n",
    "\n",
    "    word_baseline_frequency = final_word_baseline_frequency\n",
    "\n",
    "    word_baseline_probability = {}\n",
    "    word_non_baseline_probability = {}\n",
    "\n",
    "    for word in word_baseline_frequency:\n",
    "        word_baseline_probability[word] = (word_baseline_frequency[word]+1)/(baseline_length+len(word_baseline_frequency))\n",
    "        word_non_baseline_probability[word] = (word_non_baseline_frequency[word]+1)/(non_baseline_length+len(word_non_baseline_frequency))\n",
    "\n",
    "    # print(word_baseline_probability['<unk>'])\n",
    "    # print(word_non_baseline_probability['<unk>'])\n",
    "\n",
    "    assert sanity_check(word_baseline_probability) and sanity_check(word_non_baseline_probability)\n",
    "\n",
    "    conf_mat1 = np.zeros((2,2))\n",
    "    conf_mat2 = np.zeros((2,2))\n",
    "\n",
    "    min_p = 1\n",
    "\n",
    "    for i in trainset+testset:\n",
    "        P_b = 0\n",
    "        P_nb = 0\n",
    "        maxP_b = 0\n",
    "        minP_nb = 1\n",
    "        n_better = 0\n",
    "        for context in i['fixed_context']:\n",
    "            \n",
    "            P_b_con = 1\n",
    "            P_nb_con = 1\n",
    "            for word in context:\n",
    "                if word not in word_baseline_probability:\n",
    "                    P_b_con*=word_baseline_probability['<unk>']\n",
    "                    P_nb_con*=word_non_baseline_probability['<unk>']\n",
    "                else:\n",
    "                    P_b_con*=word_baseline_probability[word]\n",
    "                    P_nb_con*=word_non_baseline_probability[word]\n",
    "            if P_b_con>P_nb_con:\n",
    "                n_better+=1\n",
    "            P_b+=P_b_con\n",
    "            P_nb+=P_nb_con\n",
    "            maxP_b = max(P_b, P_b_con)\n",
    "            minP_nb = min(P_nb, P_nb_con)\n",
    "        P_b/=len(i['fixed_context'])\n",
    "        P_nb/=len(i['fixed_context'])\n",
    "\n",
    "        # if P_b>P_nb:\n",
    "        # \tprint('yes')\n",
    "\n",
    "        # i['P_b'] = P_b\n",
    "        # i['P_nb'] = P_nb\n",
    "#         n_better = n_better/len(i['fixed_context'])\n",
    "        min_p = min(min_p, P_b, P_nb)\n",
    "#         i['lmp'] = [P_b, P_nb, n_better]\n",
    "        i['lmp'] = [P_b, P_nb, maxP_b, minP_nb, P_b/P_nb, maxP_b/minP_nb, n_better]\n",
    "\n",
    "    for i in trainset:\t\n",
    "        # if len(i['fixed_context'])>1 and i['label']=='baseline':\n",
    "        # \ttestset.append(i)\n",
    "        # \tcontinue\n",
    "        i['lmp'][0]/=min_p\n",
    "        i['lmp'][1]/=min_p\n",
    "        i['lmp'][2]/=min_p\n",
    "        i['lmp'][3]/=min_p\n",
    "        if i['lmp'][0]>i['lmp'][1]:\n",
    "            if i['label']=='baseline':\n",
    "                conf_mat1[0, 0]+=1\n",
    "            else:\n",
    "                conf_mat1[0, 1]+=1\n",
    "        else:\n",
    "            if i['label']=='baseline':\n",
    "                conf_mat1[1, 0]+=1\n",
    "            else:\n",
    "                conf_mat1[1, 1]+=1\n",
    "        if i['lmp'][2]>i['lmp'][3]:\n",
    "            if i['label']=='baseline':\n",
    "                conf_mat2[0, 0]+=1\n",
    "            else:\n",
    "                conf_mat2[0, 1]+=1\n",
    "        else:\n",
    "            if i['label']=='baseline':\n",
    "                conf_mat2[1, 0]+=1\n",
    "            else:\n",
    "                conf_mat2[1, 1]+=1\n",
    "\n",
    "    # print(conf_mat1)\n",
    "    prec = conf_mat1[0,0]/(conf_mat1[0,0]+conf_mat1[0,1])\n",
    "    rec = conf_mat1[0,0]/(conf_mat1[0,0]+conf_mat1[1,0])\n",
    "    print(prec, rec, 2*prec*rec/(prec+rec))\n",
    "    conf_mat1 = np.zeros((2,2))\n",
    "\n",
    "    # print(conf_mat2)\n",
    "    prec = conf_mat2[0,0]/(conf_mat2[0,0]+conf_mat2[0,1])\n",
    "    rec = conf_mat2[0,0]/(conf_mat2[0,0]+conf_mat2[1,0])\n",
    "    print(prec, rec, 2*prec*rec/(prec+rec))\n",
    "#     conf_mat2 = np.zeros((2,2))\n",
    "\n",
    "    for i in testset:\n",
    "        i['lmp'][0]/=min_p\n",
    "        i['lmp'][1]/=min_p\n",
    "        i['lmp'][2]/=min_p\n",
    "        i['lmp'][3]/=min_p\n",
    "        if i['lmp'][0]>i['lmp'][1]:\n",
    "            if i['label']=='baseline':\n",
    "                conf_mat1[0, 0]+=1\n",
    "            else:\n",
    "                conf_mat1[0, 1]+=1\n",
    "        else:\n",
    "            if i['label']=='baseline':\n",
    "                conf_mat1[1, 0]+=1\n",
    "            else:\n",
    "                conf_mat1[1, 1]+=1\n",
    "        if i['lmp'][2]>i['lmp'][3]:\n",
    "            if i['label']=='baseline':\n",
    "                conf_mat2[0, 0]+=1\n",
    "            else:\n",
    "                conf_mat2[0, 1]+=1\n",
    "        else:\n",
    "            if i['label']=='baseline':\n",
    "                conf_mat2[1, 0]+=1\n",
    "            else:\n",
    "                conf_mat2[1, 1]+=1\n",
    "\n",
    "    # print(conf_mat1)\n",
    "    prec = conf_mat1[0,0]/(conf_mat1[0,0]+conf_mat1[0,1])\n",
    "    rec = conf_mat1[0,0]/(conf_mat1[0,0]+conf_mat1[1,0])\n",
    "    print(prec, rec, 2*prec*rec/(prec+rec))\n",
    "    conf_mat1 = np.zeros((2,2))\n",
    "\n",
    "    # print(conf_mat2)\n",
    "    prec = conf_mat2[0,0]/(conf_mat2[0,0]+conf_mat2[0,1])\n",
    "    rec = conf_mat2[0,0]/(conf_mat2[0,0]+conf_mat2[1,0])\n",
    "    print(prec, rec, 2*prec*rec/(prec+rec))\n",
    "    conf_mat2 = np.zeros((2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.28828139935002867 0.6651962946625496 0.4022405974926647\n",
      "0.25510485651214126 0.8156153506837229 0.38864950078822913\n",
      "0.27034120734908135 0.577570093457944 0.36829558998808104\n",
      "0.2520735261152208 0.8026409707351891 0.3836574547935859\n"
     ]
    }
   ],
   "source": [
    "lm_model(train_set,test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = train_set+test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7509819480636123\n",
      "0.6846241500895507\n",
      "0.30856580436926023\n",
      "0.22246808549935848\n"
     ]
    }
   ],
   "source": [
    "valbase = 0\n",
    "valnonbase = 0\n",
    "countbase = 0\n",
    "countnonbase = 0\n",
    "for data in train_set :\n",
    "    if(data['label']=='baseline') :\n",
    "        valbase+=data['dist']\n",
    "        countbase+=1\n",
    "    else :\n",
    "        valnonbase+=data['dist']\n",
    "        countnonbase+=1\n",
    "        \n",
    "print(valbase/countbase)\n",
    "print(valnonbase/countnonbase)\n",
    "\n",
    "valbase = 0\n",
    "valnonbase = 0\n",
    "countbase = 0\n",
    "countnonbase = 0\n",
    "for data in test_set :\n",
    "    if(data['label']=='baseline') :\n",
    "        valbase+=data['dist']\n",
    "        countbase+=1\n",
    "    else :\n",
    "        valnonbase+=data['dist']\n",
    "        countnonbase+=1\n",
    "        \n",
    "print(valbase/countbase)\n",
    "print(valnonbase/countnonbase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = []\n",
    "output = []\n",
    "for data in dataset :\n",
    "    try :\n",
    "        ar = []\n",
    "        count = 0\n",
    "        ar.append(data['dist'])\n",
    "        ar.append(data['context_count'])   \n",
    "        ar.append(data['title_overlap'])\n",
    "        ar.append(data['author_hindex'])\n",
    "        ar.append(data['author_prod'])\n",
    "        ar.append(data['popularity'])\n",
    "        ar.append(data['citation_count'])\n",
    "        ar.append(data['num_table'])\n",
    "        ar.extend(data['location_feature'])\n",
    "        ar.extend(data['lmp'])\n",
    "        ar.extend(data['wcue_max'])\n",
    "        ar.extend(data['bert_embed'])\n",
    "#         ar.extend(data['source_embed'])\n",
    "\n",
    "        values.append(ar)\n",
    "        if(data['label']=='baseline'):\n",
    "            output.append(1)\n",
    "        else :\n",
    "            output.append(0)\n",
    "            \n",
    "    except :\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = np.array(values)\n",
    "output = np.array(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25968, 321)\n"
     ]
    }
   ],
   "source": [
    "print(values.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler((0,1))\n",
    "values = scaler.fit_transform(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "values, output = shuffle(values,output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(data, output):\n",
    "    n = len(data)\n",
    "    last = int(0.8*n)\n",
    "    train_data = data[:last]\n",
    "    train_output = output[:last]\n",
    "    test_data = data[last:]\n",
    "    test_output = output[last:]\n",
    "    return train_data, test_data, train_output, test_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data, train_output, test_output = split(values, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle(train_data, train_output) :\n",
    "    baselines = []\n",
    "    non_baselines = []\n",
    "    for i in range(len(train_output)) :\n",
    "        if(train_output[i]==1) :\n",
    "            baselines.append(train_data[i])\n",
    "        else :\n",
    "            non_baselines.append(train_data[i])\n",
    "    \n",
    "    n = len(baselines)\n",
    "    ar = np.random.choice(len(non_baselines), len(baselines))\n",
    "    nb_ar = []\n",
    "    for x in ar :\n",
    "        nb_ar.append(non_baselines[x])\n",
    "        \n",
    "    data = []\n",
    "    data.extend(nb_ar)\n",
    "    output = []\n",
    "    for i in range(len(data)):\n",
    "        output.append(0)\n",
    "    \n",
    "    data.extend(baselines)\n",
    "    for i in range(n) :\n",
    "        output.append(1)\n",
    "        \n",
    "    total_data = []\n",
    "    for i in range(len(data)):\n",
    "        ar = []\n",
    "        ar.append(data[i])\n",
    "        ar.append(output[i])\n",
    "        total_data.append(ar)\n",
    "        \n",
    "    total_data = np.array(total_data)\n",
    "    np.random.shuffle(total_data)\n",
    "    \n",
    "    data = []\n",
    "    output = []\n",
    "    for ar in total_data :\n",
    "        data.append(ar[0])\n",
    "        output.append(ar[1])\n",
    "        \n",
    "    data = np.array(data)\n",
    "    output = np.array(output)\n",
    "    \n",
    "    return data, output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data, train_output = shuffle(train_data, train_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'C':[0.1, 0.5, 1, 2], 'fit_intercept':[True, False]}\n",
    "modelin = LogisticRegression(solver='lbfgs', max_iter=1e4, n_jobs=5, random_state=1, warm_start=False)\n",
    "model = GridSearchCV(modelin, params, cv=2, n_jobs=5)\n",
    "# model = LogisticRegression(solver='lbfgs',max_iter=1e4, n_jobs=5, random_state=1, warm_start=False, C=1, fit_intercept=True)\n",
    "clf = model.fit(train_data, train_output)\n",
    "predict_test = clf.predict(test_data)\n",
    "print(classification_report(test_output, predict_test))\n",
    "predictions = clf.predict(train_data)\n",
    "print(classification_report(train_output, predictions))\n",
    "print(model.best_params_)\n",
    "\n",
    "\n",
    "import copy\n",
    "normal = copy.deepcopy(clf.best_estimator_.coef_[0])\n",
    "coef = clf.best_estimator_.coef_[0][:64]\n",
    "print(coef)\n",
    "ar = clf.best_estimator_.coef_[0]\n",
    "ar.sort()\n",
    "# print(ar)\n",
    "\n",
    "for i in range(15) :\n",
    "    print(ar[len(ar)-1-i], list(normal).index(ar[len(ar)-1-i]))\n",
    "# print(clf.best_estimator_.coef_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'C':[0.1, 0.5, 1, 2]}\n",
    "rbf_svc = svm.SVC(kernel='rbf', gamma='scale', max_iter=1e4, C=1 )\n",
    "model = GridSearchCV(rbf_svc, params, cv=2, n_jobs=5)\n",
    "clf = model.fit(train_data, train_output)\n",
    "predict_test = clf.predict(test_data)\n",
    "print(classification_report(test_output, predict_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
