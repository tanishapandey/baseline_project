{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, ComplementNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import svm\n",
    "import random\n",
    "import math\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = pickle.load(open(\"pickles_data/graph_directed_embedding_mapping.pkl\",'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_to_name = pickle.load(open(\"pickles_data/arnetids_to_papername.pkl\",\"rb\"))\n",
    "name_to_id = pickle.load(open(\"pickles_data/arnetids_to_papername.pkl\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = pickle.load(open(\"pickles_data/baseline_tags.pkl\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset = pickle.load(open(\"pickles_data/testset_for_graph.pkl\",\"rb\"))\n",
    "trainset = pickle.load(open(\"pickles_data/trainset_for_graph.pkl\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in trainset :\n",
    "    data['source_embed'] = mapping[data['acl_paper_arnetid']]\n",
    "    data['dest_embed'] = mapping[data['arnet_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in testset :\n",
    "    data['source_embed'] = mapping[data['acl_paper_arnetid']]\n",
    "    data['dest_embed'] = mapping[data['arnet_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_cue = pickle.load(open(\"pickles_data/weighted_cue_words.pkl\", \"rb\"))\n",
    "bert_embeddings = pickle.load(open(\"pickles_data/bert_embeddings_relu.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "location_feature = pickle.load(open(\"pickles_data/location_feature.pkl\",\"rb\"))\n",
    "title_overlap = pickle.load(open(\"pickles_data/title_overlap.pkl\",\"rb\"))\n",
    "context_count = pickle.load(open(\"pickles_data/context_count.pkl\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_table = pickle.load(open(\"pickles_data/num_table.pkl\",\"rb\"))\n",
    "popularity = pickle.load(open(\"pickles_data/popularity_sent.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_info = pickle.load(open(\"pickles/paper_info (1).pickle\", \"rb\"))\n",
    "fixed_context = pickle.load(open(\"pickles_data/fixed_context.pkl\",\"rb\"))\n",
    "author_feat = pickle.load(open(\"pickles/author_level.pickle\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20896\n",
      "23659\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "cbert = 0\n",
    "count_cc = 0\n",
    "train_set = []\n",
    "for data in trainset :\n",
    "    count+=1\n",
    "    paper = data['paper_name']\n",
    "    key = data['acl_paper_id']\n",
    "    if(key in bert_embeddings) :\n",
    "        for pap in bert_embeddings[key] :\n",
    "            if(pap['paper_name']==paper) :\n",
    "                cbert+=1\n",
    "                data['bert_embed'] = pap['embedding']\n",
    "\n",
    "        for pap in paper_info[key] :\n",
    "            if(pap['paper_name']==paper) :\n",
    "                try: \n",
    "                    data['citation_count'] = int(pap['citation'])\n",
    "                except :\n",
    "                    data['citation_count'] = 1\n",
    "                    count_cc += 1\n",
    "                try :\n",
    "                    data['venue_cit'] = int(pap['venue_cit'])\n",
    "                except :\n",
    "                    data['venue_cit'] = 20\n",
    "\n",
    "                info_found = 1\n",
    "                break\n",
    "\n",
    "\n",
    "        for pap in location_feature[key]:\n",
    "            if(pap['paper_name']==paper) :\n",
    "                data['location_feature'] = pap['location_feature']\n",
    "                break\n",
    "\n",
    "        for pap in author_feat[key] :\n",
    "            if(pap['paper_name']==paper) :\n",
    "                data['author_hindex'] = pap['hindex']\n",
    "                data['author_prod'] = pap['productivity']\n",
    "\n",
    "        for pap in num_table[key]:\n",
    "            if(pap['paper_name']==paper) :\n",
    "                data['num_table'] = pap['num_table']\n",
    "                break\n",
    "\n",
    "        for pap in title_overlap[key]:\n",
    "            if(pap['paper_name']==paper) :\n",
    "                data['title_overlap'] = pap['overlap']\n",
    "                break\n",
    "\n",
    "        for pap in popularity[key]:\n",
    "            if(pap['paper_name']==paper) :\n",
    "                data['popularity'] = pap['popularity']\n",
    "                break\n",
    "\n",
    "        for pap in context_count[key]:\n",
    "            if(pap['paper_name']==paper) :\n",
    "                data['context_count'] = pap['context_count']\n",
    "                break\n",
    "\n",
    "        for pap in weighted_cue[key]:\n",
    "            if(pap['paper_name']==paper) :\n",
    "                max_data = pap['cue_weights_max']\n",
    "                data['wcue_max'] = []\n",
    "                for key1 in max_data :\n",
    "                    data['wcue_max'].append(max_data[key1])\n",
    "                add_data = pap['cue_weights_add']\n",
    "                data['wcue_add'] = []\n",
    "                for key1 in add_data :\n",
    "                    data['wcue_add'].append(add_data[key1])\n",
    "                break\n",
    "\n",
    "\n",
    "        for pap in fixed_context[key]:\n",
    "            if(pap['paper_name']==paper) :\n",
    "                data['fixed_context'] = pap['fixed_context']    \n",
    "                \n",
    "        train_set.append(data)\n",
    "            \n",
    "    \n",
    "\n",
    "\n",
    "print(cbert)\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5185\n",
      "5915\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "cbert = 0\n",
    "count_cc = 0\n",
    "test_set = []\n",
    "for data in testset :\n",
    "    count+=1\n",
    "    paper = data['paper_name']\n",
    "    key = data['acl_paper_id']\n",
    "    if(key in bert_embeddings) :\n",
    "        for pap in bert_embeddings[key] :\n",
    "            if(pap['paper_name']==paper) :\n",
    "                cbert+=1\n",
    "                data['bert_embed'] = pap['embedding']\n",
    "\n",
    "        for pap in paper_info[key] :\n",
    "            if(pap['paper_name']==paper) :\n",
    "                try: \n",
    "                    data['citation_count'] = int(pap['citation'])\n",
    "                except :\n",
    "                    data['citation_count'] = 1\n",
    "                    count_cc += 1\n",
    "                try :\n",
    "                    data['venue_cit'] = int(pap['venue_cit'])\n",
    "                except :\n",
    "                    data['venue_cit'] = 20\n",
    "\n",
    "                info_found = 1\n",
    "                break\n",
    "\n",
    "\n",
    "        for pap in location_feature[key]:\n",
    "            if(pap['paper_name']==paper) :\n",
    "                data['location_feature'] = pap['location_feature']\n",
    "                break\n",
    "\n",
    "        for pap in author_feat[key] :\n",
    "            if(pap['paper_name']==paper) :\n",
    "                data['author_hindex'] = pap['hindex']\n",
    "                data['author_prod'] = pap['productivity']\n",
    "\n",
    "        for pap in num_table[key]:\n",
    "            if(pap['paper_name']==paper) :\n",
    "                data['num_table'] = pap['num_table']\n",
    "                break\n",
    "\n",
    "        for pap in title_overlap[key]:\n",
    "            if(pap['paper_name']==paper) :\n",
    "                data['title_overlap'] = pap['overlap']\n",
    "                break\n",
    "\n",
    "        for pap in popularity[key]:\n",
    "            if(pap['paper_name']==paper) :\n",
    "                data['popularity'] = pap['popularity']\n",
    "                break\n",
    "\n",
    "        for pap in context_count[key]:\n",
    "            if(pap['paper_name']==paper) :\n",
    "                data['context_count'] = pap['context_count']\n",
    "                break\n",
    "\n",
    "        for pap in weighted_cue[key]:\n",
    "            if(pap['paper_name']==paper) :\n",
    "                max_data = pap['cue_weights_max']\n",
    "                data['wcue_max'] = []\n",
    "                for key1 in max_data :\n",
    "                    data['wcue_max'].append(max_data[key1])\n",
    "                add_data = pap['cue_weights_add']\n",
    "                data['wcue_add'] = []\n",
    "                for key1 in add_data :\n",
    "                    data['wcue_add'].append(add_data[key1])\n",
    "                break\n",
    "\n",
    "\n",
    "        for pap in fixed_context[key]:\n",
    "            if(pap['paper_name']==paper) :\n",
    "                data['fixed_context'] = pap['fixed_context']    \n",
    "                \n",
    "        test_set.append(data)\n",
    "            \n",
    "    \n",
    "\n",
    "\n",
    "print(cbert)\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in train_set :\n",
    "    if(data['tag']==1) :\n",
    "        data['label']='baseline'\n",
    "    else :\n",
    "        data['label']='non_baseline'\n",
    "        \n",
    "for data in test_set :\n",
    "    if(data['tag']==1) :\n",
    "        data['label']='baseline'\n",
    "    else :\n",
    "        data['label'] = 'non_baseline'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in train_set :\n",
    "    data['dist'] = cosine_similarity(data['source_embed'].reshape(1,-1),data['dest_embed'].reshape(1,-1))[0][0]\n",
    "    \n",
    "for data in test_set :\n",
    "    data['dist'] = cosine_similarity(data['source_embed'].reshape(1,-1),data['dest_embed'].reshape(1,-1))[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5343202\n"
     ]
    }
   ],
   "source": [
    "for data in train_set :\n",
    "    print(data['dist'])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sanity_check(probs):\n",
    "\n",
    "\tsum = 0\n",
    "\tfor key, value in probs.items():\n",
    "\t\tsum+=value\n",
    "\tsum = round(sum, 7)\n",
    "\treturn sum==1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lm_model(trainset, testset):\n",
    "\n",
    "    word_baseline_frequency = {}\n",
    "    word_non_baseline_frequency = {}\n",
    "    baseline_length = 0\n",
    "    non_baseline_length = 0\n",
    "\n",
    "    for i in trainset:\n",
    "        # if len(i['fixed_context'])>1 and i['label']=='baseline':\n",
    "        # \tcontinue\n",
    "        for context in i['fixed_context']:\n",
    "            if i['label']=='baseline':\n",
    "                baseline_length+=len(context)\n",
    "            else:\n",
    "                non_baseline_length+=len(context)\n",
    "            for word in context:\n",
    "                if word not in word_baseline_frequency:\n",
    "                    word_baseline_frequency[word] = 0\n",
    "                    word_non_baseline_frequency[word] = 0\n",
    "                if i['label']=='baseline':\n",
    "                    word_baseline_frequency[word]+=1\n",
    "                else:\n",
    "                    word_non_baseline_frequency[word]+=1\n",
    "\n",
    "    final_word_baseline_frequency = {}\n",
    "    final_word_baseline_frequency['<unk>'] = 0\n",
    "    word_non_baseline_frequency['<unk>'] = 0\n",
    "\n",
    "    for word in word_baseline_frequency:\n",
    "        if word_baseline_frequency[word]>5:\t\n",
    "            final_word_baseline_frequency[word] = word_baseline_frequency[word]\n",
    "        else:\n",
    "            final_word_baseline_frequency['<unk>'] += word_baseline_frequency[word]\n",
    "            word_non_baseline_frequency['<unk>'] += word_non_baseline_frequency[word]\n",
    "            del word_non_baseline_frequency[word]\n",
    "\n",
    "    word_baseline_frequency = final_word_baseline_frequency\n",
    "\n",
    "    word_baseline_probability = {}\n",
    "    word_non_baseline_probability = {}\n",
    "\n",
    "    for word in word_baseline_frequency:\n",
    "        word_baseline_probability[word] = (word_baseline_frequency[word]+1)/(baseline_length+len(word_baseline_frequency))\n",
    "        word_non_baseline_probability[word] = (word_non_baseline_frequency[word]+1)/(non_baseline_length+len(word_non_baseline_frequency))\n",
    "\n",
    "    # print(word_baseline_probability['<unk>'])\n",
    "    # print(word_non_baseline_probability['<unk>'])\n",
    "\n",
    "    assert sanity_check(word_baseline_probability) and sanity_check(word_non_baseline_probability)\n",
    "\n",
    "    conf_mat1 = np.zeros((2,2))\n",
    "    conf_mat2 = np.zeros((2,2))\n",
    "\n",
    "    min_p = 1\n",
    "\n",
    "    for i in trainset+testset:\n",
    "        P_b = 0\n",
    "        P_nb = 0\n",
    "        maxP_b = 0\n",
    "        minP_nb = 1\n",
    "        n_better = 0\n",
    "        for context in i['fixed_context']:\n",
    "            \n",
    "            P_b_con = 1\n",
    "            P_nb_con = 1\n",
    "            for word in context:\n",
    "                if word not in word_baseline_probability:\n",
    "                    P_b_con*=word_baseline_probability['<unk>']\n",
    "                    P_nb_con*=word_non_baseline_probability['<unk>']\n",
    "                else:\n",
    "                    P_b_con*=word_baseline_probability[word]\n",
    "                    P_nb_con*=word_non_baseline_probability[word]\n",
    "            if P_b_con>P_nb_con:\n",
    "                n_better+=1\n",
    "            P_b+=P_b_con\n",
    "            P_nb+=P_nb_con\n",
    "            maxP_b = max(P_b, P_b_con)\n",
    "            minP_nb = min(P_nb, P_nb_con)\n",
    "        P_b/=len(i['fixed_context'])\n",
    "        P_nb/=len(i['fixed_context'])\n",
    "\n",
    "        # if P_b>P_nb:\n",
    "        # \tprint('yes')\n",
    "\n",
    "        # i['P_b'] = P_b\n",
    "        # i['P_nb'] = P_nb\n",
    "#         n_better = n_better/len(i['fixed_context'])\n",
    "        min_p = min(min_p, P_b, P_nb)\n",
    "#         i['lmp'] = [P_b, P_nb, n_better]\n",
    "        i['lmp'] = [P_b, P_nb, maxP_b, minP_nb, P_b/P_nb, maxP_b/minP_nb, n_better]\n",
    "\n",
    "    for i in trainset:\t\n",
    "        # if len(i['fixed_context'])>1 and i['label']=='baseline':\n",
    "        # \ttestset.append(i)\n",
    "        # \tcontinue\n",
    "        i['lmp'][0]/=min_p\n",
    "        i['lmp'][1]/=min_p\n",
    "        i['lmp'][2]/=min_p\n",
    "        i['lmp'][3]/=min_p\n",
    "        if i['lmp'][0]>i['lmp'][1]:\n",
    "            if i['label']=='baseline':\n",
    "                conf_mat1[0, 0]+=1\n",
    "            else:\n",
    "                conf_mat1[0, 1]+=1\n",
    "        else:\n",
    "            if i['label']=='baseline':\n",
    "                conf_mat1[1, 0]+=1\n",
    "            else:\n",
    "                conf_mat1[1, 1]+=1\n",
    "        if i['lmp'][2]>i['lmp'][3]:\n",
    "            if i['label']=='baseline':\n",
    "                conf_mat2[0, 0]+=1\n",
    "            else:\n",
    "                conf_mat2[0, 1]+=1\n",
    "        else:\n",
    "            if i['label']=='baseline':\n",
    "                conf_mat2[1, 0]+=1\n",
    "            else:\n",
    "                conf_mat2[1, 1]+=1\n",
    "\n",
    "    # print(conf_mat1)\n",
    "    prec = conf_mat1[0,0]/(conf_mat1[0,0]+conf_mat1[0,1])\n",
    "    rec = conf_mat1[0,0]/(conf_mat1[0,0]+conf_mat1[1,0])\n",
    "    print(prec, rec, 2*prec*rec/(prec+rec))\n",
    "    conf_mat1 = np.zeros((2,2))\n",
    "\n",
    "    # print(conf_mat2)\n",
    "    prec = conf_mat2[0,0]/(conf_mat2[0,0]+conf_mat2[0,1])\n",
    "    rec = conf_mat2[0,0]/(conf_mat2[0,0]+conf_mat2[1,0])\n",
    "    print(prec, rec, 2*prec*rec/(prec+rec))\n",
    "#     conf_mat2 = np.zeros((2,2))\n",
    "\n",
    "    for i in testset:\n",
    "        i['lmp'][0]/=min_p\n",
    "        i['lmp'][1]/=min_p\n",
    "        i['lmp'][2]/=min_p\n",
    "        i['lmp'][3]/=min_p\n",
    "        if i['lmp'][0]>i['lmp'][1]:\n",
    "            if i['label']=='baseline':\n",
    "                conf_mat1[0, 0]+=1\n",
    "            else:\n",
    "                conf_mat1[0, 1]+=1\n",
    "        else:\n",
    "            if i['label']=='baseline':\n",
    "                conf_mat1[1, 0]+=1\n",
    "            else:\n",
    "                conf_mat1[1, 1]+=1\n",
    "        if i['lmp'][2]>i['lmp'][3]:\n",
    "            if i['label']=='baseline':\n",
    "                conf_mat2[0, 0]+=1\n",
    "            else:\n",
    "                conf_mat2[0, 1]+=1\n",
    "        else:\n",
    "            if i['label']=='baseline':\n",
    "                conf_mat2[1, 0]+=1\n",
    "            else:\n",
    "                conf_mat2[1, 1]+=1\n",
    "\n",
    "    # print(conf_mat1)\n",
    "    prec = conf_mat1[0,0]/(conf_mat1[0,0]+conf_mat1[0,1])\n",
    "    rec = conf_mat1[0,0]/(conf_mat1[0,0]+conf_mat1[1,0])\n",
    "    print(prec, rec, 2*prec*rec/(prec+rec))\n",
    "    conf_mat1 = np.zeros((2,2))\n",
    "\n",
    "    # print(conf_mat2)\n",
    "    prec = conf_mat2[0,0]/(conf_mat2[0,0]+conf_mat2[0,1])\n",
    "    rec = conf_mat2[0,0]/(conf_mat2[0,0]+conf_mat2[1,0])\n",
    "    print(prec, rec, 2*prec*rec/(prec+rec))\n",
    "    conf_mat2 = np.zeros((2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.28828139935002867 0.6651962946625496 0.4022405974926647\n",
      "0.25510485651214126 0.8156153506837229 0.38864950078822913\n",
      "0.27034120734908135 0.577570093457944 0.36829558998808104\n",
      "0.2520735261152208 0.8026409707351891 0.3836574547935859\n"
     ]
    }
   ],
   "source": [
    "lm_model(train_set,test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = train_set+test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.49876739283350724\n",
      "0.42803639209066724\n",
      "0.22495107885763466\n",
      "0.15472951113441447\n"
     ]
    }
   ],
   "source": [
    "valbase = 0\n",
    "valnonbase = 0\n",
    "countbase = 0\n",
    "countnonbase = 0\n",
    "for data in train_set :\n",
    "    if(data['label']=='baseline') :\n",
    "        valbase+=data['dist']\n",
    "        countbase+=1\n",
    "    else :\n",
    "        valnonbase+=data['dist']\n",
    "        countnonbase+=1\n",
    "        \n",
    "print(valbase/countbase)\n",
    "print(valnonbase/countnonbase)\n",
    "\n",
    "valbase = 0\n",
    "valnonbase = 0\n",
    "countbase = 0\n",
    "countnonbase = 0\n",
    "for data in test_set :\n",
    "    if(data['label']=='baseline') :\n",
    "        valbase+=data['dist']\n",
    "        countbase+=1\n",
    "    else :\n",
    "        valnonbase+=data['dist']\n",
    "        countnonbase+=1\n",
    "        \n",
    "print(valbase/countbase)\n",
    "print(valnonbase/countnonbase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = []\n",
    "output = []\n",
    "for data in dataset :\n",
    "    try :\n",
    "        ar = []\n",
    "        count = 0\n",
    "        ar.append(data['dist'])\n",
    "        ar.append(data['context_count'])   \n",
    "        ar.append(data['title_overlap'])\n",
    "        ar.append(data['author_hindex'])\n",
    "        ar.append(data['author_prod'])\n",
    "        ar.append(data['popularity'])\n",
    "        ar.append(data['citation_count'])\n",
    "        ar.append(data['num_table'])\n",
    "        ar.extend(data['location_feature'])\n",
    "        ar.extend(data['lmp'])\n",
    "        ar.extend(data['wcue_max'])\n",
    "        ar.extend(data['bert_embed'])\n",
    "#         ar.extend(data['source_embed'])\n",
    "\n",
    "        values.append(ar)\n",
    "        if(data['label']=='baseline'):\n",
    "            output.append(1)\n",
    "        else :\n",
    "            output.append(0)\n",
    "            \n",
    "    except :\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = np.array(values)\n",
    "output = np.array(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25968, 321)\n"
     ]
    }
   ],
   "source": [
    "print(values.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler((0,1))\n",
    "values = scaler.fit_transform(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(data, output):\n",
    "    n = len(data)\n",
    "    last = int(0.8*n)\n",
    "    train_data = data[:last]\n",
    "    train_output = output[:last]\n",
    "    test_data = data[last:]\n",
    "    test_output = output[last:]\n",
    "    return train_data, test_data, train_output, test_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data, train_output, test_output = split(values, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle(train_data, train_output) :\n",
    "    baselines = []\n",
    "    non_baselines = []\n",
    "    for i in range(len(train_output)) :\n",
    "        if(train_output[i]==1) :\n",
    "            baselines.append(train_data[i])\n",
    "        else :\n",
    "            non_baselines.append(train_data[i])\n",
    "    \n",
    "    n = len(baselines)\n",
    "    ar = np.random.choice(len(non_baselines), len(baselines))\n",
    "    nb_ar = []\n",
    "    for x in ar :\n",
    "        nb_ar.append(non_baselines[x])\n",
    "        \n",
    "    data = []\n",
    "    data.extend(nb_ar)\n",
    "    output = []\n",
    "    for i in range(len(data)):\n",
    "        output.append(0)\n",
    "    \n",
    "    data.extend(baselines)\n",
    "    for i in range(n) :\n",
    "        output.append(1)\n",
    "        \n",
    "    total_data = []\n",
    "    for i in range(len(data)):\n",
    "        ar = []\n",
    "        ar.append(data[i])\n",
    "        ar.append(output[i])\n",
    "        total_data.append(ar)\n",
    "        \n",
    "    total_data = np.array(total_data)\n",
    "    np.random.shuffle(total_data)\n",
    "    \n",
    "    data = []\n",
    "    output = []\n",
    "    for ar in total_data :\n",
    "        data.append(ar[0])\n",
    "        output.append(ar[1])\n",
    "        \n",
    "    data = np.array(data)\n",
    "    output = np.array(output)\n",
    "    \n",
    "    return data, output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data, train_output = shuffle(train_data, train_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-aed947f02564>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodelin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# model = LogisticRegression(solver='lbfgs',max_iter=1e4, n_jobs=5, random_state=1, warm_start=False, C=1, fit_intercept=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mpredict_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredict_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    737\u001b[0m             \u001b[0mrefit_start_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 739\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    740\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    741\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1599\u001b[0m                       \u001b[0mpenalty\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpenalty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_squared_sum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_squared_sum\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1600\u001b[0m                       sample_weight=sample_weight)\n\u001b[0;32m-> 1601\u001b[0;31m             for class_, warm_start_coef_ in zip(classes_, warm_start_coef))\n\u001b[0m\u001b[1;32m   1602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1603\u001b[0m         \u001b[0mfold_coefs_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfold_coefs_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1017\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1018\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1019\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    907\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    908\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 909\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    910\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    560\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    561\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    563\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    425\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "params = {'C':[0.1, 0.5, 1, 2], 'fit_intercept':[True, False]}\n",
    "modelin = LogisticRegression(solver='lbfgs', max_iter=1e4, n_jobs=5, random_state=1, warm_start=False)\n",
    "model = GridSearchCV(modelin, params, cv=2, n_jobs=5)\n",
    "# model = LogisticRegression(solver='lbfgs',max_iter=1e4, n_jobs=5, random_state=1, warm_start=False, C=1, fit_intercept=True)\n",
    "clf = model.fit(train_data, train_output)\n",
    "predict_test = clf.predict(test_data)\n",
    "print(classification_report(test_output, predict_test))\n",
    "predictions = clf.predict(train_data)\n",
    "print(classification_report(train_output, predictions))\n",
    "print(model.best_params_)\n",
    "\n",
    "\n",
    "import copy\n",
    "normal = copy.deepcopy(clf.best_estimator_.coef_[0])\n",
    "coef = clf.best_estimator_.coef_[0][:64]\n",
    "print(coef)\n",
    "ar = clf.best_estimator_.coef_[0]\n",
    "ar.sort()\n",
    "# print(ar)\n",
    "\n",
    "for i in range(15) :\n",
    "    print(ar[len(ar)-1-i], list(normal).index(ar[len(ar)-1-i]))\n",
    "# print(clf.best_estimator_.coef_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tanisha17116/.local/lib/python3.6/site-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.95      0.96      4690\n",
      "           1       0.62      0.75      0.68       504\n",
      "\n",
      "    accuracy                           0.93      5194\n",
      "   macro avg       0.79      0.85      0.82      5194\n",
      "weighted avg       0.94      0.93      0.93      5194\n",
      "\n"
     ]
    }
   ],
   "source": [
    "params = {'C':[0.1, 0.5, 1, 2]}\n",
    "rbf_svc = svm.SVC(kernel='rbf', gamma='scale', max_iter=1e4, C=1, class_weight={0:1,1:5} )\n",
    "model = GridSearchCV(rbf_svc, params, cv=2, n_jobs=5)\n",
    "clf = model.fit(train_data, train_output)\n",
    "predict_test = clf.predict(test_data)\n",
    "print(classification_report(test_output, predict_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
