{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as func\n",
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction import image\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords, wordnet as wn\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "import string\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pickle\n",
    "import json\n",
    "import xml.etree.ElementTree as ET\n",
    "from nltk.corpus import stopwords, wordnet as wn\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "import os\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "import numpy as np\n",
    "import math\n",
    "from difflib import SequenceMatcher\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "stemmer = PorterStemmer()\n",
    "year_regex = re.compile(r'((19[0-9]{2})|(20[0-9]{2}))[a-z]?')\n",
    "conversion_dict = {}\n",
    "stop_words = [',', '.', '(', ')', ':', '-', \"+\", \";\", \"a\", \"about\", \"al\", \"al.\", \"all\", \n",
    "\t\"already\", \"also\", \"although\", \"am\", \"an\", \"and\", \"another\", \"any\", \"anyhow\", \"are\", \n",
    "\t\"aren\", \"aren't\", \"around\", \"as\", \"at\", \"back\", \"be\", \"because\", \"been\", \n",
    "\t\"being\", \"beyond\", \"but\", \"by\", \"can\", \"cannot\", \"cant\", \"co\", \"con\", \"could\", \"couldn\", \n",
    "\t\"couldnt\", \"d\", \"de\", \"did\", \"didn\", \"didn't\", \"do\", \"does\", \"doesn\", \"doesn't\", \n",
    "\t\"doing\", \"don\", \"don't\", \"done\", \"due\", \"each\", \"either\", \"else\", \"elsewhere\", \"et\", \n",
    "\t\"etc\", \"even\", \"ever\", \"except\", \"for\", \"found\", \"from\", \"further\", \"had\", \"hadn\", \n",
    "\t\"hadn't\", \"has\", \"hasn\", \"hasn't\", \"hasnt\", \"have\", \"haven\", \"haven't\", \"having\", \n",
    "\t\"he\", \"hence\", \"her\", \"here\", \"hereafter\", \"hereby\", \"hers\", \n",
    "\t\"herself\", \"him\", \"himself\", \"his\", \"how\", \"however\", \"i\", \"ie\", \"if\", \"in\", \"inc\", \n",
    "\t\"indeed\", \"interest\", \"into\", \"is\", \"isn\", \"isn't\", \"it\", \"it's\", \"its\", \"itself\", \n",
    "\t\"just\", \"ltd\", \"ll\", \"m\", \"may\", \"me\", \"meanwhile\", \"might\", \"mightn\", \n",
    "\t\"mightn't\", \"mine\", \"moreover\", \"most\", \"mostly\", \"move\", \"much\", \"must\", \"mustn\", \n",
    "\t\"mustn't\", \"my\", \"myself\", \"name\", \"namely\", \"need\", \"needn\", \"needn't\", \"neither\", \n",
    "\t\"nevertheless\", \"no\", \"nobody\", \"noone\", \"nor\", \"not\", \"now\", \"nowhere\", \"o\", \"of\", \n",
    "\t\"off\", \"often\", \"on\", \"only\", \"onto\", \"or\", \"other\", \"others\", \"otherwise\", \"our\", \"own\", \n",
    "\t\"per\", \"perhaps\", \"put\", \"rather\", \"re\", \"s\", \"same\", \"see\", \"seem\", \"seemed\", \n",
    "\t\"seeming\", \"seems\", \"serious\", \"she\", \"should\", \"shouldn\", \"shouldn't\", \"since\", \n",
    "\t\"sincere\", \"so\", \"some\", \"somehow\", \"someone\", \"something\", \"somewhere\", \"still\", \n",
    "\t\"such\", \"t\", \"take\", \"than\", \"that\", \"that'll\", \"the\", \"their\", \"theirs\", \n",
    "\t\"them\", \"themselves\", \"then\", \"thence\", \"there\", \"thereafter\", \"thereby\", \"therefore\", \n",
    "\t\"therein\", \"thereupon\", \"these\", \"they\", \"this\", \"those\", \"though\", \"throughout\", \n",
    "\t\"thru\", \"thus\", \"to\", \"together\", \"too\", \"toward\", \"towards\", \"un\", \"until\", \"upon\", \n",
    "\t\"us\", \"ve\", \"very\", \"via\", \"was\", \"wasn\", \"wasn't\", \"we\", \"well\", \"were\", \"weren\", \n",
    "\t\"weren't\", \"what\", \"whatever\", \"when\", \"whence\", \"whenever\", \"where\", \"whereafter\", \n",
    "\t\"whereas\", \"whereby\", \"wherein\", \"whereupon\", \"wherever\", \"whether\", \"which\", \"while\", \n",
    "\t\"whither\", \"who\", \"whoever\", \"whole\", \"whom\", \"whose\", \"why\", \"will\", \"with\", \"within\", \n",
    "\t\"without\", \"won\", \"won't\", \"would\", \"wouldn\", \"wouldn't\", \"y\", \"yet\", \"you\", \"your\", \n",
    "\t\"yours\", \"yourself\", \"yourselves\", \"from SVM import SVCone\", \"two\", \"three\", \"four\", \"five\", \"six\", \"seven\",\n",
    "\t\"eight\", \"nine\", \"zero\", \"between\", 'below', 'ourselves', \"you'll\", 'again', 'once', 'over', 'shan', 'few', \n",
    "    'against', 'before', 'out', 'down', 'both', 'up', \"you've\", \"shan't\", \"you're\", \"should've\", 'ours', 'ma', \n",
    "    \"couldn't\", 'during', 'more', 'ain', 'through', 'after', 'above', \"she's\", \"you'd\", 'under' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_citations(folder):\n",
    "    citation_list = {}\n",
    "    for file in os.listdir(folder) :\n",
    "        tree = ET.parse(folder+file)\n",
    "        root = tree.getroot()\n",
    "        id = file[:8]\n",
    "        for element in root.iterfind(\"algorithm\"):\n",
    "            if(element.attrib['name']==\"ParsCit\"):\n",
    "                citlist = element.getchildren()\n",
    "                cits = citlist[0].getchildren()\n",
    "                citations = []\n",
    "                for cit in cits:\n",
    "                    cit_dict = {}\n",
    "                    if(cit.attrib['valid']==\"true\"):\n",
    "                        try :\n",
    "                            title = cit.find('title').text.lower()\n",
    "                        except :\n",
    "                            title = cit.find('rawString').text.lower()\n",
    "                        cit_dict['title'] = title\n",
    "                        cit_dict['cit'] = cit\n",
    "                        citations.append(cit_dict)\n",
    "                \n",
    "                citation_list[id] = citations\n",
    "            \n",
    "    return citation_list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "citations = get_citations(\"../xmls/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_words(string, cit_auths=None):\n",
    "\n",
    "    string = string.replace('-', '').lower()\n",
    "    context_words = word_tokenize(string)\n",
    "    final_context_words = []\n",
    "\n",
    "    for word in context_words:\n",
    "        if word in stop_words:\n",
    "            continue\n",
    "        if re.fullmatch(year_regex, word): #or match_auths(word, cit_auths):\n",
    "            continue\n",
    "        if re.fullmatch(r'[0-9]+([.][0-9]+)?', word):\n",
    "            word = '<number>'\n",
    "            final_context_words.append(word)\n",
    "        elif 'this_citation' in word:\n",
    "            final_context_words.append('<this_citation>')\n",
    "        elif re.fullmatch(r'[a-z]+', word):\n",
    "            original_word = word\n",
    "            final_word = lemmatizer.lemmatize(word)\n",
    "            \n",
    "            if final_word not in conversion_dict:\n",
    "                conversion_dict[final_word] = {}\n",
    "\n",
    "            if original_word not in conversion_dict[final_word]:\n",
    "                conversion_dict[final_word][original_word] = 0\n",
    "            conversion_dict[final_word][original_word]+=1\n",
    "\n",
    "            final_context_words.append(final_word)\n",
    "\n",
    "    return final_context_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_contexts(citations) :\n",
    "    dataset = {}\n",
    "    count = 0\n",
    "    for key in citations.keys():\n",
    "        context_list = []\n",
    "        for cit in citations[key] :\n",
    "            dict1 = {}\n",
    "            dict1['paper_name'] = cit['title']\n",
    "            dict1['context'] = \"\"\n",
    "            for context in cit['cit'].findall('contexts/context') :\n",
    "                text = context.text.lower()\n",
    "                citstr = context.get('citStr').lower()\n",
    "                text = text.replace(citstr, \"this_citation\")\n",
    "                dict1['context']+= text+\" \"\n",
    "            dict1['context'] = get_words(dict1['context'])\n",
    "            context_list.append(dict1)\n",
    "        dataset[key] = context_list\n",
    "        count+=1\n",
    "        if(count%100==0) :\n",
    "            print(count)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n"
     ]
    }
   ],
   "source": [
    "contexts = get_contexts(citations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1141\n",
      "140.41749366058292\n"
     ]
    }
   ],
   "source": [
    "max1 = 0\n",
    "avg = 0\n",
    "number = 0\n",
    "for key in contexts :\n",
    "    papers = contexts[key]\n",
    "    for pap in papers :\n",
    "        val = len(pap['context'])\n",
    "        avg += val\n",
    "        number += 1\n",
    "        if(val>max1) :\n",
    "            max1 = val\n",
    "            \n",
    "print(max1)\n",
    "print(avg/number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_dict = {}\n",
    "with open(\"glove.6B.100d.txt\", 'r', encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        vector = np.asarray(values[1:], \"float32\")\n",
    "        embeddings_dict[word] = vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400000\n"
     ]
    }
   ],
   "source": [
    "print(len(embeddings_dict.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {}\n",
    "mapping_rev = {}\n",
    "values = []\n",
    "count = 0\n",
    "for key in contexts :\n",
    "    papers = contexts[key]\n",
    "    for pap in papers :\n",
    "        name = pap['paper_name']\n",
    "        words = pap['context']\n",
    "        if(len(words)>0) :\n",
    "            mapping[key+\"_|_\"+name] = count\n",
    "            mapping_rev[count] = key+\"_|_\"+name\n",
    "            count+=1\n",
    "            embed = []\n",
    "            for word in words :\n",
    "                if(word in embeddings_dict) :\n",
    "                    embed.append(embeddings_dict[word])\n",
    "                else :\n",
    "                    embed.append(embeddings_dict['unk'])\n",
    "            diff = 1141-len(words)\n",
    "            if(diff>0) :\n",
    "                for i in range(diff) :\n",
    "                    embed.append(embeddings_dict['unk'])\n",
    "            values.append(embed)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27635\n"
     ]
    }
   ],
   "source": [
    "print(len(values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = pickle.load(open(\"../pickles_data/baseline_tags.pkl\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = []\n",
    "for i in range(count) :\n",
    "    key,name = mapping_rev[i].split(\"_|_\")\n",
    "    papers = tags[key]\n",
    "    for pap in papers :\n",
    "        if(pap['paper_name']==name) :\n",
    "            output.append(pap['tag'])\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27635\n"
     ]
    }
   ],
   "source": [
    "print(len(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = len(values)\n",
    "trainset = values[:int(0.8*size)]\n",
    "trainlabel = output[:int(0.8*size)]\n",
    "testset = values[int(0.8*size):]\n",
    "testlabel = output[int(0.8*size):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle(train_data, train_output) :\n",
    "    baselines = []\n",
    "    non_baselines = []\n",
    "    for i in range(len(train_output)) :\n",
    "        if(train_output[i]==1) :\n",
    "            baselines.append(train_data[i])\n",
    "        else :\n",
    "            non_baselines.append(train_data[i])\n",
    "    \n",
    "    n = len(baselines)\n",
    "    ar = np.random.choice(len(non_baselines), len(baselines))\n",
    "    nb_ar = []\n",
    "    for x in ar :\n",
    "        nb_ar.append(non_baselines[x])\n",
    "        \n",
    "    data = []\n",
    "    data.extend(nb_ar)\n",
    "    output = []\n",
    "    for i in range(len(data)):\n",
    "        output.append(0)\n",
    "    \n",
    "    data.extend(baselines)\n",
    "    for i in range(n) :\n",
    "        output.append(1)\n",
    "        \n",
    "    total_data = []\n",
    "    for i in range(len(data)):\n",
    "        ar = []\n",
    "        ar.append(data[i])\n",
    "        ar.append(output[i])\n",
    "        total_data.append(ar)\n",
    "        \n",
    "    total_data = np.array(total_data)\n",
    "    np.random.shuffle(total_data)\n",
    "    \n",
    "    data = []\n",
    "    output = []\n",
    "    for ar in total_data :\n",
    "        data.append(ar[0])\n",
    "        output.append(ar[1])\n",
    "        \n",
    "    data = np.array(data)\n",
    "    output = np.array(output)\n",
    "    \n",
    "    return data, output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainset, trainlabel = shuffle(trainset, trainlabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "from torch.nn import functional as F\n",
    "\n",
    "class RCNN(nn.Module):\n",
    "\tdef __init__(self, batch_size, output_size, hidden_size, embedding_length):\n",
    "\t\tsuper(RCNN, self).__init__()\n",
    "\t\t\n",
    "\t\t\"\"\"\n",
    "\t\tArguments\n",
    "\t\t---------\n",
    "\t\tbatch_size : Size of the batch which is same as the batch_size of the data returned by the TorchText BucketIterator\n",
    "\t\toutput_size : 2 = (pos, neg)\n",
    "\t\thidden_sie : Size of the hidden_state of the LSTM\n",
    "\t\tvocab_size : Size of the vocabulary containing unique words\n",
    "\t\tembedding_length : Embedding dimension of GloVe word embeddings\n",
    "\t\tweights : Pre-trained GloVe word_embeddings which we will use to create our word_embedding look-up table \n",
    "\t\t\n",
    "\t\t\"\"\"\n",
    "\t\t\n",
    "\t\tself.batch_size = batch_size\n",
    "\t\tself.output_size = output_size\n",
    "\t\tself.hidden_size = hidden_size\n",
    "# \t\tself.vocab_size = vocab_size\n",
    "\t\tself.embedding_length = embedding_length\n",
    "\t\t\n",
    "# \t\tself.word_embeddings = nn.Embedding(vocab_size, embedding_length)# Initializing the look-up table.\n",
    "# \t\tself.word_embeddings.weight = nn.Parameter(weights, requires_grad=False) # Assigning the look-up table to the pre-trained GloVe word embedding.\n",
    "\t\tself.dropout = 0.8\n",
    "\t\tself.lstm = nn.LSTM(embedding_length, hidden_size, dropout=self.dropout, bidirectional=True)\n",
    "\t\tself.W2 = nn.Linear(2*hidden_size+embedding_length, hidden_size)\n",
    "\t\tself.label = nn.Linear(hidden_size, output_size)\n",
    "\t\t\n",
    "\tdef forward(self, input1, batch_size=None):\n",
    "\t\n",
    "\t\t\"\"\" \n",
    "\t\tParameters\n",
    "\t\t----------\n",
    "\t\tinput_sentence: input_sentence of shape = (batch_size, num_sequences)\n",
    "\t\tbatch_size : default = None. Used only for prediction on a single sentence after training (batch_size = 1)\n",
    "\t\t\n",
    "\t\tReturns\n",
    "\t\t-------\n",
    "\t\tOutput of the linear layer containing logits for positive & negative class which receives its input as the final_hidden_state of the LSTM\n",
    "\t\tfinal_output.shape = (batch_size, output_size)\n",
    "\t\t\n",
    "\t\t\"\"\"\n",
    "\t\t\n",
    "\t\t\"\"\"\n",
    "\t\t\n",
    "\t\tThe idea of the paper \"Recurrent Convolutional Neural Networks for Text Classification\" is that we pass the embedding vector\n",
    "\t\tof the text sequences through a bidirectional LSTM and then for each sequence, our final embedding vector is the concatenation of \n",
    "\t\tits own GloVe embedding and the left and right contextual embedding which in bidirectional LSTM is same as the corresponding hidden\n",
    "\t\tstate. This final embedding is passed through a linear layer which maps this long concatenated encoding vector back to the hidden_size\n",
    "\t\tvector. After this step, we use a max pooling layer across all sequences of texts. This converts any varying length text into a fixed\n",
    "\t\tdimension tensor of size (batch_size, hidden_size) and finally we map this to the output layer.\n",
    "\t\t\"\"\"\n",
    "# \t\tinput = self.word_embeddings(input_sentence) # embedded input of shape = (batch_size, num_sequences, embedding_length)\n",
    "\t\tinput1 = input1.permute(1, 0, 2) # input.size() = (num_sequences, batch_size, embedding_length)\n",
    "\t\tif batch_size is None:\n",
    "\t\t\th_0 = Variable(torch.zeros(2, self.batch_size, self.hidden_size).cuda()) # Initial hidden state of the LSTM\n",
    "\t\t\tc_0 = Variable(torch.zeros(2, self.batch_size, self.hidden_size).cuda()) # Initial cell state of the LSTM\n",
    "\t\telse:\n",
    "\t\t\th_0 = Variable(torch.zeros(2, batch_size, self.hidden_size).cuda())\n",
    "\t\t\tc_0 = Variable(torch.zeros(2, batch_size, self.hidden_size).cuda())\n",
    "\n",
    "\t\toutput, (final_hidden_state, final_cell_state) = self.lstm(input1, (h_0, c_0))\n",
    "\t\t\n",
    "\t\tfinal_encoding = torch.cat((output, input1), 2).permute(1, 0, 2)\n",
    "\t\ty = self.W2(final_encoding) # y.size() = (batch_size, num_sequences, hidden_size)\n",
    "\t\ty = y.permute(0, 2, 1) # y.size() = (batch_size, hidden_size, num_sequences)\n",
    "\t\ty = F.max_pool1d(y, y.size()[2]) # y.size() = (batch_size, hidden_size, 1)\n",
    "\t\ty = y.squeeze(2)\n",
    "\t\tlogits = self.label(y)\n",
    "\t\t\n",
    "\t\treturn logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "batch_size = 64\n",
    "\n",
    "train_data = TensorDataset(torch.as_tensor(trainset), torch.as_tensor(trainlabel))\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "val_data = TensorDataset(torch.as_tensor(testset), torch.as_tensor(testlabel))\n",
    "val_sampler = RandomSampler(val_data)\n",
    "val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def eval_model(model, val_loader) :\n",
    "    final_out = []\n",
    "    final_lab = []\n",
    "\n",
    "    for idx, (val_input, val_label) in enumerate(val_loader):\n",
    "    # val_input = val_input.permute(1,0,2)\n",
    "    # print(train_input.shape)\n",
    "        if(val_input.shape[0]==64) :\n",
    "            val_input = val_input.type(torch.FloatTensor)\n",
    "            val_input = val_input.cuda()\n",
    "            output = model(val_input)\n",
    "            output = output.cpu().detach().numpy()\n",
    "            val_label = val_label.cpu().detach().numpy()\n",
    "            ar= []\n",
    "            for i in range(output.shape[0]) :\n",
    "                index = -1\n",
    "                max_val = -1\n",
    "                for j in range(len(output[i])) :\n",
    "                    if(output[i][j]>max_val) :\n",
    "                        index = j\n",
    "                        max_val = output[i][j]\n",
    "                ar.append(index)\n",
    "\n",
    "            val_label = list(val_label)\n",
    "            final_out.extend(ar)\n",
    "            final_lab.extend(val_label)\n",
    "\n",
    "        \n",
    "    return classification_report(final_lab, final_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tanisha17116/.local/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss:0.7513\n",
      "classification_report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.68      0.78      4979\n",
      "           1       0.11      0.37      0.17       525\n",
      "\n",
      "    accuracy                           0.65      5504\n",
      "   macro avg       0.51      0.52      0.47      5504\n",
      "weighted avg       0.83      0.65      0.72      5504\n",
      "\n",
      "--------------------------------------------------------------\n",
      "Epoch [1/10], Loss:0.6528\n",
      "classification_report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.83      0.89      4979\n",
      "           1       0.30      0.69      0.42       525\n",
      "\n",
      "    accuracy                           0.82      5504\n",
      "   macro avg       0.63      0.76      0.66      5504\n",
      "weighted avg       0.90      0.82      0.85      5504\n",
      "\n",
      "--------------------------------------------------------------\n",
      "Epoch [1/10], Loss:0.3994\n",
      "classification_report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.84      0.90      4980\n",
      "           1       0.32      0.73      0.45       524\n",
      "\n",
      "    accuracy                           0.83      5504\n",
      "   macro avg       0.64      0.79      0.67      5504\n",
      "weighted avg       0.91      0.83      0.85      5504\n",
      "\n",
      "--------------------------------------------------------------\n",
      "Epoch [1/10], Loss:0.3847\n",
      "classification_report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.90      0.93      4978\n",
      "           1       0.41      0.67      0.51       526\n",
      "\n",
      "    accuracy                           0.88      5504\n",
      "   macro avg       0.69      0.78      0.72      5504\n",
      "weighted avg       0.91      0.88      0.89      5504\n",
      "\n",
      "--------------------------------------------------------------\n",
      "Epoch [2/10], Loss:0.3986\n",
      "classification_report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.92      0.94      4979\n",
      "           1       0.45      0.65      0.53       525\n",
      "\n",
      "    accuracy                           0.89      5504\n",
      "   macro avg       0.70      0.78      0.73      5504\n",
      "weighted avg       0.91      0.89      0.90      5504\n",
      "\n",
      "--------------------------------------------------------------\n",
      "Epoch [2/10], Loss:0.7025\n",
      "classification_report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.97      0.96      4978\n",
      "           1       0.62      0.44      0.52       526\n",
      "\n",
      "    accuracy                           0.92      5504\n",
      "   macro avg       0.78      0.71      0.74      5504\n",
      "weighted avg       0.91      0.92      0.91      5504\n",
      "\n",
      "--------------------------------------------------------------\n",
      "Epoch [2/10], Loss:0.3807\n",
      "classification_report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.91      0.94      4977\n",
      "           1       0.46      0.70      0.56       527\n",
      "\n",
      "    accuracy                           0.89      5504\n",
      "   macro avg       0.72      0.81      0.75      5504\n",
      "weighted avg       0.92      0.89      0.90      5504\n",
      "\n",
      "--------------------------------------------------------------\n",
      "Epoch [2/10], Loss:0.3407\n",
      "classification_report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.91      0.94      4979\n",
      "           1       0.45      0.72      0.55       525\n",
      "\n",
      "    accuracy                           0.89      5504\n",
      "   macro avg       0.71      0.81      0.75      5504\n",
      "weighted avg       0.92      0.89      0.90      5504\n",
      "\n",
      "--------------------------------------------------------------\n",
      "Epoch [3/10], Loss:0.1825\n",
      "classification_report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.93      0.94      4979\n",
      "           1       0.49      0.65      0.56       525\n",
      "\n",
      "    accuracy                           0.90      5504\n",
      "   macro avg       0.72      0.79      0.75      5504\n",
      "weighted avg       0.92      0.90      0.91      5504\n",
      "\n",
      "--------------------------------------------------------------\n",
      "Epoch [3/10], Loss:0.3400\n",
      "classification_report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.92      0.94      4980\n",
      "           1       0.47      0.64      0.54       524\n",
      "\n",
      "    accuracy                           0.90      5504\n",
      "   macro avg       0.72      0.78      0.74      5504\n",
      "weighted avg       0.91      0.90      0.90      5504\n",
      "\n",
      "--------------------------------------------------------------\n",
      "Epoch [3/10], Loss:0.2731\n",
      "classification_report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95      4978\n",
      "           1       0.55      0.56      0.56       526\n",
      "\n",
      "    accuracy                           0.91      5504\n",
      "   macro avg       0.75      0.76      0.75      5504\n",
      "weighted avg       0.91      0.91      0.91      5504\n",
      "\n",
      "--------------------------------------------------------------\n",
      "Epoch [3/10], Loss:0.3957\n",
      "classification_report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.94      0.95      4980\n",
      "           1       0.52      0.65      0.58       524\n",
      "\n",
      "    accuracy                           0.91      5504\n",
      "   macro avg       0.74      0.79      0.76      5504\n",
      "weighted avg       0.92      0.91      0.91      5504\n",
      "\n",
      "--------------------------------------------------------------\n",
      "Epoch [4/10], Loss:0.2533\n",
      "classification_report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96      4979\n",
      "           1       0.58      0.57      0.58       525\n",
      "\n",
      "    accuracy                           0.92      5504\n",
      "   macro avg       0.77      0.77      0.77      5504\n",
      "weighted avg       0.92      0.92      0.92      5504\n",
      "\n",
      "--------------------------------------------------------------\n",
      "Epoch [4/10], Loss:0.4045\n",
      "classification_report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.90      0.93      4979\n",
      "           1       0.43      0.70      0.53       525\n",
      "\n",
      "    accuracy                           0.88      5504\n",
      "   macro avg       0.70      0.80      0.73      5504\n",
      "weighted avg       0.91      0.88      0.90      5504\n",
      "\n",
      "--------------------------------------------------------------\n",
      "Epoch [4/10], Loss:0.2167\n",
      "classification_report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.89      0.93      4979\n",
      "           1       0.43      0.76      0.55       525\n",
      "\n",
      "    accuracy                           0.88      5504\n",
      "   macro avg       0.70      0.83      0.74      5504\n",
      "weighted avg       0.92      0.88      0.89      5504\n",
      "\n",
      "--------------------------------------------------------------\n",
      "Epoch [4/10], Loss:0.3406\n",
      "classification_report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.90      0.93      4979\n",
      "           1       0.43      0.74      0.54       525\n",
      "\n",
      "    accuracy                           0.88      5504\n",
      "   macro avg       0.70      0.82      0.74      5504\n",
      "weighted avg       0.92      0.88      0.89      5504\n",
      "\n",
      "--------------------------------------------------------------\n",
      "Epoch [5/10], Loss:0.2451\n",
      "classification_report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.94      0.95      4981\n",
      "           1       0.52      0.64      0.57       523\n",
      "\n",
      "    accuracy                           0.91      5504\n",
      "   macro avg       0.74      0.79      0.76      5504\n",
      "weighted avg       0.92      0.91      0.91      5504\n",
      "\n",
      "--------------------------------------------------------------\n",
      "Epoch [5/10], Loss:0.2251\n",
      "classification_report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.74      0.84      4977\n",
      "           1       0.26      0.89      0.41       527\n",
      "\n",
      "    accuracy                           0.75      5504\n",
      "   macro avg       0.62      0.81      0.63      5504\n",
      "weighted avg       0.92      0.75      0.80      5504\n",
      "\n",
      "--------------------------------------------------------------\n",
      "Epoch [5/10], Loss:0.1502\n",
      "classification_report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.92      0.94      4979\n",
      "           1       0.44      0.64      0.53       525\n",
      "\n",
      "    accuracy                           0.89      5504\n",
      "   macro avg       0.70      0.78      0.73      5504\n",
      "weighted avg       0.91      0.89      0.90      5504\n",
      "\n",
      "--------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/10], Loss:0.1724\n",
      "classification_report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.92      0.94      4978\n",
      "           1       0.47      0.69      0.56       526\n",
      "\n",
      "    accuracy                           0.89      5504\n",
      "   macro avg       0.72      0.80      0.75      5504\n",
      "weighted avg       0.92      0.89      0.90      5504\n",
      "\n",
      "--------------------------------------------------------------\n",
      "Epoch [6/10], Loss:0.1507\n",
      "classification_report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.92      0.94      4979\n",
      "           1       0.46      0.66      0.55       525\n",
      "\n",
      "    accuracy                           0.89      5504\n",
      "   macro avg       0.71      0.79      0.74      5504\n",
      "weighted avg       0.92      0.89      0.90      5504\n",
      "\n",
      "--------------------------------------------------------------\n",
      "Epoch [6/10], Loss:0.1454\n",
      "classification_report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.97      0.96      4978\n",
      "           1       0.62      0.42      0.50       526\n",
      "\n",
      "    accuracy                           0.92      5504\n",
      "   macro avg       0.78      0.70      0.73      5504\n",
      "weighted avg       0.91      0.92      0.91      5504\n",
      "\n",
      "--------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.005\n",
    "num_epochs = 10\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.cuda.empty_cache()\n",
    "model = RCNN(64,2,32,100).to(device)\n",
    "weights = [1.0, 5.0]\n",
    "class_weights = torch.FloatTensor(weights).cuda()\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for batch_id, (train_input, train_label) in enumerate(train_dataloader):\n",
    "        if(train_input.shape[0]==64) :\n",
    "            optimizer.zero_grad() \n",
    "            train_input = train_input.type(torch.FloatTensor)\n",
    "            train_input = train_input.cuda()\n",
    "            output = model(train_input)\n",
    "\n",
    "            train_label = train_label.type(torch.LongTensor)\n",
    "            train_label = train_label.cuda()\n",
    "            loss = criterion(output, train_label)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if batch_id % 100 == 0:\n",
    "                print('Epoch [{}/{}], Loss:{:.4f}'\n",
    "                    .format(epoch+1, num_epochs, loss.data))\n",
    "                print(\"classification_report\")\n",
    "                print(eval_model(model,val_dataloader))\n",
    "                print(\"--------------------------------------------------------------\")\n",
    "                # losses.append(loss.data)\n",
    "\n",
    "            del train_input\n",
    "            del train_label\n",
    "            del output\n",
    "            del loss\n",
    "            torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.97      0.96      4978\n",
      "           1       0.62      0.40      0.49       526\n",
      "\n",
      "    accuracy                           0.92      5504\n",
      "   macro avg       0.78      0.69      0.72      5504\n",
      "weighted avg       0.91      0.92      0.91      5504\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(eval_model(model, val_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict, \"models/2layer_bilstm_atten_statedict.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"models/2layer_bilstm_atten_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention_Net_Features(nn.Module) :\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3.6",
   "language": "python",
   "name": "python3.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
