{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pickle\n",
    "import json\n",
    "import string\n",
    "import gensim\n",
    "import xml.etree.ElementTree as ET\n",
    "from nltk.corpus import stopwords, wordnet as wn\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "import os\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "import numpy as np\n",
    "import math\n",
    "from difflib import SequenceMatcher\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "stemmer = PorterStemmer()\n",
    "year_regex = re.compile(r'((19[0-9]{2})|(20[0-9]{2}))[a-z]?')\n",
    "conversion_dict = {}\n",
    "stop_words = [',', '.', '(', ')', ':', '-', \"+\", \";\", \"a\", \"about\", \"al\", \"al.\", \"all\", \n",
    "\t\"already\", \"also\", \"although\", \"am\", \"an\", \"and\", \"another\", \"any\", \"anyhow\", \"are\", \n",
    "\t\"aren\", \"aren't\", \"around\", \"as\", \"at\", \"back\", \"be\", \"because\", \"been\", \n",
    "\t\"being\", \"beyond\", \"but\", \"by\", \"can\", \"cannot\", \"cant\", \"co\", \"con\", \"could\", \"couldn\", \n",
    "\t\"couldnt\", \"d\", \"de\", \"did\", \"didn\", \"didn't\", \"do\", \"does\", \"doesn\", \"doesn't\", \n",
    "\t\"doing\", \"don\", \"don't\", \"done\", \"due\", \"each\", \"either\", \"else\", \"elsewhere\", \"et\", \n",
    "\t\"etc\", \"even\", \"ever\", \"except\", \"for\", \"found\", \"from\", \"further\", \"had\", \"hadn\", \n",
    "\t\"hadn't\", \"has\", \"hasn\", \"hasn't\", \"hasnt\", \"have\", \"haven\", \"haven't\", \"having\", \n",
    "\t\"he\", \"hence\", \"her\", \"here\", \"hereafter\", \"hereby\", \"hers\", \n",
    "\t\"herself\", \"him\", \"himself\", \"his\", \"how\", \"however\", \"i\", \"ie\", \"if\", \"in\", \"inc\", \n",
    "\t\"indeed\", \"interest\", \"into\", \"is\", \"isn\", \"isn't\", \"it\", \"it's\", \"its\", \"itself\", \n",
    "\t\"just\", \"ltd\", \"ll\", \"m\", \"may\", \"me\", \"meanwhile\", \"might\", \"mightn\", \n",
    "\t\"mightn't\", \"mine\", \"moreover\", \"most\", \"mostly\", \"move\", \"much\", \"must\", \"mustn\", \n",
    "\t\"mustn't\", \"my\", \"myself\", \"name\", \"namely\", \"need\", \"needn\", \"needn't\", \"neither\", \n",
    "\t\"nevertheless\", \"no\", \"nobody\", \"noone\", \"nor\", \"not\", \"now\", \"nowhere\", \"o\", \"of\", \n",
    "\t\"off\", \"often\", \"on\", \"only\", \"onto\", \"or\", \"other\", \"others\", \"otherwise\", \"our\", \"own\", \n",
    "\t\"per\", \"perhaps\", \"put\", \"rather\", \"re\", \"s\", \"same\", \"see\", \"seem\", \"seemed\", \n",
    "\t\"seeming\", \"seems\", \"serious\", \"she\", \"should\", \"shouldn\", \"shouldn't\", \"since\", \n",
    "\t\"sincere\", \"so\", \"some\", \"somehow\", \"someone\", \"something\", \"somewhere\", \"still\", \n",
    "\t\"such\", \"t\", \"take\", \"than\", \"that\", \"that'll\", \"the\", \"their\", \"theirs\", \n",
    "\t\"them\", \"themselves\", \"then\", \"thence\", \"there\", \"thereafter\", \"thereby\", \"therefore\", \n",
    "\t\"therein\", \"thereupon\", \"these\", \"they\", \"this\", \"those\", \"though\", \"throughout\", \n",
    "\t\"thru\", \"thus\", \"to\", \"together\", \"too\", \"toward\", \"towards\", \"un\", \"until\", \"upon\", \n",
    "\t\"us\", \"ve\", \"very\", \"via\", \"was\", \"wasn\", \"wasn't\", \"we\", \"well\", \"were\", \"weren\", \n",
    "\t\"weren't\", \"what\", \"whatever\", \"when\", \"whence\", \"whenever\", \"where\", \"whereafter\", \n",
    "\t\"whereas\", \"whereby\", \"wherein\", \"whereupon\", \"wherever\", \"whether\", \"which\", \"while\", \n",
    "\t\"whither\", \"who\", \"whoever\", \"whole\", \"whom\", \"whose\", \"why\", \"will\", \"with\", \"within\", \n",
    "\t\"without\", \"won\", \"won't\", \"would\", \"wouldn\", \"wouldn't\", \"y\", \"yet\", \"you\", \"your\", \n",
    "\t\"yours\", \"yourself\", \"yourselves\", \"from SVM import SVCone\", \"two\", \"three\", \"four\", \"five\", \"six\", \"seven\",\n",
    "\t\"eight\", \"nine\", \"zero\", \"between\", 'below', 'ourselves', \"you'll\", 'again', 'once', 'over', 'shan', 'few', \n",
    "    'against', 'before', 'out', 'down', 'both', 'up', \"you've\", \"shan't\", \"you're\", \"should've\", 'ours', 'ma', \n",
    "    \"couldn't\", 'during', 'more', 'ain', 'through', 'after', 'above', \"she's\", \"you'd\", 'under' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_citations(folder):\n",
    "    citation_list = {}\n",
    "    for file in os.listdir(folder) :\n",
    "        tree = ET.parse(folder+file)\n",
    "        root = tree.getroot()\n",
    "        id = file[:8]\n",
    "        for element in root.iterfind(\"algorithm\"):\n",
    "            if(element.attrib['name']==\"ParsCit\"):\n",
    "                citlist = element.getchildren()\n",
    "                cits = citlist[0].getchildren()\n",
    "                citations = []\n",
    "                for cit in cits:\n",
    "                    cit_dict = {}\n",
    "                    if(cit.attrib['valid']==\"true\"):\n",
    "                        try :\n",
    "                            title = cit.find('title').text.lower()\n",
    "                        except :\n",
    "                            title = cit.find('rawString').text.lower()\n",
    "                        cit_dict['title'] = title\n",
    "                        cit_dict['cit'] = cit\n",
    "                        citations.append(cit_dict)\n",
    "                \n",
    "                citation_list[id] = citations\n",
    "            \n",
    "    return citation_list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "citations = get_citations(\"../xmls/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_words(string, cit_auths=None):\n",
    "\n",
    "    string = string.replace('-', '').lower()\n",
    "    context_words = word_tokenize(string)\n",
    "    final_context_words = []\n",
    "\n",
    "    for word in context_words:\n",
    "        if word in stop_words:\n",
    "            continue\n",
    "        if re.fullmatch(year_regex, word): #or match_auths(word, cit_auths):\n",
    "            continue\n",
    "        if re.fullmatch(r'[0-9]+([.][0-9]+)?', word):\n",
    "            word = '<number>'\n",
    "            final_context_words.append(word)\n",
    "        elif 'this_citation' in word:\n",
    "            final_context_words.append('<this_citation>')\n",
    "        elif re.fullmatch(r'[a-z]+', word):\n",
    "            original_word = word\n",
    "            final_word = lemmatizer.lemmatize(word)\n",
    "            \n",
    "            if final_word not in conversion_dict:\n",
    "                conversion_dict[final_word] = {}\n",
    "\n",
    "            if original_word not in conversion_dict[final_word]:\n",
    "                conversion_dict[final_word][original_word] = 0\n",
    "            conversion_dict[final_word][original_word]+=1\n",
    "\n",
    "            final_context_words.append(final_word)\n",
    "\n",
    "    return final_context_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_contexts(citations) :\n",
    "    dataset = {}\n",
    "    count = 0\n",
    "    for key in citations.keys():\n",
    "        context_list = []\n",
    "        for cit in citations[key] :\n",
    "            dict1 = {}\n",
    "            dict1['paper_name'] = cit['title']\n",
    "            dict1['context'] = \"\"\n",
    "            for context in cit['cit'].findall('contexts/context') :\n",
    "                text = context.text.lower()\n",
    "                citstr = context.get('citStr').lower()\n",
    "                text = text.replace(citstr, \"this_citation\")\n",
    "                dict1['context']+= text+\" \"\n",
    "            dict1['context'] = get_words(dict1['context'])\n",
    "            context_list.append(dict1)\n",
    "        dataset[key] = context_list\n",
    "        count+=1\n",
    "        if(count%100==0) :\n",
    "            print(count)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n"
     ]
    }
   ],
   "source": [
    "contexts = get_contexts(citations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1141\n",
      "140.41749366058292\n"
     ]
    }
   ],
   "source": [
    "max1 = 0\n",
    "avg = 0\n",
    "number = 0\n",
    "for key in contexts :\n",
    "    papers = contexts[key]\n",
    "    for pap in papers :\n",
    "        val = len(pap['context'])\n",
    "        avg += val\n",
    "        number += 1\n",
    "        if(val>max1) :\n",
    "            max1 = val\n",
    "            \n",
    "print(max1)\n",
    "print(avg/number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_dict = {}\n",
    "with open(\"glove.6B.100d.txt\", 'r', encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        vector = np.asarray(values[1:], \"float32\")\n",
    "        embeddings_dict[word] = vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400000\n"
     ]
    }
   ],
   "source": [
    "print(len(embeddings_dict.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100,)\n"
     ]
    }
   ],
   "source": [
    "print(embeddings_dict['unk'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {}\n",
    "mapping_rev = {}\n",
    "values = []\n",
    "count = 0\n",
    "for key in contexts :\n",
    "    papers = contexts[key]\n",
    "    for pap in papers :\n",
    "        name = pap['paper_name']\n",
    "        words = pap['context']\n",
    "        if(len(words)>0) :\n",
    "            mapping[key+\"_|_\"+name] = count\n",
    "            mapping_rev[count] = key+\"_|_\"+name\n",
    "            count+=1\n",
    "            embed = []\n",
    "            for word in words :\n",
    "                if(word in embeddings_dict) :\n",
    "                    embed.append(embeddings_dict[word])\n",
    "                else :\n",
    "                    embed.append(embeddings_dict['unk'])\n",
    "            diff = 1141-len(words)\n",
    "            if(diff>0) :\n",
    "                for i in range(diff) :\n",
    "                    embed.append(np.zeros((100,)))\n",
    "            values.append(embed)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27635\n"
     ]
    }
   ],
   "source": [
    "print(len(values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = pickle.load(open(\"../pickles_data/baseline_tags.pkl\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = []\n",
    "for i in range(count) :\n",
    "    key,name = mapping_rev[i].split(\"_|_\")\n",
    "    papers = tags[key]\n",
    "    for pap in papers :\n",
    "        if(pap['paper_name']==name) :\n",
    "            output.append(pap['tag'])\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27635\n"
     ]
    }
   ],
   "source": [
    "print(len(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = len(values)\n",
    "trainset = values[:int(0.8*size)]\n",
    "trainlabel = output[:int(0.8*size)]\n",
    "testset = values[int(0.8*size):]\n",
    "testlabel = output[int(0.8*size):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "from keras.engine.topology import Layer\n",
    "from keras import initializers, regularizers, constraints\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Embedding, Input\n",
    "from keras.layers import CuDNNLSTM, Bidirectional, Dropout\n",
    "\n",
    "def dot_product(x, kernel):\n",
    "    \"\"\"\n",
    "    Wrapper for dot product operation, in order to be compatible with both\n",
    "    Theano and Tensorflow\n",
    "    Args:\n",
    "        x (): input\n",
    "        kernel (): weights\n",
    "    Returns:\n",
    "    \"\"\"\n",
    "    if K.backend() == 'tensorflow':\n",
    "        return K.squeeze(K.dot(x, K.expand_dims(kernel)), axis=-1)\n",
    "    else:\n",
    "        return K.dot(x, kernel)\n",
    "    \n",
    "\n",
    "class AttentionWithContext(Layer):\n",
    "    \"\"\"\n",
    "    Attention operation, with a context/query vector, for temporal data.\n",
    "    Supports Masking.\n",
    "    Follows the work of Yang et al. [https://www.cs.cmu.edu/~diyiy/docs/naacl16.pdf]\n",
    "    \"Hierarchical Attention Networks for Document Classification\"\n",
    "    by using a context vector to assist the attention\n",
    "    # Input shape\n",
    "        3D tensor with shape: `(samples, steps, features)`.\n",
    "    # Output shape\n",
    "        2D tensor with shape: `(samples, features)`.\n",
    "    How to use:\n",
    "    Just put it on top of an RNN Layer (GRU/LSTM/SimpleRNN) with return_sequences=True.\n",
    "    The dimensions are inferred based on the output shape of the RNN.\n",
    "    Note: The layer has been tested with Keras 2.0.6\n",
    "    Example:\n",
    "        model.add(LSTM(64, return_sequences=True))\n",
    "        model.add(AttentionWithContext())\n",
    "        # next add a Dense layer (for classification/regression) or whatever...\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 W_regularizer=None, u_regularizer=None, b_regularizer=None,\n",
    "                 W_constraint=None, u_constraint=None, b_constraint=None,\n",
    "                 bias=True, **kwargs):\n",
    "\n",
    "        self.supports_masking = True\n",
    "        self.init = initializers.get('glorot_uniform')\n",
    "\n",
    "        self.W_regularizer = regularizers.get(W_regularizer)\n",
    "        self.u_regularizer = regularizers.get(u_regularizer)\n",
    "        self.b_regularizer = regularizers.get(b_regularizer)\n",
    "\n",
    "        self.W_constraint = constraints.get(W_constraint)\n",
    "        self.u_constraint = constraints.get(u_constraint)\n",
    "        self.b_constraint = constraints.get(b_constraint)\n",
    "\n",
    "        self.bias = bias\n",
    "        super(AttentionWithContext, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) == 3\n",
    "\n",
    "        self.W = self.add_weight(shape=(input_shape[-1], input_shape[-1],),\n",
    "                                 initializer=self.init,\n",
    "                                 name='{}_W'.format(self.name),\n",
    "                                 regularizer=self.W_regularizer,\n",
    "                                 constraint=self.W_constraint)\n",
    "        if self.bias:\n",
    "            self.b = self.add_weight(shape=(input_shape[-1],),\n",
    "                                     initializer='zero',\n",
    "                                     name='{}_b'.format(self.name),\n",
    "                                     regularizer=self.b_regularizer,\n",
    "                                     constraint=self.b_constraint)\n",
    "\n",
    "        self.u = self.add_weight(shape=(input_shape[-1],),\n",
    "                                 initializer=self.init,\n",
    "                                 name='{}_u'.format(self.name),\n",
    "                                 regularizer=self.u_regularizer,\n",
    "                                 constraint=self.u_constraint)\n",
    "\n",
    "        super(AttentionWithContext, self).build(input_shape)\n",
    "\n",
    "    def compute_mask(self, input, input_mask=None):\n",
    "        # do not pass the mask to the next layers\n",
    "        return None\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        uit = dot_product(x, self.W)\n",
    "\n",
    "        if self.bias:\n",
    "            uit += self.b\n",
    "\n",
    "        uit = K.tanh(uit)\n",
    "        ait = dot_product(uit, self.u)\n",
    "\n",
    "        a = K.exp(ait)\n",
    "\n",
    "        # apply mask after the exp. will be re-normalized next\n",
    "        if mask is not None:\n",
    "            # Cast the mask to floatX to avoid float64 upcasting in theano\n",
    "            a *= K.cast(mask, K.floatx())\n",
    "\n",
    "        # in some cases especially in the early stages of training the sum may be almost zero\n",
    "        # and this results in NaN's. A workaround is to add a very small positive number ε to the sum.\n",
    "        # a /= K.cast(K.sum(a, axis=1, keepdims=True), K.floatx())\n",
    "        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n",
    "\n",
    "        a = K.expand_dims(a)\n",
    "        weighted_input = x * a\n",
    "        return K.sum(weighted_input, axis=1)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[0], input_shape[-1]\n",
    "    \n",
    "def model_lstm_atten(batch_size, timesteps, vectorsize):\n",
    "    inp = Input(batch_shape=(batch_size, timesteps, vectorsize))\n",
    "    x = Bidirectional(CuDNNLSTM(32, return_sequences=True))(inp)\n",
    "    x = AttentionWithContext()(x)\n",
    "    x = Dense(32, activation=\"relu\")(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "    x = Dense(1, activation=\"sigmoid\")(x)\n",
    "    model = Model(inputs=inp, outputs=x)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import precision_recall_fscore_support\n",
    "# from sklearn.metrics import classification_report\n",
    "\n",
    "# def eval_model(model, val_loader) :\n",
    "#     final_out = []\n",
    "#     final_lab = []\n",
    "\n",
    "#     for idx, (val_input, val_label) in enumerate(val_loader):\n",
    "#     # val_input = val_input.permute(1,0,2)\n",
    "#     # print(train_input.shape)\n",
    "#         val_input = val_input.type(torch.FloatTensor)\n",
    "#         val_input = val_input.cuda()\n",
    "#         output = model(val_input)\n",
    "#         output = output.cpu().detach().numpy()\n",
    "#         val_label = val_label.cpu().detach().numpy()\n",
    "#         ar= []\n",
    "#         for i in range(output.shape[0]) :\n",
    "#             index = -1\n",
    "#             max_val = -1\n",
    "#             for j in range(len(output[i])) :\n",
    "#                 if(output[i][j]>max_val) :\n",
    "#                     index = j\n",
    "#                     max_val = output[i][j]\n",
    "#             ar.append(index)\n",
    "    \n",
    "#         val_label = list(val_label)\n",
    "#         final_out.extend(ar)\n",
    "#         final_lab.extend(val_label)\n",
    "\n",
    "        \n",
    "#     return classification_report(final_lab, final_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_f1(y_true, y_pred): #taken from old keras source code\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
    "    return f1_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/job:localhost/replica:0/task:0/device:GPU:0']\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 17708579766986834680\n",
      ", name: \"/device:XLA_GPU:0\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 6636438457831287673\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 11351868100505684653\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 9922186445\n",
      "locality {\n",
      "  bus_id: 2\n",
      "  numa_node: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 13917449353595200715\n",
      "physical_device_desc: \"device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:af:00.0, compute capability: 7.5\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/job:localhost/replica:0/task:0/device:GPU:0']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "batch_size = 128\n",
    "timesteps = 250\n",
    "vectorsize = 100\n",
    "model = model_lstm_atten(batch_size, timesteps, vectorsize)\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam',\n",
    "                  metrics=[get_f1])\n",
    "file_path = \".model.hdf5\"\n",
    "ckpt = ModelCheckpoint(file_path, monitor='val_loss', verbose=1,\n",
    "                       save_best_only=True, mode='min')\n",
    "early = EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=15)\n",
    "trainset1 = trainset[:22080]\n",
    "trainlabel1 = trainlabel[:22080]\n",
    "testset1 = testset[:5504]\n",
    "testlabel1 = testlabel[:5504]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 22080 samples, validate on 5504 samples\n",
      "Epoch 1/15\n",
      "22080/22080 [==============================] - 55s 2ms/step - loss: 0.2953 - get_f1: 0.1002 - val_loss: 0.2341 - val_get_f1: 0.3016\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.23412, saving model to .model.hdf5\n",
      "Epoch 2/15\n",
      "22080/22080 [==============================] - 54s 2ms/step - loss: 0.2419 - get_f1: 0.3098 - val_loss: 0.2126 - val_get_f1: 0.2954\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.23412 to 0.21257, saving model to .model.hdf5\n",
      "Epoch 3/15\n",
      "22080/22080 [==============================] - 54s 2ms/step - loss: 0.2273 - get_f1: 0.3730 - val_loss: 0.2063 - val_get_f1: 0.3661\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.21257 to 0.20626, saving model to .model.hdf5\n",
      "Epoch 4/15\n",
      "22080/22080 [==============================] - 53s 2ms/step - loss: 0.2123 - get_f1: 0.4431 - val_loss: 0.2014 - val_get_f1: 0.4620\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.20626 to 0.20140, saving model to .model.hdf5\n",
      "Epoch 5/15\n",
      "22080/22080 [==============================] - 53s 2ms/step - loss: 0.2032 - get_f1: 0.4836 - val_loss: 0.2015 - val_get_f1: 0.4698\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.20140\n",
      "Epoch 6/15\n",
      "22080/22080 [==============================] - 53s 2ms/step - loss: 0.1940 - get_f1: 0.5138 - val_loss: 0.2073 - val_get_f1: 0.4505\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.20140\n",
      "Epoch 7/15\n",
      "22080/22080 [==============================] - 53s 2ms/step - loss: 0.1851 - get_f1: 0.5421 - val_loss: 0.2043 - val_get_f1: 0.4788\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.20140\n",
      "Epoch 8/15\n",
      "22080/22080 [==============================] - 54s 2ms/step - loss: 0.1787 - get_f1: 0.5848 - val_loss: 0.2012 - val_get_f1: 0.4897\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.20140 to 0.20119, saving model to .model.hdf5\n",
      "Epoch 9/15\n",
      "22080/22080 [==============================] - 54s 2ms/step - loss: 0.1694 - get_f1: 0.6143 - val_loss: 0.2133 - val_get_f1: 0.4620\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.20119\n",
      "Epoch 10/15\n",
      "22080/22080 [==============================] - 54s 2ms/step - loss: 0.1626 - get_f1: 0.6397 - val_loss: 0.2101 - val_get_f1: 0.4182\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.20119\n",
      "Epoch 11/15\n",
      "22080/22080 [==============================] - 54s 2ms/step - loss: 0.1527 - get_f1: 0.6587 - val_loss: 0.2319 - val_get_f1: 0.3336\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.20119\n",
      "Epoch 12/15\n",
      "22080/22080 [==============================] - 54s 2ms/step - loss: 0.1437 - get_f1: 0.7027 - val_loss: 0.2323 - val_get_f1: 0.4974\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.20119\n",
      "Epoch 13/15\n",
      "22080/22080 [==============================] - 53s 2ms/step - loss: 0.1323 - get_f1: 0.7154 - val_loss: 0.2531 - val_get_f1: 0.4792\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.20119\n",
      "Epoch 14/15\n",
      "22080/22080 [==============================] - 53s 2ms/step - loss: 0.1291 - get_f1: 0.7216 - val_loss: 0.2726 - val_get_f1: 0.4086\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.20119\n",
      "Epoch 15/15\n",
      "22080/22080 [==============================] - 53s 2ms/step - loss: 0.1243 - get_f1: 0.7265 - val_loss: 0.2684 - val_get_f1: 0.4133\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.20119\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7fa9f0053748>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(np.array(trainset1), np.array(trainlabel1), batch_size=64, epochs=15, validation_data=(np.array(testset1), np.array(testlabel1)), callbacks=[ckpt, early])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-be26601946ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "np.array(trainset).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/15], Loss:0.6940\n",
      "classification_report\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tanisha17116/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      5000\n",
      "           1       0.10      1.00      0.17       527\n",
      "\n",
      "    accuracy                           0.10      5527\n",
      "   macro avg       0.05      0.50      0.09      5527\n",
      "weighted avg       0.01      0.10      0.02      5527\n",
      "\n",
      "--------------------------------------------------------------\n",
      "Epoch [2/15], Loss:0.5060\n",
      "classification_report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.87      0.91      5000\n",
      "           1       0.33      0.59      0.42       527\n",
      "\n",
      "    accuracy                           0.84      5527\n",
      "   macro avg       0.64      0.73      0.67      5527\n",
      "weighted avg       0.89      0.84      0.86      5527\n",
      "\n",
      "--------------------------------------------------------------\n",
      "Epoch [3/15], Loss:0.4954\n",
      "classification_report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.79      0.87      5000\n",
      "           1       0.26      0.71      0.38       527\n",
      "\n",
      "    accuracy                           0.78      5527\n",
      "   macro avg       0.61      0.75      0.63      5527\n",
      "weighted avg       0.90      0.78      0.82      5527\n",
      "\n",
      "--------------------------------------------------------------\n",
      "Epoch [4/15], Loss:0.5183\n",
      "classification_report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.76      0.85      5000\n",
      "           1       0.25      0.77      0.38       527\n",
      "\n",
      "    accuracy                           0.76      5527\n",
      "   macro avg       0.61      0.76      0.61      5527\n",
      "weighted avg       0.90      0.76      0.81      5527\n",
      "\n",
      "--------------------------------------------------------------\n",
      "Epoch [5/15], Loss:0.5350\n",
      "classification_report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.79      0.87      5000\n",
      "           1       0.27      0.76      0.40       527\n",
      "\n",
      "    accuracy                           0.78      5527\n",
      "   macro avg       0.62      0.77      0.64      5527\n",
      "weighted avg       0.90      0.78      0.82      5527\n",
      "\n",
      "--------------------------------------------------------------\n",
      "Epoch [6/15], Loss:0.5219\n",
      "classification_report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.72      0.83      5000\n",
      "           1       0.24      0.87      0.38       527\n",
      "\n",
      "    accuracy                           0.73      5527\n",
      "   macro avg       0.61      0.79      0.60      5527\n",
      "weighted avg       0.91      0.73      0.79      5527\n",
      "\n",
      "--------------------------------------------------------------\n",
      "Epoch [7/15], Loss:0.3678\n",
      "classification_report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.84      0.90      5000\n",
      "           1       0.33      0.78      0.47       527\n",
      "\n",
      "    accuracy                           0.83      5527\n",
      "   macro avg       0.65      0.81      0.68      5527\n",
      "weighted avg       0.91      0.83      0.86      5527\n",
      "\n",
      "--------------------------------------------------------------\n",
      "Epoch [8/15], Loss:0.4171\n",
      "classification_report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.86      0.91      5000\n",
      "           1       0.36      0.74      0.49       527\n",
      "\n",
      "    accuracy                           0.85      5527\n",
      "   macro avg       0.67      0.80      0.70      5527\n",
      "weighted avg       0.91      0.85      0.87      5527\n",
      "\n",
      "--------------------------------------------------------------\n",
      "Epoch [9/15], Loss:0.4201\n",
      "classification_report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.90      0.93      5000\n",
      "           1       0.41      0.70      0.52       527\n",
      "\n",
      "    accuracy                           0.88      5527\n",
      "   macro avg       0.69      0.80      0.72      5527\n",
      "weighted avg       0.91      0.88      0.89      5527\n",
      "\n",
      "--------------------------------------------------------------\n",
      "Epoch [10/15], Loss:0.4484\n",
      "classification_report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.87      0.92      5000\n",
      "           1       0.38      0.77      0.51       527\n",
      "\n",
      "    accuracy                           0.86      5527\n",
      "   macro avg       0.68      0.82      0.71      5527\n",
      "weighted avg       0.92      0.86      0.88      5527\n",
      "\n",
      "--------------------------------------------------------------\n",
      "Epoch [11/15], Loss:0.3449\n",
      "classification_report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.87      0.92      5000\n",
      "           1       0.39      0.78      0.52       527\n",
      "\n",
      "    accuracy                           0.86      5527\n",
      "   macro avg       0.68      0.82      0.72      5527\n",
      "weighted avg       0.92      0.86      0.88      5527\n",
      "\n",
      "--------------------------------------------------------------\n",
      "Epoch [12/15], Loss:0.3850\n",
      "classification_report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.79      0.87      5000\n",
      "           1       0.30      0.86      0.44       527\n",
      "\n",
      "    accuracy                           0.79      5527\n",
      "   macro avg       0.64      0.82      0.66      5527\n",
      "weighted avg       0.92      0.79      0.83      5527\n",
      "\n",
      "--------------------------------------------------------------\n",
      "Epoch [13/15], Loss:0.4876\n",
      "classification_report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.89      0.93      5000\n",
      "           1       0.41      0.74      0.53       527\n",
      "\n",
      "    accuracy                           0.87      5527\n",
      "   macro avg       0.69      0.81      0.73      5527\n",
      "weighted avg       0.92      0.87      0.89      5527\n",
      "\n",
      "--------------------------------------------------------------\n",
      "Epoch [14/15], Loss:0.2898\n",
      "classification_report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.88      0.92      5000\n",
      "           1       0.39      0.76      0.52       527\n",
      "\n",
      "    accuracy                           0.86      5527\n",
      "   macro avg       0.68      0.82      0.72      5527\n",
      "weighted avg       0.92      0.86      0.88      5527\n",
      "\n",
      "--------------------------------------------------------------\n",
      "Epoch [15/15], Loss:0.4271\n",
      "classification_report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.89      0.93      5000\n",
      "           1       0.40      0.69      0.50       527\n",
      "\n",
      "    accuracy                           0.87      5527\n",
      "   macro avg       0.68      0.79      0.71      5527\n",
      "weighted avg       0.91      0.87      0.89      5527\n",
      "\n",
      "--------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# learning_rate = 0.005\n",
    "# num_epochs = 15\n",
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# torch.cuda.empty_cache()\n",
    "# model = Attention_Net().to(device)\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# for epoch in range(num_epochs):\n",
    "#     for batch_id, (train_input, train_label) in enumerate(train_dataloader):\n",
    "#         optimizer.zero_grad() \n",
    "#         train_input = train_input.type(torch.FloatTensor)\n",
    "#         train_input = train_input.cuda()\n",
    "#         output = model(train_input)\n",
    "\n",
    "#         train_label = train_label.type(torch.LongTensor)\n",
    "#         train_label = train_label.cuda()\n",
    "#         loss = criterion(output, train_label)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "        \n",
    "#         if batch_id % 100 == 0:\n",
    "#             print('Epoch [{}/{}], Loss:{:.4f}'\n",
    "#                 .format(epoch+1, num_epochs, loss.data))\n",
    "#             print(\"classification_report\")\n",
    "#             print(eval_model(model,val_dataloader))\n",
    "#             print(\"--------------------------------------------------------------\")\n",
    "#             # losses.append(loss.data)\n",
    "            \n",
    "#         del train_input\n",
    "#         del train_label\n",
    "#         del output\n",
    "#         del loss\n",
    "#         torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.98      0.96      5000\n",
      "           1       0.65      0.43      0.52       527\n",
      "\n",
      "    accuracy                           0.92      5527\n",
      "   macro avg       0.80      0.70      0.74      5527\n",
      "weighted avg       0.91      0.92      0.92      5527\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print(eval_model(model, val_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model.state_dict, \"models/2layer_bilstm_atten_statedict.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model, \"models/2layer_bilstm_atten_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Attention_Net_Features(nn.Module) :\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3.6",
   "language": "python",
   "name": "python3.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
