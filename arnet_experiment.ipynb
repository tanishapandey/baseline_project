{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import random\n",
    "import math\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pickle\n",
    "import json\n",
    "import xml.etree.ElementTree as ET\n",
    "from nltk.corpus import stopwords, wordnet as wn\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "import os\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "import numpy as np\n",
    "import math\n",
    "from difflib import SequenceMatcher\n",
    "import pandas as pd\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stemmer = PorterStemmer()\n",
    "year_regex = re.compile(r'((19[0-9]{2})|(20[0-9]{2}))[a-z]?')\n",
    "conversion_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = [',', '.', '(', ')', ':', '-', \"+\", \";\", \"a\", \"about\", \"al\", \"al.\", \"all\", \n",
    "\t\"already\", \"also\", \"although\", \"am\", \"an\", \"and\", \"another\", \"any\", \"anyhow\", \"are\", \n",
    "\t\"aren\", \"aren't\", \"around\", \"as\", \"at\", \"back\", \"be\", \"because\", \"been\", \n",
    "\t\"being\", \"beyond\", \"but\", \"by\", \"can\", \"cannot\", \"cant\", \"co\", \"con\", \"could\", \"couldn\", \n",
    "\t\"couldnt\", \"d\", \"de\", \"did\", \"didn\", \"didn't\", \"do\", \"does\", \"doesn\", \"doesn't\", \n",
    "\t\"doing\", \"don\", \"don't\", \"done\", \"due\", \"each\", \"either\", \"else\", \"elsewhere\", \"et\", \n",
    "\t\"etc\", \"even\", \"ever\", \"except\", \"for\", \"found\", \"from\", \"further\", \"had\", \"hadn\", \n",
    "\t\"hadn't\", \"has\", \"hasn\", \"hasn't\", \"hasnt\", \"have\", \"haven\", \"haven't\", \"having\", \n",
    "\t\"he\", \"hence\", \"her\", \"here\", \"hereafter\", \"hereby\", \"hers\", \n",
    "\t\"herself\", \"him\", \"himself\", \"his\", \"how\", \"however\", \"i\", \"ie\", \"if\", \"in\", \"inc\", \n",
    "\t\"indeed\", \"interest\", \"into\", \"is\", \"isn\", \"isn't\", \"it\", \"it's\", \"its\", \"itself\", \n",
    "\t\"just\", \"ltd\", \"ll\", \"m\", \"may\", \"me\", \"meanwhile\", \"might\", \"mightn\", \n",
    "\t\"mightn't\", \"mine\", \"moreover\", \"most\", \"mostly\", \"move\", \"much\", \"must\", \"mustn\", \n",
    "\t\"mustn't\", \"my\", \"myself\", \"name\", \"namely\", \"need\", \"needn\", \"needn't\", \"neither\", \n",
    "\t\"nevertheless\", \"no\", \"nobody\", \"noone\", \"nor\", \"not\", \"now\", \"nowhere\", \"o\", \"of\", \n",
    "\t\"off\", \"often\", \"on\", \"only\", \"onto\", \"or\", \"other\", \"others\", \"otherwise\", \"our\", \"own\", \n",
    "\t\"per\", \"perhaps\", \"put\", \"rather\", \"re\", \"s\", \"same\", \"see\", \"seem\", \"seemed\", \n",
    "\t\"seeming\", \"seems\", \"serious\", \"she\", \"should\", \"shouldn\", \"shouldn't\", \"since\", \n",
    "\t\"sincere\", \"so\", \"some\", \"somehow\", \"someone\", \"something\", \"somewhere\", \"still\", \n",
    "\t\"such\", \"t\", \"take\", \"than\", \"that\", \"that'll\", \"the\", \"their\", \"theirs\", \n",
    "\t\"them\", \"themselves\", \"then\", \"thence\", \"there\", \"thereafter\", \"thereby\", \"therefore\", \n",
    "\t\"therein\", \"thereupon\", \"these\", \"they\", \"this\", \"those\", \"though\", \"throughout\", \n",
    "\t\"thru\", \"thus\", \"to\", \"together\", \"too\", \"toward\", \"towards\", \"un\", \"until\", \"upon\", \n",
    "\t\"us\", \"ve\", \"very\", \"via\", \"was\", \"wasn\", \"wasn't\", \"we\", \"well\", \"were\", \"weren\", \n",
    "\t\"weren't\", \"what\", \"whatever\", \"when\", \"whence\", \"whenever\", \"where\", \"whereafter\", \n",
    "\t\"whereas\", \"whereby\", \"wherein\", \"whereupon\", \"wherever\", \"whether\", \"which\", \"while\", \n",
    "\t\"whither\", \"who\", \"whoever\", \"whole\", \"whom\", \"whose\", \"why\", \"will\", \"with\", \"within\", \n",
    "\t\"without\", \"won\", \"won't\", \"would\", \"wouldn\", \"wouldn't\", \"y\", \"yet\", \"you\", \"your\", \n",
    "\t\"yours\", \"yourself\", \"yourselves\", \"from SVM import SVCone\", \"two\", \"three\", \"four\", \"five\", \"six\", \"seven\",\n",
    "\t\"eight\", \"nine\", \"zero\", \"between\", 'below', 'ourselves', \"you'll\", 'again', 'once', 'over', 'shan', 'few', \n",
    "    'against', 'before', 'out', 'down', 'both', 'up', \"you've\", \"shan't\", \"you're\", \"should've\", 'ours', 'ma', \n",
    "    \"couldn't\", 'during', 'more', 'ain', 'through', 'after', 'above', \"she's\", \"you'd\", 'under' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_common_words(paper_title, cit_title):\n",
    "\n",
    "\tpaper_title_words = word_tokenize(paper_title.replace('-', ' ').lower())\n",
    "\tcit_title_words = word_tokenize(cit_title.replace('-', ' ').lower())\n",
    "\n",
    "\tfinal_paper_title_words = []\n",
    "\tfor word in paper_title_words:\n",
    "\t\tif word in stop_words:\n",
    "\t\t\tcontinue\n",
    "\t\telif re.fullmatch(r'[a-z]+', word):\n",
    "\t\t\tword = lemmatizer.lemmatize(word)\n",
    "\t\t\tfinal_word = stemmer.stem(word)\n",
    "\t\t\tword = final_word\n",
    "\n",
    "\t\t\tfinal_paper_title_words.append(word)\n",
    "\n",
    "\tfinal_cit_title_words = []\n",
    "\tfor word in cit_title_words:\n",
    "\t\tif word in stop_words:\n",
    "\t\t\tcontinue\n",
    "\t\telif re.fullmatch(r'[a-z]+', word):\n",
    "\t\t\tword = lemmatizer.lemmatize(word)\n",
    "\t\t\tfinal_word = stemmer.stem(word)\n",
    "\t\t\tword = final_word\n",
    "\n",
    "\t\t\tfinal_cit_title_words.append(word)\n",
    "\n",
    "\treturn len(set(final_cit_title_words)&set(final_paper_title_words))/(len(set(final_paper_title_words)|set(final_cit_title_words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_abstract_similarity() :\n",
    "    abstracts = pickle.load(open(\"pickles_data/abstracts_total.pkl\", \"rb\"))\n",
    "    paper_info = pickle.load(open(\"pickles_data/paper_info_partial_mapping.pickle\",\"rb\"))\n",
    "    ids_consider = pickle.load(open(\"pickles_data/arnet_exp_keys.pkl\", \"rb\"))\n",
    "    \n",
    "    dataset = {}\n",
    "    for key in paper_info :\n",
    "        papers = paper_info[key]\n",
    "        abstract = abstracts[key]\n",
    "        data = []\n",
    "        for paper in papers :\n",
    "            try :\n",
    "                abcit = \"\".join(list(paper['abstract']['InvertedIndex'].keys()))\n",
    "                sim = find_common_words(abcit, abstract)\n",
    "                dict1 = {}\n",
    "                dict1['paper_name'] = paper['paper_name']\n",
    "                dict1['abs_sim'] = sim\n",
    "                data.append(dict1)\n",
    "            except :\n",
    "                pass\n",
    "        dataset[key] = data\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs_sim = get_abstract_similarity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "location_feature = pickle.load(open(\"pickles_data/location_feature.pkl\",\"rb\"))\n",
    "title_overlap = pickle.load(open(\"pickles_data/title_overlap.pkl\",\"rb\"))\n",
    "context_count = pickle.load(open(\"pickles_data/context_count.pkl\",\"rb\"))\n",
    "cue_words = pickle.load(open(\"pickles_data/cue_count.pkl\", \"rb\"))\n",
    "tags = pickle.load(open(\"pickles_data/baseline_tags.pkl\", \"rb\"))\n",
    "contexts = pickle.load(open(\"pickles_data/context_words.pkl\", \"rb\"))\n",
    "popularity = pickle.load(open(\"pickles_data/popularity_sent.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_diff = pickle.load(open(\"pickles_data/year_diff.pkl\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_context = pickle.load(open(\"pickles_data/fixed_context.pkl\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_cue = pickle.load(open(\"pickles_data/weighted_cue_words.pkl\", \"rb\"))\n",
    "bert_embeddings = pickle.load(open(\"pickles_data/bert_embeddings_relu.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1181\n"
     ]
    }
   ],
   "source": [
    "print(len(context_count.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_table = pickle.load(open(\"pickles_data/num_table.pkl\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cit_titles = pickle.load(open(\"pickles_data/citation_titles.pkl\",\"rb\"))\n",
    "ids = tags.keys()\n",
    "ids = list(set(ids).intersection(set(num_table.keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_consider = pickle.load(open(\"pickles_data/arnet_exp_keys.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_info = pickle.load(open(\"pickles_data/paper_info_partial_mapping.pickle\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'paper_name': 'joint language and translation modeling with recurrent neural networks.',\n",
       "  'citation': 129,\n",
       "  'abstract': {'IndexLength': 133,\n",
       "   'InvertedIndex': {'We': [0, 51, 92],\n",
       "    'present': [1],\n",
       "    'a': [2, 10, 38, 56, 71, 83, 110],\n",
       "    'joint': [3, 67],\n",
       "    'language': [4, 47, 77],\n",
       "    'and': [5, 26, 61, 123],\n",
       "    'translation': [6, 49],\n",
       "    'model': [7, 35, 68, 78, 101],\n",
       "    'based': [8, 18],\n",
       "    'on': [9, 19, 70, 113, 127],\n",
       "    'recurrent': [11, 74],\n",
       "    'neural': [12, 75],\n",
       "    'network': [13, 76],\n",
       "    'which': [14],\n",
       "    'predicts': [15],\n",
       "    'target': [16, 27],\n",
       "    'words': [17],\n",
       "    'an': [20],\n",
       "    'unbounded': [21],\n",
       "    'history': [22],\n",
       "    'of': [23, 33, 85, 109],\n",
       "    'both': [24],\n",
       "    'source': [25, 90],\n",
       "    'words.': [28],\n",
       "    'The': [29],\n",
       "    'weaker': [30],\n",
       "    'independence': [31],\n",
       "    'assumptions': [32],\n",
       "    'this': [34, 53],\n",
       "    'result': [36],\n",
       "    'in': [37],\n",
       "    'vastly': [39],\n",
       "    'larger': [40],\n",
       "    'search': [41],\n",
       "    'space': [42],\n",
       "    'compared': [43, 96],\n",
       "    'to': [44, 97, 120],\n",
       "    'related': [45],\n",
       "    'feedforward-based': [46],\n",
       "    'or': [48],\n",
       "    'models.': [50],\n",
       "    'tackle': [52],\n",
       "    'issue': [54],\n",
       "    'with': [55],\n",
       "    'new': [57],\n",
       "    'lattice': [58],\n",
       "    'rescoring': [59],\n",
       "    'algorithm': [60],\n",
       "    'demonstrate': [62],\n",
       "    'its': [63],\n",
       "    'effectiveness': [64],\n",
       "    'empirically.': [65],\n",
       "    'Our': [66, 103],\n",
       "    'builds': [69],\n",
       "    'well': [72],\n",
       "    'known': [73],\n",
       "    '(Mikolov,': [79],\n",
       "    '2012)': [80],\n",
       "    'augmented': [81],\n",
       "    'by': [82, 118, 124],\n",
       "    'layer': [84],\n",
       "    'additional': [86],\n",
       "    'inputs': [87],\n",
       "    'from': [88],\n",
       "    'the': [89, 98, 107],\n",
       "    'language.': [91],\n",
       "    'show': [93],\n",
       "    'competitive': [94],\n",
       "    'accuracy': [95],\n",
       "    'traditional': [99],\n",
       "    'channel': [100],\n",
       "    'features.': [102],\n",
       "    'best': [104],\n",
       "    'results': [105],\n",
       "    'improve': [106],\n",
       "    'output': [108],\n",
       "    'system': [111],\n",
       "    'trained': [112],\n",
       "    'WMT': [114],\n",
       "    '2012': [115],\n",
       "    'French-English': [116],\n",
       "    'data': [117],\n",
       "    'up': [119],\n",
       "    '1.5': [121],\n",
       "    'BLEU,': [122],\n",
       "    '1.1': [125],\n",
       "    'BLEU': [126],\n",
       "    'average': [128],\n",
       "    'across': [129],\n",
       "    'several': [130],\n",
       "    'test': [131],\n",
       "    'sets.': [132]}}},\n",
       " {'paper_name': 'a neural probabilistic language model.',\n",
       "  'citation': 2187,\n",
       "  'abstract': {'IndexLength': 228,\n",
       "   'InvertedIndex': {'A': [0],\n",
       "    'goal': [1],\n",
       "    'of': [2, 13, 15, 25, 28, 80, 102, 129, 138, 153, 161, 179, 225],\n",
       "    'statistical': [3],\n",
       "    'language': [4],\n",
       "    'modeling': [5],\n",
       "    'is': [6, 21, 40, 133, 151, 185],\n",
       "    'to': [7, 42, 76, 94, 166, 222],\n",
       "    'learn': [8],\n",
       "    'the': [9, 26, 35, 47, 71, 78, 96, 120, 159, 198, 207, 218],\n",
       "    'joint': [10],\n",
       "    'probability': [11, 121, 148, 199],\n",
       "    'function': [12, 122],\n",
       "    'sequences': [14, 49, 68],\n",
       "    'words': [16, 88, 139, 154, 167],\n",
       "    'in': [17, 70, 127],\n",
       "    'a': [18, 30, 84, 111, 136, 163, 182, 187],\n",
       "    'language.': [19],\n",
       "    'This': [20],\n",
       "    'intrinsically': [22],\n",
       "    'difficult': [23],\n",
       "    'because': [24, 135],\n",
       "    'curse': [27, 79],\n",
       "    'dimensionality:': [29],\n",
       "    'word': [31, 48, 116, 124],\n",
       "    'sequence': [32, 137],\n",
       "    'on': [33, 59, 192, 202, 212],\n",
       "    'which': [34, 89],\n",
       "    'model': [36, 97, 107],\n",
       "    'will': [37],\n",
       "    'be': [38, 43],\n",
       "    'tested': [39],\n",
       "    'likely': [41],\n",
       "    'different': [44],\n",
       "    'from': [45],\n",
       "    'all': [46],\n",
       "    'seen': [50, 69, 144, 171],\n",
       "    'during': [51],\n",
       "    'training.': [52],\n",
       "    'Traditional': [53],\n",
       "    'but': [54],\n",
       "    'very': [55, 65],\n",
       "    'successful': [56],\n",
       "    'approaches': [57],\n",
       "    'based': [58],\n",
       "    'n-grams': [60],\n",
       "    'obtain': [61],\n",
       "    'generalization': [62],\n",
       "    'by': [63, 82],\n",
       "    'concatenating': [64],\n",
       "    'short': [66],\n",
       "    'overlapping': [67],\n",
       "    'training': [72, 92],\n",
       "    'set.': [73],\n",
       "    'We': [74, 190],\n",
       "    'propose': [75],\n",
       "    'fight': [77],\n",
       "    'dimensionality': [81],\n",
       "    'learning': [83],\n",
       "    'distributed': [85, 112],\n",
       "    'representation': [86, 113],\n",
       "    'for': [87, 114, 123, 197],\n",
       "    'allows': [90, 221],\n",
       "    'each': [91, 115],\n",
       "    'sentence': [93],\n",
       "    'inform': [95],\n",
       "    'about': [98],\n",
       "    'an': [99, 169],\n",
       "    'exponential': [100],\n",
       "    'number': [101],\n",
       "    'semantically': [103],\n",
       "    'neighboring': [104],\n",
       "    'sentences.': [105],\n",
       "    'The': [106],\n",
       "    'learns': [108],\n",
       "    'simultaneously': [109],\n",
       "    '(1)': [110],\n",
       "    'along': [117],\n",
       "    'with': [118],\n",
       "    '(2)': [119],\n",
       "    'sequences,': [125],\n",
       "    'expressed': [126],\n",
       "    'terms': [128],\n",
       "    'these': [130],\n",
       "    'representations.': [131],\n",
       "    'Generalization': [132],\n",
       "    'obtained': [134],\n",
       "    'that': [140, 155, 206, 217],\n",
       "    'has': [141],\n",
       "    'never': [142],\n",
       "    'been': [143],\n",
       "    'before': [145],\n",
       "    'gets': [146],\n",
       "    'high': [147],\n",
       "    'if': [149],\n",
       "    'it': [150],\n",
       "    'made': [152],\n",
       "    'are': [156],\n",
       "    'similar': [157],\n",
       "    '(in': [158],\n",
       "    'sense': [160],\n",
       "    'having': [162],\n",
       "    'nearby': [164],\n",
       "    'representation)': [165],\n",
       "    'forming': [168],\n",
       "    'already': [170],\n",
       "    'sentence.': [172],\n",
       "    'Training': [173],\n",
       "    'such': [174],\n",
       "    'large': [175],\n",
       "    'models': [176],\n",
       "    '(with': [177],\n",
       "    'millions': [178],\n",
       "    'parameters)': [180],\n",
       "    'within': [181],\n",
       "    'reasonable': [183],\n",
       "    'time': [184],\n",
       "    'itself': [186],\n",
       "    'significant': [188],\n",
       "    'challenge.': [189],\n",
       "    'report': [191],\n",
       "    'experiments': [193],\n",
       "    'using': [194],\n",
       "    'neural': [195],\n",
       "    'networks': [196],\n",
       "    'function,': [200],\n",
       "    'showing': [201],\n",
       "    'two': [203],\n",
       "    'text': [204],\n",
       "    'corpora': [205],\n",
       "    'proposed': [208, 219],\n",
       "    'approach': [209, 220],\n",
       "    'significantly': [210],\n",
       "    'improves': [211],\n",
       "    'state-of-the-art': [213],\n",
       "    'n-gram': [214],\n",
       "    'models,': [215],\n",
       "    'and': [216],\n",
       "    'take': [223],\n",
       "    'advantage': [224],\n",
       "    'longer': [226],\n",
       "    'contexts.': [227]}}},\n",
       " {'paper_name': 'latent dirichlet allocation.',\n",
       "  'citation': 15863,\n",
       "  'abstract': {'IndexLength': 120,\n",
       "   'InvertedIndex': {'We': [0, 78, 97],\n",
       "    'describe': [1],\n",
       "    'latent': [2],\n",
       "    'Dirichlet': [3],\n",
       "    'allocation': [4],\n",
       "    '(LDA),': [5],\n",
       "    'a': [6, 21, 31, 36, 76, 110],\n",
       "    'generative': [7],\n",
       "    'probabilistic': [8, 117],\n",
       "    'model': [9, 114],\n",
       "    'for': [10, 92],\n",
       "    'collections': [11],\n",
       "    'of': [12, 30, 43, 59, 65, 75, 112],\n",
       "    'discrete': [13],\n",
       "    'data': [14],\n",
       "    'such': [15],\n",
       "    'as': [16, 35, 51],\n",
       "    'text': [17, 66, 103],\n",
       "    'corpora.': [18],\n",
       "    'LDA': [19],\n",
       "    'is': [20, 33],\n",
       "    'three-level': [22],\n",
       "    'hierarchical': [23],\n",
       "    'Bayesian': [24],\n",
       "    'model,': [25],\n",
       "    'in': [26, 48, 100],\n",
       "    'which': [27],\n",
       "    'each': [28],\n",
       "    'item': [29],\n",
       "    'collection': [32],\n",
       "    'modeled': [34, 50],\n",
       "    'finite': [37],\n",
       "    'mixture': [38, 54, 111],\n",
       "    'over': [39, 55],\n",
       "    'an': [40, 52, 56, 72, 89],\n",
       "    'underlying': [41, 57],\n",
       "    'set': [42, 58],\n",
       "    'topics.': [44],\n",
       "    'Each': [45],\n",
       "    'topic': [46, 60, 69],\n",
       "    'is,': [47],\n",
       "    'turn,': [49],\n",
       "    'infinite': [53],\n",
       "    'probabilities.': [61],\n",
       "    'In': [62],\n",
       "    'the': [63, 68, 116],\n",
       "    'context': [64],\n",
       "    'modeling,': [67, 102],\n",
       "    'probabilities': [70],\n",
       "    'provide': [71],\n",
       "    'explicit': [73],\n",
       "    'representation': [74],\n",
       "    'document.': [77],\n",
       "    'present': [79],\n",
       "    'efficient': [80],\n",
       "    'approximate': [81],\n",
       "    'inference': [82],\n",
       "    'techniques': [83],\n",
       "    'based': [84],\n",
       "    'on': [85],\n",
       "    'variational': [86],\n",
       "    'methods': [87],\n",
       "    'and': [88, 105, 115],\n",
       "    'EM': [90],\n",
       "    'algorithm': [91],\n",
       "    'empirical': [93],\n",
       "    'Bayes': [94],\n",
       "    'parameter': [95],\n",
       "    'estimation.': [96],\n",
       "    'report': [98],\n",
       "    'results': [99],\n",
       "    'document': [101],\n",
       "    'classification,': [104],\n",
       "    'collaborative': [106],\n",
       "    'filtering,': [107],\n",
       "    'comparing': [108],\n",
       "    'to': [109],\n",
       "    'unigrams': [113],\n",
       "    'LSI': [118],\n",
       "    'model.': [119]}}},\n",
       " {'paper_name': 'natural language processing (almost) from scratch.',\n",
       "  'citation': 2313,\n",
       "  'abstract': {'IndexLength': 98,\n",
       "   'InvertedIndex': {'We': [0],\n",
       "    'propose': [1],\n",
       "    'a': [2, 44, 82, 86],\n",
       "    'unified': [3],\n",
       "    'neural': [4],\n",
       "    'network': [5],\n",
       "    'architecture': [6],\n",
       "    'and': [7, 27, 41, 94],\n",
       "    'learning': [8],\n",
       "    'algorithm': [9],\n",
       "    'that': [10],\n",
       "    'can': [11],\n",
       "    'be': [12],\n",
       "    'applied': [13],\n",
       "    'to': [14, 37],\n",
       "    'various': [15],\n",
       "    'natural': [16],\n",
       "    'language': [17],\n",
       "    'processing': [18],\n",
       "    'tasks': [19],\n",
       "    'including': [20],\n",
       "    'part-of-speech': [21],\n",
       "    'tagging,': [22],\n",
       "    'chunking,': [23],\n",
       "    'named': [24],\n",
       "    'entity': [25],\n",
       "    'recognition,': [26],\n",
       "    'semantic': [28],\n",
       "    'role': [29],\n",
       "    'labeling.': [30],\n",
       "    'This': [31, 76],\n",
       "    'versatility': [32],\n",
       "    'is': [33, 78],\n",
       "    'achieved': [34],\n",
       "    'by': [35],\n",
       "    'trying': [36],\n",
       "    'avoid': [38],\n",
       "    'task-specific': [39],\n",
       "    'engineering': [40],\n",
       "    'therefore': [42],\n",
       "    'disregarding': [43],\n",
       "    'lot': [45],\n",
       "    'of': [46, 50, 68, 71],\n",
       "    'prior': [47],\n",
       "    'knowledge.': [48],\n",
       "    'Instead': [49],\n",
       "    'exploiting': [51],\n",
       "    'man-made': [52],\n",
       "    'input': [53],\n",
       "    'features': [54],\n",
       "    'carefully': [55],\n",
       "    'optimized': [56],\n",
       "    'for': [57, 84],\n",
       "    'each': [58],\n",
       "    'task,': [59],\n",
       "    'our': [60],\n",
       "    'system': [61, 90],\n",
       "    'learns': [62],\n",
       "    'internal': [63],\n",
       "    'representations': [64],\n",
       "    'on': [65],\n",
       "    'the': [66],\n",
       "    'basis': [67, 83],\n",
       "    'vast': [69],\n",
       "    'amounts': [70],\n",
       "    'mostly': [72],\n",
       "    'unlabeled': [73],\n",
       "    'training': [74],\n",
       "    'data.': [75],\n",
       "    'work': [77],\n",
       "    'then': [79],\n",
       "    'used': [80],\n",
       "    'as': [81],\n",
       "    'building': [85],\n",
       "    'freely': [87],\n",
       "    'available': [88],\n",
       "    'tagging': [89],\n",
       "    'with': [91],\n",
       "    'good': [92],\n",
       "    'performance': [93],\n",
       "    'minimal': [95],\n",
       "    'computational': [96],\n",
       "    'requirements.': [97]}}},\n",
       " {'paper_name': 'indexing by latent semantic analysis.',\n",
       "  'citation': 8845,\n",
       "  'abstract': {'IndexLength': 125,\n",
       "   'InvertedIndex': {'A': [0],\n",
       "    'new': [1],\n",
       "    'method': [2, 119],\n",
       "    'for': [3, 120],\n",
       "    'automatic': [4, 118],\n",
       "    'indexing': [5],\n",
       "    'and': [6, 105],\n",
       "    'retrieval': [7, 121],\n",
       "    'is': [8, 12, 50, 61],\n",
       "    'described.': [9],\n",
       "    'The': [10, 46],\n",
       "    'approach': [11],\n",
       "    'to': [13, 31, 122],\n",
       "    'take': [14],\n",
       "    'advantage': [15],\n",
       "    'of': [16, 23, 35, 41, 66, 90, 103],\n",
       "    'implicit': [17],\n",
       "    'higher-order': [18],\n",
       "    'structure': [19],\n",
       "    'in': [20, 29, 44, 53],\n",
       "    'the': [21, 33, 39, 73],\n",
       "    'association': [22],\n",
       "    'terms': [24, 42],\n",
       "    'with': [25, 107],\n",
       "    'documents': [26, 37, 106],\n",
       "    '(“semantic': [27],\n",
       "    'structure”)': [28],\n",
       "    'order': [30],\n",
       "    'improve': [32],\n",
       "    'detection': [34],\n",
       "    'relevant': [36],\n",
       "    'on': [38],\n",
       "    'basis': [40],\n",
       "    'found': [43],\n",
       "    'queries.': [45],\n",
       "    'particular': [47],\n",
       "    'technique': [48],\n",
       "    'used': [49],\n",
       "    'singular-value': [51],\n",
       "    'decomposition,': [52],\n",
       "    'which': [54, 72],\n",
       "    'a': [55, 64],\n",
       "    'large': [56],\n",
       "    'term': [57],\n",
       "    'by': [58, 79, 85],\n",
       "    'document': [59],\n",
       "    'matrix': [60, 75],\n",
       "    'decomposed': [62],\n",
       "    'into': [63],\n",
       "    'set': [65],\n",
       "    'ca.': [67, 86],\n",
       "    '100': [68, 87],\n",
       "    'orthogonal': [69],\n",
       "    'factors': [70],\n",
       "    'from': [71, 100],\n",
       "    'original': [74],\n",
       "    'can': [76],\n",
       "    'be': [77, 123],\n",
       "    'approximated': [78],\n",
       "    'linear': [80],\n",
       "    'combination.': [81],\n",
       "    'Documents': [82],\n",
       "    'are': [83, 94, 111],\n",
       "    'represented': [84, 95],\n",
       "    'item': [88],\n",
       "    'vectors': [89, 98],\n",
       "    'factor': [91],\n",
       "    'weights.': [92],\n",
       "    'Queries': [93],\n",
       "    'as': [96],\n",
       "    'pseudo-document': [97],\n",
       "    'formed': [99],\n",
       "    'weighted': [101],\n",
       "    'combinations': [102],\n",
       "    'terms,': [104],\n",
       "    'supra-threshold': [108],\n",
       "    'cosine': [109],\n",
       "    'values': [110],\n",
       "    'returned.': [112],\n",
       "    'initial': [113],\n",
       "    'tests': [114],\n",
       "    'find': [115],\n",
       "    'this': [116],\n",
       "    'completely': [117],\n",
       "    'promising.': [124]}}},\n",
       " {'paper_name': 'scalable stacking and learning for building deep architectures.',\n",
       "  'citation': 112,\n",
       "  'abstract': {'IndexLength': 139,\n",
       "   'InvertedIndex': {'Deep': [0, 24],\n",
       "    'Neural': [1],\n",
       "    'Networks': [2],\n",
       "    '(DNNs)': [3],\n",
       "    'have': [4],\n",
       "    'shown': [5],\n",
       "    'remarkable': [6],\n",
       "    'success': [7],\n",
       "    'in': [8, 49, 58, 74, 120, 127],\n",
       "    'pattern': [9],\n",
       "    'recognition': [10],\n",
       "    'tasks.': [11],\n",
       "    'However,': [12],\n",
       "    'parallelizing': [13, 33],\n",
       "    'DNN': [14],\n",
       "    'training': [15, 84, 99],\n",
       "    'across': [16],\n",
       "    'computers': [17],\n",
       "    'has': [18],\n",
       "    'been': [19],\n",
       "    'difficult.': [20],\n",
       "    'We': [21],\n",
       "    'present': [22],\n",
       "    'the': [23, 30, 66, 75, 93, 98, 105, 115, 137],\n",
       "    'Stacking': [25],\n",
       "    'Network': [26],\n",
       "    '(DSN),': [27],\n",
       "    'which': [28],\n",
       "    'overcomes': [29],\n",
       "    'problem': [31, 57],\n",
       "    'of': [32, 44, 97],\n",
       "    'learning': [34, 56, 73, 117],\n",
       "    'algorithms': [35],\n",
       "    'for': [36],\n",
       "    'deep': [37, 51],\n",
       "    'architectures.': [38],\n",
       "    'The': [39],\n",
       "    'DSN': [40, 76, 116],\n",
       "    'provides': [41],\n",
       "    'a': [42, 54],\n",
       "    'method': [43],\n",
       "    'stacking': [45],\n",
       "    'simple': [46],\n",
       "    'processing': [47],\n",
       "    'modules': [48],\n",
       "    'buiding': [50],\n",
       "    'architectures,': [52],\n",
       "    'with': [53],\n",
       "    'convex': [55],\n",
       "    'each': [59],\n",
       "    'module.': [60],\n",
       "    'Additional': [61],\n",
       "    'fine': [62],\n",
       "    'tuning': [63],\n",
       "    'further': [64],\n",
       "    'improves': [65],\n",
       "    'DSN,': [67],\n",
       "    'while': [68],\n",
       "    'introducing': [69],\n",
       "    'minor': [70],\n",
       "    'non-convexity.': [71],\n",
       "    'Full': [72],\n",
       "    'is': [77, 123],\n",
       "    'batch-mode,': [78],\n",
       "    'making': [79],\n",
       "    'it': [80, 130],\n",
       "    'amenable': [81],\n",
       "    'to': [82],\n",
       "    'parallel': [83],\n",
       "    'over': [85, 92],\n",
       "    'many': [86],\n",
       "    'machines': [87],\n",
       "    'and': [88, 108],\n",
       "    'thus': [89],\n",
       "    'be': [90],\n",
       "    'scalable': [91],\n",
       "    'potentially': [94],\n",
       "    'huge': [95],\n",
       "    'size': [96],\n",
       "    'data.': [100],\n",
       "    'Experimental': [101],\n",
       "    'results': [102],\n",
       "    'on': [103],\n",
       "    'both': [104],\n",
       "    'MNIST': [106],\n",
       "    '(image)': [107],\n",
       "    'TIMIT': [109],\n",
       "    '(speech)': [110],\n",
       "    'classification': [111, 134],\n",
       "    'tasks': [112],\n",
       "    'demonstrate': [113],\n",
       "    'that': [114],\n",
       "    'algorithm': [118],\n",
       "    'developed': [119],\n",
       "    'this': [121],\n",
       "    'work': [122],\n",
       "    'not': [124],\n",
       "    'only': [125],\n",
       "    'parallelizable': [126],\n",
       "    'implementation': [128],\n",
       "    'but': [129],\n",
       "    'also': [131],\n",
       "    'attains': [132],\n",
       "    'higher': [133],\n",
       "    'accuracy': [135],\n",
       "    'than': [136],\n",
       "    'DNN.': [138]}}},\n",
       " {'paper_name': 'posterior regularization for structured latent variable models.',\n",
       "  'citation': 248,\n",
       "  'abstract': {'IndexLength': 122,\n",
       "   'InvertedIndex': {'We': [0, 75],\n",
       "    'present': [1, 76],\n",
       "    'posterior': [2, 21, 52, 83],\n",
       "    'regularization,': [3],\n",
       "    'a': [4, 90],\n",
       "    'probabilistic': [5, 24],\n",
       "    'framework': [6, 13],\n",
       "    'for': [7, 80],\n",
       "    'structured,': [8],\n",
       "    'weakly': [9],\n",
       "    'supervised': [10],\n",
       "    'learning.': [11],\n",
       "    'Our': [12],\n",
       "    'efficiently': [14],\n",
       "    'incorporates': [15],\n",
       "    'indirect': [16],\n",
       "    'supervision': [17],\n",
       "    'via': [18],\n",
       "    'constraints': [19, 39, 71, 95],\n",
       "    'on': [20, 50, 89],\n",
       "    'distributions': [22],\n",
       "    'of': [23, 37, 54, 64, 93],\n",
       "    'models': [25],\n",
       "    'with': [26, 82],\n",
       "    'latent': [27, 55],\n",
       "    'variables.': [28],\n",
       "    'Posterior': [29],\n",
       "    'regularization': [30, 49, 84],\n",
       "    'separates': [31],\n",
       "    'model': [32, 67],\n",
       "    'complexity': [33, 36],\n",
       "    'from': [34],\n",
       "    'the': [35, 51, 61, 65],\n",
       "    'structural': [38, 94],\n",
       "    'it': [40],\n",
       "    'is': [41],\n",
       "    'desired': [42, 70],\n",
       "    'to': [43],\n",
       "    'satisfy.': [44],\n",
       "    'By': [45],\n",
       "    'directly': [46],\n",
       "    'imposing': [47],\n",
       "    'decomposable': [48],\n",
       "    'moments': [53],\n",
       "    'variables': [56],\n",
       "    'during': [57],\n",
       "    'learning,': [58, 110],\n",
       "    'we': [59],\n",
       "    'retain': [60],\n",
       "    'computational': [62],\n",
       "    'efficiency': [63],\n",
       "    'unconstrained': [66],\n",
       "    'while': [68],\n",
       "    'ensuring': [69],\n",
       "    'hold': [72],\n",
       "    'in': [73, 103],\n",
       "    'expectation.': [74],\n",
       "    'an': [77],\n",
       "    'efficient': [78],\n",
       "    'algorithm': [79],\n",
       "    'learning': [81],\n",
       "    'and': [85, 100, 118],\n",
       "    'illustrate': [86],\n",
       "    'its': [87],\n",
       "    'versatility': [88],\n",
       "    'diverse': [91],\n",
       "    'set': [92],\n",
       "    'such': [96],\n",
       "    'as': [97],\n",
       "    'bijectivity,': [98],\n",
       "    'symmetry': [99],\n",
       "    'group': [101],\n",
       "    'sparsity': [102],\n",
       "    'several': [104],\n",
       "    'large': [105],\n",
       "    'scale': [106],\n",
       "    'experiments,': [107],\n",
       "    'including': [108],\n",
       "    'multi-view': [109],\n",
       "    'cross-lingual': [111],\n",
       "    'dependency': [112],\n",
       "    'grammar': [113],\n",
       "    'induction,': [114, 117],\n",
       "    'unsupervised': [115],\n",
       "    'part-of-speech': [116],\n",
       "    'bitext': [119],\n",
       "    'word': [120],\n",
       "    'alignment.': [121]}}},\n",
       " {'paper_name': 'training mrf-based translation models using gradient ascent.',\n",
       "  'citation': 12,\n",
       "  'abstract': {'IndexLength': 124,\n",
       "   'InvertedIndex': {'This': [0],\n",
       "    'paper': [1],\n",
       "    'presents': [2],\n",
       "    'a': [3, 23, 39, 70, 110, 118],\n",
       "    'general,': [4],\n",
       "    'statistical': [5, 73],\n",
       "    'framework': [6],\n",
       "    'for': [7, 18],\n",
       "    'modeling': [8],\n",
       "    'phrase': [9, 24],\n",
       "    'translation': [10, 75, 91, 114],\n",
       "    'via': [11],\n",
       "    'Markov': [12, 101],\n",
       "    'random': [13, 102],\n",
       "    'fields.': [14],\n",
       "    'The': [15, 31, 62],\n",
       "    'model': [16, 35, 63, 104],\n",
       "    'allows': [17],\n",
       "    'arbituary': [19],\n",
       "    'features': [20],\n",
       "    'extracted': [21],\n",
       "    'from': [22],\n",
       "    'pair': [25],\n",
       "    'to': [26, 66, 117],\n",
       "    'be': [27, 67],\n",
       "    'incorporated': [28],\n",
       "    'as': [29, 58],\n",
       "    'evidence.': [30],\n",
       "    'parameters': [32],\n",
       "    'of': [33, 109, 120],\n",
       "    'the': [34, 59, 82, 100, 107],\n",
       "    'are': [36],\n",
       "    'estimated': [37],\n",
       "    'using': [38],\n",
       "    'large-scale': [40],\n",
       "    'discriminative': [41],\n",
       "    'training': [42],\n",
       "    'approach': [43],\n",
       "    'that': [44, 98],\n",
       "    'is': [45, 64, 86],\n",
       "    'based': [46, 55],\n",
       "    'on': [47, 88],\n",
       "    'stochastic': [48],\n",
       "    'gradient': [49],\n",
       "    'ascent': [50],\n",
       "    'and': [51, 94],\n",
       "    'an': [52],\n",
       "    'N-best': [53],\n",
       "    'list': [54],\n",
       "    'expected': [56],\n",
       "    'BLEU': [57, 122],\n",
       "    'objective': [60],\n",
       "    'function.': [61],\n",
       "    'easy': [65],\n",
       "    'incoporated': [68],\n",
       "    'into': [69],\n",
       "    'standard': [71],\n",
       "    'phrase-based': [72, 112],\n",
       "    'machine': [74, 113],\n",
       "    'system,': [76, 115],\n",
       "    'requiring': [77],\n",
       "    'no': [78],\n",
       "    'code': [79],\n",
       "    'change': [80],\n",
       "    'in': [81],\n",
       "    'runtime': [83],\n",
       "    'engine.': [84],\n",
       "    'Evaluation': [85],\n",
       "    'performed': [87],\n",
       "    'two': [89],\n",
       "    'Europarl': [90],\n",
       "    'tasks,': [92],\n",
       "    'GermanEnglish': [93],\n",
       "    'French-English.': [95],\n",
       "    'Results': [96],\n",
       "    'show': [97],\n",
       "    'incoporating': [99],\n",
       "    'field': [103],\n",
       "    'significantly': [105],\n",
       "    'improves': [106],\n",
       "    'performance': [108],\n",
       "    'state-of-the-art': [111],\n",
       "    'leading': [116],\n",
       "    'gain': [119],\n",
       "    '0.8-1.3': [121],\n",
       "    'points.': [123]}}},\n",
       " {'paper_name': 'clickthrough-based latent semantic models for web search.',\n",
       "  'citation': 59,\n",
       "  'abstract': {'IndexLength': 229,\n",
       "   'InvertedIndex': {'This': [0],\n",
       "    'paper': [1],\n",
       "    'presents': [2],\n",
       "    'two': [3, 54],\n",
       "    'new': [4],\n",
       "    'document': [5],\n",
       "    'ranking': [6],\n",
       "    'models': [7, 57, 202],\n",
       "    'for': [8, 41, 77, 198],\n",
       "    'Web': [9, 207],\n",
       "    'search': [10, 208],\n",
       "    'based': [11],\n",
       "    'upon': [12],\n",
       "    'the': [13,\n",
       "     19,\n",
       "     34,\n",
       "     37,\n",
       "     70,\n",
       "     81,\n",
       "     84,\n",
       "     91,\n",
       "     105,\n",
       "     115,\n",
       "     129,\n",
       "     141,\n",
       "     163,\n",
       "     177,\n",
       "     186,\n",
       "     189,\n",
       "     206],\n",
       "    'methods': [14],\n",
       "    'of': [15, 36, 46, 83, 90, 191],\n",
       "    'semantic': [16, 56, 94, 119, 179],\n",
       "    'representation': [17, 95],\n",
       "    'and': [18, 99, 110, 138, 168, 188],\n",
       "    'statistical': [20],\n",
       "    'translation-based': [21],\n",
       "    'approach': [22],\n",
       "    'to': [23, 33, 150],\n",
       "    'information': [24],\n",
       "    'retrieval': [25],\n",
       "    '(IR).': [26],\n",
       "    'Assuming': [27],\n",
       "    'that': [28, 42, 107, 162, 184, 199, 218],\n",
       "    'a': [29, 65, 78, 87, 108, 124, 166, 211],\n",
       "    'query': [30, 79, 85, 109, 167, 187],\n",
       "    'is': [31, 64, 96, 123, 148, 158, 181],\n",
       "    'parallel': [32],\n",
       "    'titles': [35, 113, 190],\n",
       "    'documents': [38, 76, 193],\n",
       "    'clicked': [39],\n",
       "    'on': [40, 205],\n",
       "    'query,': [43],\n",
       "    'large': [44],\n",
       "    'amounts': [45],\n",
       "    'query-title': [47, 102],\n",
       "    'pairs': [48],\n",
       "    'are': [49, 58, 203, 227],\n",
       "    'constructed': [50],\n",
       "    'from': [51, 60, 101, 152],\n",
       "    'clickthrough': [52],\n",
       "    'data;': [53],\n",
       "    'latent': [55],\n",
       "    'learned': [59, 100, 159],\n",
       "    'this': [61],\n",
       "    'data.': [62],\n",
       "    'One': [63],\n",
       "    'bilingual': [66],\n",
       "    'topic': [67],\n",
       "    'model': [68, 127],\n",
       "    'within': [69, 128],\n",
       "    'language': [71, 97],\n",
       "    'modeling': [72, 132],\n",
       "    'framework.': [73, 133],\n",
       "    'It': [74],\n",
       "    'ranks': [75],\n",
       "    'by': [80],\n",
       "    'likelihood': [82],\n",
       "    'being': [86],\n",
       "    'semantics-based': [88],\n",
       "    'translation': [89],\n",
       "    'documents.': [92],\n",
       "    'The': [93, 121],\n",
       "    'independent': [98],\n",
       "    'pairs,': [103],\n",
       "    'with': [104],\n",
       "    'assumption': [106],\n",
       "    'its': [111, 139, 169],\n",
       "    'paired': [112, 170],\n",
       "    'share': [114],\n",
       "    'same': [116],\n",
       "    'distribution': [117],\n",
       "    'over': [118],\n",
       "    'topics.': [120],\n",
       "    'other': [122, 192],\n",
       "    'discriminative': [125],\n",
       "    'projection': [126, 142],\n",
       "    'vector': [130],\n",
       "    'space': [131],\n",
       "    'Unlike': [134],\n",
       "    'Latent': [135],\n",
       "    'Semantic': [136],\n",
       "    'Analysis': [137],\n",
       "    'variants,': [140],\n",
       "    'matrix': [143],\n",
       "    'in': [144, 176],\n",
       "    'our': [145],\n",
       "    'model,': [146],\n",
       "    'which': [147, 194, 226],\n",
       "    'used': [149],\n",
       "    'map': [151],\n",
       "    'term': [153],\n",
       "    'vectors': [154, 175],\n",
       "    'into': [155],\n",
       "    'sematic': [156],\n",
       "    'space,': [157, 180],\n",
       "    'discriminatively': [160],\n",
       "    'such': [161],\n",
       "    'distance': [164],\n",
       "    'between': [165, 185],\n",
       "    'title,': [171],\n",
       "    'both': [172],\n",
       "    'represented': [173],\n",
       "    'as': [174],\n",
       "    'projected': [178],\n",
       "    'smaller': [182],\n",
       "    'than': [183],\n",
       "    'have': [195],\n",
       "    'no': [196],\n",
       "    'clicks': [197],\n",
       "    'query.': [200],\n",
       "    'These': [201],\n",
       "    'evaluated': [204],\n",
       "    'task': [209],\n",
       "    'using': [210],\n",
       "    'real': [212],\n",
       "    'world': [213],\n",
       "    'data': [214],\n",
       "    'set.': [215],\n",
       "    'Results': [216],\n",
       "    'show': [217],\n",
       "    'they': [219],\n",
       "    'significantly': [220],\n",
       "    'outperform': [221],\n",
       "    'their': [222],\n",
       "    'corresponding': [223],\n",
       "    'baseline': [224],\n",
       "    'models,': [225],\n",
       "    'state-of-the-art.': [228]}}},\n",
       " {'paper_name': 'maximum expected bleu training of phrase and lexicon translation models.',\n",
       "  'citation': 50,\n",
       "  'abstract': {'IndexLength': 112,\n",
       "   'InvertedIndex': {'This': [0],\n",
       "    'paper': [1],\n",
       "    'proposes': [2],\n",
       "    'a': [3, 20, 46, 78, 84],\n",
       "    'new': [4],\n",
       "    'discriminative': [5],\n",
       "    'training': [6],\n",
       "    'method': [7, 98],\n",
       "    'in': [8, 24],\n",
       "    'constructing': [9],\n",
       "    'phrase': [10, 57],\n",
       "    'and': [11, 41, 58],\n",
       "    'lexicon': [12, 59],\n",
       "    'translation': [13, 60, 87, 103],\n",
       "    'models.': [14],\n",
       "    'In': [15, 89],\n",
       "    'order': [16],\n",
       "    'to': [17, 62, 77],\n",
       "    'reliably': [18],\n",
       "    'learn': [19],\n",
       "    'myriad': [21],\n",
       "    'of': [22, 108],\n",
       "    'parameters': [23],\n",
       "    'these': [25],\n",
       "    'models,': [26],\n",
       "    'we': [27, 52],\n",
       "    'propose': [28],\n",
       "    'an': [29],\n",
       "    'expected': [30],\n",
       "    'BLEU': [31, 80],\n",
       "    'score-based': [32],\n",
       "    'utility': [33],\n",
       "    'function': [34],\n",
       "    'with': [35],\n",
       "    'KL': [36],\n",
       "    'regularization': [37],\n",
       "    'as': [38],\n",
       "    'the': [39, 43, 65, 72, 96, 100, 106],\n",
       "    'objective,': [40],\n",
       "    'train': [42],\n",
       "    'models': [44],\n",
       "    'on': [45, 71, 105],\n",
       "    'large': [47],\n",
       "    'parallel': [48],\n",
       "    'dataset.': [49],\n",
       "    'For': [50],\n",
       "    'training,': [51],\n",
       "    'derive': [53],\n",
       "    'growth': [54],\n",
       "    'transformations': [55],\n",
       "    'for': [56],\n",
       "    'probabilities': [61],\n",
       "    'iteratively': [63],\n",
       "    'improve': [64],\n",
       "    'objective.': [66],\n",
       "    'The': [67],\n",
       "    'proposed': [68, 97],\n",
       "    'method,': [69],\n",
       "    'evaluated': [70],\n",
       "    'Europarl': [73],\n",
       "    'German-to-English': [74],\n",
       "    'dataset,': [75],\n",
       "    'leads': [76],\n",
       "    '1.1': [79],\n",
       "    'point': [81],\n",
       "    'improvement': [82],\n",
       "    'over': [83],\n",
       "    'state-of-the-art': [85],\n",
       "    'baseline': [86],\n",
       "    'system.': [88],\n",
       "    'IWSLT': [90],\n",
       "    '2011': [91],\n",
       "    'Benchmark,': [92],\n",
       "    'our': [93],\n",
       "    'system': [94],\n",
       "    'using': [95],\n",
       "    'achieves': [99],\n",
       "    'best': [101],\n",
       "    'Chinese-to-English': [102],\n",
       "    'result': [104],\n",
       "    'task': [107],\n",
       "    'translating': [109],\n",
       "    'TED': [110],\n",
       "    'talks.': [111]}}},\n",
       " {'paper_name': 'probabilistic latent semantic indexing.',\n",
       "  'citation': 3328,\n",
       "  'abstract': {'IndexLength': 122,\n",
       "   'InvertedIndex': {'Probabilistic': [0],\n",
       "    'Latent': [1, 63],\n",
       "    'Semantic': [2, 64],\n",
       "    'Indexing': [3, 65],\n",
       "    'is': [4, 13, 46],\n",
       "    'a': [5, 16, 29, 36, 75, 81, 89],\n",
       "    'novel': [6],\n",
       "    'approach': [7],\n",
       "    'to': [8, 48, 61, 119],\n",
       "    'automated': [9],\n",
       "    'document': [10],\n",
       "    'indexing': [11],\n",
       "    'which': [12],\n",
       "    'based': [14],\n",
       "    'on': [15, 88],\n",
       "    'statistical': [17, 77],\n",
       "    'latent': [18],\n",
       "    'class': [19],\n",
       "    'model': [20, 45],\n",
       "    'for': [21],\n",
       "    'factor': [22],\n",
       "    'analysis': [23],\n",
       "    'of': [24, 32, 38, 91, 112],\n",
       "    'count': [25],\n",
       "    'data.': [26],\n",
       "    'Fitted': [27],\n",
       "    'from': [28],\n",
       "    'training': [30],\n",
       "    'corpus': [31],\n",
       "    'text': [33],\n",
       "    'documents': [34],\n",
       "    'by': [35, 67],\n",
       "    'generalization': [37],\n",
       "    'the': [39, 43, 71, 110],\n",
       "    'Expectation': [40],\n",
       "    'Maximization': [41],\n",
       "    'algorithm,': [42],\n",
       "    'utilized': [44],\n",
       "    'able': [47],\n",
       "    'deal': [49],\n",
       "    'with': [50, 56, 114],\n",
       "    'domain{specific': [51],\n",
       "    'synonymy': [52],\n",
       "    'as': [53, 55, 103, 105],\n",
       "    'well': [54, 104],\n",
       "    'polysemous': [57],\n",
       "    'words.': [58],\n",
       "    'In': [59, 108],\n",
       "    'contrast': [60],\n",
       "    'standard': [62],\n",
       "    '(LSI)': [66],\n",
       "    'Singular': [68],\n",
       "    'Value': [69],\n",
       "    'Decomposition,': [70],\n",
       "    'probabilistic': [72],\n",
       "    'variant': [73],\n",
       "    'has': [74, 117],\n",
       "    'solid': [76],\n",
       "    'foundation': [78],\n",
       "    'and': [79],\n",
       "    'defines': [80],\n",
       "    'proper': [82],\n",
       "    'generative': [83],\n",
       "    'data': [84],\n",
       "    'model.': [85],\n",
       "    'Retrieval': [86],\n",
       "    'experiments': [87],\n",
       "    'number': [90],\n",
       "    'test': [92],\n",
       "    'collections': [93],\n",
       "    'indicate': [94],\n",
       "    'substantial': [95],\n",
       "    'performance': [96],\n",
       "    'gains': [97],\n",
       "    'over': [98, 106],\n",
       "    'direct': [99],\n",
       "    'term': [100],\n",
       "    'matching': [101],\n",
       "    'methods': [102],\n",
       "    'LSI.': [107],\n",
       "    'particular,': [109],\n",
       "    'combination': [111],\n",
       "    'models': [113],\n",
       "    'different': [115],\n",
       "    'dimensionalities': [116],\n",
       "    'proven': [118],\n",
       "    'be': [120],\n",
       "    'advantageous.': [121]}}},\n",
       " {'paper_name': 'learning deep structured semantic models for web search using clickthrough data. in cikm.',\n",
       "  'citation': 403,\n",
       "  'abstract': {'IndexLength': 175,\n",
       "   'InvertedIndex': {'Latent': [0],\n",
       "    'semantic': [1, 17, 36, 73, 120, 158],\n",
       "    'models,': [2, 159],\n",
       "    'such': [3, 130],\n",
       "    'as': [4, 64],\n",
       "    'LSA,': [5],\n",
       "    'intend': [6],\n",
       "    'to': [7, 11, 29, 99, 115, 122, 168],\n",
       "    'map': [8],\n",
       "    'a': [9, 31, 39, 48, 56, 59, 88, 107, 138, 144],\n",
       "    'query': [10, 60, 89],\n",
       "    'its': [12],\n",
       "    'relevant': [13],\n",
       "    'documents': [14, 46, 86],\n",
       "    'at': [15],\n",
       "    'the': [16, 53, 65, 80, 84, 91, 165, 169],\n",
       "    'level': [18],\n",
       "    'where': [19, 52],\n",
       "    'keyword-based': [20],\n",
       "    'matching': [21],\n",
       "    'often': [22],\n",
       "    'fails.': [23],\n",
       "    'In': [24],\n",
       "    'this': [25, 173],\n",
       "    'study': [26],\n",
       "    'we': [27, 104],\n",
       "    'strive': [28],\n",
       "    'develop': [30],\n",
       "    'series': [32],\n",
       "    'of': [33, 55, 83],\n",
       "    'new': [34, 133],\n",
       "    'latent': [35, 157],\n",
       "    'models': [37, 74, 97, 121, 134],\n",
       "    'with': [38],\n",
       "    'deep': [40, 71],\n",
       "    'structure': [41],\n",
       "    'that': [42, 150],\n",
       "    'project': [43],\n",
       "    'queries': [44],\n",
       "    'and': [45],\n",
       "    'into': [47],\n",
       "    'common': [49, 128],\n",
       "    'low-dimensional': [50],\n",
       "    'space': [51],\n",
       "    'relevance': [54],\n",
       "    'document': [57, 140],\n",
       "    'given': [58, 87],\n",
       "    'is': [61, 113],\n",
       "    'readily': [62],\n",
       "    'computed': [63],\n",
       "    'distance': [66],\n",
       "    'between': [67],\n",
       "    'them.': [68],\n",
       "    'The': [69, 132],\n",
       "    'proposed': [70],\n",
       "    'structured': [72],\n",
       "    'are': [75, 127, 135],\n",
       "    'discriminatively': [76],\n",
       "    'trained': [77],\n",
       "    'by': [78],\n",
       "    'maximizing': [79],\n",
       "    'conditional': [81],\n",
       "    'likelihood': [82],\n",
       "    'clicked': [85],\n",
       "    'using': [90, 143],\n",
       "    'clickthrough': [92],\n",
       "    'data.': [93],\n",
       "    'To': [94],\n",
       "    'make': [95],\n",
       "    'our': [96, 119, 151],\n",
       "    'applicable': [98],\n",
       "    'large-scale': [100],\n",
       "    'Web': [101, 139],\n",
       "    'search': [102],\n",
       "    'applications,': [103],\n",
       "    'also': [105],\n",
       "    'use': [106],\n",
       "    'technique': [108],\n",
       "    'called': [109],\n",
       "    'word': [110],\n",
       "    'hashing,': [111],\n",
       "    'which': [112, 126, 160],\n",
       "    'shown': [114],\n",
       "    'effectively': [116],\n",
       "    'scale': [117],\n",
       "    'up': [118],\n",
       "    'handle': [123],\n",
       "    'large': [124],\n",
       "    'vocabularies': [125],\n",
       "    'in': [129, 164, 172],\n",
       "    'tasks.': [131],\n",
       "    'evaluated': [136],\n",
       "    'on': [137],\n",
       "    'ranking': [141],\n",
       "    'task': [142],\n",
       "    'real-world': [145],\n",
       "    'data': [146],\n",
       "    'set.': [147],\n",
       "    'Results': [148],\n",
       "    'show': [149],\n",
       "    'best': [152],\n",
       "    'model': [153],\n",
       "    'significantly': [154],\n",
       "    'outperforms': [155],\n",
       "    'other': [156],\n",
       "    'were': [161],\n",
       "    'considered': [162],\n",
       "    'state-of-the-art': [163],\n",
       "    'performance': [166],\n",
       "    'prior': [167],\n",
       "    'work': [170],\n",
       "    'presented': [171],\n",
       "    'paper.': [174]}}},\n",
       " {'paper_name': 'recurrent continuous translation models.',\n",
       "  'citation': 411,\n",
       "  'abstract': {'IndexLength': 138,\n",
       "   'InvertedIndex': {'We': [0],\n",
       "    'introduce': [1],\n",
       "    'a': [2, 39, 42, 53, 68, 82, 129],\n",
       "    'class': [3],\n",
       "    'of': [4, 47, 96, 116, 136],\n",
       "    'probabilistic': [5],\n",
       "    'continuous': [6, 19],\n",
       "    'translation': [7, 34, 49, 99],\n",
       "    'models': [8, 37, 80],\n",
       "    'called': [9],\n",
       "    'Recurrent': [10, 55],\n",
       "    'Continuous': [11],\n",
       "    'Translation': [12],\n",
       "    'Models': [13],\n",
       "    'that': [14, 78, 89, 95, 104, 126],\n",
       "    'are': [15, 106],\n",
       "    'purely': [16],\n",
       "    'based': [17],\n",
       "    'on': [18, 30, 61],\n",
       "    'representations': [20],\n",
       "    'for': [21],\n",
       "    'words,': [22],\n",
       "    'phrases': [23],\n",
       "    'and': [24, 26, 41, 114],\n",
       "    'sentences': [25],\n",
       "    'do': [27],\n",
       "    'not': [28],\n",
       "    'rely': [29],\n",
       "    'alignments': [31],\n",
       "    'or': [32],\n",
       "    'phrasal': [33],\n",
       "    'units.': [35],\n",
       "    'The': [36, 45],\n",
       "    'have': [38],\n",
       "    'generation': [40, 46],\n",
       "    'conditioning': [43, 60],\n",
       "    'aspect.': [44],\n",
       "    'the': [48, 59, 62, 110, 117],\n",
       "    'is': [50, 65, 90],\n",
       "    'modelled': [51, 66],\n",
       "    'with': [52, 67, 84],\n",
       "    'target': [54],\n",
       "    'Language': [56],\n",
       "    'Model,': [57],\n",
       "    'whereas': [58],\n",
       "    'source': [63, 118],\n",
       "    'sentence': [64, 119],\n",
       "    'Convolutional': [69],\n",
       "    'Sentence': [70],\n",
       "    'Model.': [71],\n",
       "    'Through': [72],\n",
       "    'various': [73],\n",
       "    'experiments,': [74],\n",
       "    'we': [75, 102, 124],\n",
       "    'show': [76, 103, 125],\n",
       "    'first': [77],\n",
       "    'our': [79],\n",
       "    'obtain': [81],\n",
       "    'perplexity': [83],\n",
       "    'respect': [85],\n",
       "    'to': [86, 109],\n",
       "    'gold': [87],\n",
       "    'translations': [88],\n",
       "    '>': [91],\n",
       "    '43%': [92],\n",
       "    'lower': [93],\n",
       "    'than': [94],\n",
       "    'stateof-the-art': [97],\n",
       "    'alignment-based': [98],\n",
       "    'models.': [100],\n",
       "    'Secondly,': [101],\n",
       "    'they': [105, 127],\n",
       "    'remarkably': [107],\n",
       "    'sensitive': [108],\n",
       "    'word': [111],\n",
       "    'order,': [112],\n",
       "    'syntax,': [113],\n",
       "    'meaning': [115],\n",
       "    'despite': [120],\n",
       "    'lacking': [121],\n",
       "    'alignments.': [122],\n",
       "    'Finally': [123],\n",
       "    'match': [128],\n",
       "    'state-of-the-art': [130],\n",
       "    'system': [131],\n",
       "    'when': [132],\n",
       "    'rescoring': [133],\n",
       "    'n-best': [134],\n",
       "    'lists': [135],\n",
       "    'translations.': [137]}}},\n",
       " {'paper_name': 'moses: open source toolkit for statistical machine translation.',\n",
       "  'citation': 391,\n",
       "  'abstract': {'IndexLength': 60,\n",
       "   'InvertedIndex': {'We': [0],\n",
       "    'describe': [1],\n",
       "    'an': [2],\n",
       "    'open-source': [3],\n",
       "    'toolkit': [4, 41],\n",
       "    'for': [5, 15, 28, 49],\n",
       "    'statistical': [6],\n",
       "    'machine': [7],\n",
       "    'translation': [8, 29, 58],\n",
       "    'whose': [9],\n",
       "    'novel': [10],\n",
       "    'contributions': [11],\n",
       "    'are': [12],\n",
       "    '(a)': [13],\n",
       "    'support': [14],\n",
       "    'linguistically': [16],\n",
       "    'motivated': [17],\n",
       "    'factors,': [18],\n",
       "    '(b)': [19],\n",
       "    'confusion': [20],\n",
       "    'network': [21],\n",
       "    'decoding,': [22],\n",
       "    'and': [23, 31, 52],\n",
       "    '(c)': [24],\n",
       "    'efficient': [25],\n",
       "    'data': [26],\n",
       "    'formats': [27],\n",
       "    'models': [30],\n",
       "    'language': [32],\n",
       "    'models.': [33],\n",
       "    'In': [34],\n",
       "    'addition': [35],\n",
       "    'to': [36, 56],\n",
       "    'the': [37, 40, 54],\n",
       "    'SMT': [38],\n",
       "    'decoder,': [39],\n",
       "    'also': [42],\n",
       "    'includes': [43],\n",
       "    'a': [44],\n",
       "    'wide': [45],\n",
       "    'variety': [46],\n",
       "    'of': [47],\n",
       "    'tools': [48],\n",
       "    'training,': [50],\n",
       "    'tuning': [51],\n",
       "    'applying': [53],\n",
       "    'system': [55],\n",
       "    'many': [57],\n",
       "    'tasks.': [59]}}},\n",
       " {'paper_name': 'manual and automatic evaluation of machine translation between european languages.',\n",
       "  'citation': 169,\n",
       "  'abstract': {'IndexLength': 39,\n",
       "   'InvertedIndex': {'We': [0],\n",
       "    'evaluated': [1],\n",
       "    'machine': [2],\n",
       "    'translation': [3],\n",
       "    'performance': [4],\n",
       "    'for': [5],\n",
       "    'six': [6],\n",
       "    'European': [7],\n",
       "    'language': [8],\n",
       "    'pairs': [9],\n",
       "    'that': [10],\n",
       "    'participated': [11],\n",
       "    'in': [12],\n",
       "    'a': [13],\n",
       "    'shared': [14],\n",
       "    'task:': [15],\n",
       "    'translating': [16],\n",
       "    'French,': [17],\n",
       "    'German,': [18],\n",
       "    'Spanish': [19],\n",
       "    'texts': [20],\n",
       "    'to': [21],\n",
       "    'English': [22],\n",
       "    'and': [23, 33, 37],\n",
       "    'back.': [24],\n",
       "    'Evaluation': [25],\n",
       "    'was': [26],\n",
       "    'done': [27],\n",
       "    'automatically': [28],\n",
       "    'using': [29],\n",
       "    'the': [30],\n",
       "    'Bleu': [31],\n",
       "    'score': [32],\n",
       "    'manually': [34],\n",
       "    'on': [35],\n",
       "    'fluency': [36],\n",
       "    'adequacy.': [38]}}},\n",
       " {'paper_name': 'statistical phrase-based translation.',\n",
       "  'citation': 2562,\n",
       "  'abstract': {'IndexLength': 117,\n",
       "   'InvertedIndex': {'We': [0],\n",
       "    'propose': [1],\n",
       "    'a': [2, 29, 101],\n",
       "    'new': [3],\n",
       "    'phrase-based': [4, 20, 40],\n",
       "    'translation': [5, 21],\n",
       "    'model': [6],\n",
       "    'and': [7, 15, 37, 77, 90],\n",
       "    'decoding': [8],\n",
       "    'algorithm': [9],\n",
       "    'that': [10, 56],\n",
       "    'enables': [11],\n",
       "    'us': [12],\n",
       "    'to': [13, 34],\n",
       "    'evaluate': [14],\n",
       "    'compare': [16],\n",
       "    'several,': [17],\n",
       "    'previously': [18],\n",
       "    'proposed': [19],\n",
       "    'models.': [22, 44],\n",
       "    'Within': [23],\n",
       "    'our': [24, 115],\n",
       "    'framework,': [25],\n",
       "    'we': [26],\n",
       "    'carry': [27],\n",
       "    'out': [28],\n",
       "    'large': [30],\n",
       "    'number': [31],\n",
       "    'of': [32, 60, 71, 80, 114],\n",
       "    'experiments': [33],\n",
       "    'understand': [35],\n",
       "    'better': [36],\n",
       "    'explain': [38],\n",
       "    'why': [39],\n",
       "    'models': [41, 97],\n",
       "    'out-perform': [42],\n",
       "    'word-based': [43, 75],\n",
       "    'Our': [45],\n",
       "    'empirical': [46],\n",
       "    'results,': [47],\n",
       "    'which': [48],\n",
       "    'hold': [49],\n",
       "    'for': [50],\n",
       "    'all': [51],\n",
       "    'examined': [52],\n",
       "    'language': [53],\n",
       "    'pairs,': [54],\n",
       "    'suggest': [55],\n",
       "    'the': [57, 112],\n",
       "    'highest': [58],\n",
       "    'levels': [59],\n",
       "    'performance': [61, 113],\n",
       "    'can': [62],\n",
       "    'be': [63],\n",
       "    'obtained': [64],\n",
       "    'through': [65],\n",
       "    'relatively': [66],\n",
       "    'simple': [67],\n",
       "    'means:': [68],\n",
       "    'heuristic': [69],\n",
       "    'learning': [70, 84, 91],\n",
       "    'phrase': [72, 81],\n",
       "    'translations': [73],\n",
       "    'from': [74, 93],\n",
       "    'alignments': [76],\n",
       "    'lexical': [78],\n",
       "    'weighting': [79],\n",
       "    'translations.': [82],\n",
       "    'Surprisingly,': [83],\n",
       "    'phrases': [85, 92, 110],\n",
       "    'longer': [86],\n",
       "    'than': [87],\n",
       "    'three': [88],\n",
       "    'words': [89],\n",
       "    'high-accuracy': [94],\n",
       "    'word-level': [95],\n",
       "    'alignment': [96],\n",
       "    'does': [98],\n",
       "    'not': [99],\n",
       "    'have': [100],\n",
       "    'strong': [102],\n",
       "    'impact': [103],\n",
       "    'on': [104],\n",
       "    'performance.': [105],\n",
       "    'Learning': [106],\n",
       "    'only': [107],\n",
       "    'syntactically': [108],\n",
       "    'motivated': [109],\n",
       "    'degrades': [111],\n",
       "    'systems.': [116]}}},\n",
       " {'paper_name': 'recursive autoencoders for itg-based translation.',\n",
       "  'citation': 37,\n",
       "  'abstract': {'IndexLength': 108,\n",
       "   'InvertedIndex': {'While': [0],\n",
       "    'inversion': [1],\n",
       "    'transduction': [2],\n",
       "    'grammar': [3],\n",
       "    '(ITG)': [4],\n",
       "    'is': [5],\n",
       "    'well': [6],\n",
       "    'suited': [7],\n",
       "    'for': [8, 69],\n",
       "    'modeling': [9],\n",
       "    'ordering': [10],\n",
       "    'shifts': [11],\n",
       "    'between': [12],\n",
       "    'languages,': [13],\n",
       "    'how': [14],\n",
       "    'to': [15, 45, 49, 76],\n",
       "    'make': [16, 50],\n",
       "    'applying': [17],\n",
       "    'the': [18, 54, 90, 101],\n",
       "    'two': [19],\n",
       "    'reordering': [20],\n",
       "    'rules': [21],\n",
       "    '(i.e.,': [22],\n",
       "    'straight': [23],\n",
       "    'and': [24, 79],\n",
       "    'inverted)': [25],\n",
       "    'dependent': [26],\n",
       "    'on': [27, 89],\n",
       "    'actual': [28],\n",
       "    'blocks': [29, 57],\n",
       "    'being': [30],\n",
       "    'merged': [31],\n",
       "    'remains': [32],\n",
       "    'a': [33, 83],\n",
       "    'challenge.': [34],\n",
       "    'Unlike': [35],\n",
       "    'previous': [36],\n",
       "    'work': [37],\n",
       "    'that': [38, 95],\n",
       "    'only': [39],\n",
       "    'uses': [40],\n",
       "    'boundary': [41],\n",
       "    'words,': [42],\n",
       "    'we': [43],\n",
       "    'propose': [44],\n",
       "    'use': [46, 52],\n",
       "    'recursive': [47, 60],\n",
       "    'autoencoders': [48, 61],\n",
       "    'full': [51],\n",
       "    'of': [53, 64],\n",
       "    'entire': [55],\n",
       "    'merging': [56],\n",
       "    'alternatively.': [58],\n",
       "    'The': [59],\n",
       "    'are': [62],\n",
       "    'capable': [63],\n",
       "    'generating': [65],\n",
       "    'vector': [66],\n",
       "    'space': [67],\n",
       "    'representations': [68],\n",
       "    'variable-sized': [70],\n",
       "    'phrases,': [71],\n",
       "    'which': [72],\n",
       "    'enable': [73],\n",
       "    'predicting': [74],\n",
       "    'orders': [75],\n",
       "    'exploit': [77],\n",
       "    'syntactic': [78],\n",
       "    'semantic': [80],\n",
       "    'information': [81],\n",
       "    'from': [82],\n",
       "    'neural': [84],\n",
       "    'language': [85],\n",
       "    'modeling’s': [86],\n",
       "    'perspective.': [87],\n",
       "    'Experiments': [88],\n",
       "    'NIST': [91],\n",
       "    '2008': [92],\n",
       "    'dataset': [93],\n",
       "    'show': [94],\n",
       "    'our': [96],\n",
       "    'system': [97],\n",
       "    'significantly': [98],\n",
       "    'improves': [99],\n",
       "    'over': [100],\n",
       "    'MaxEnt': [102],\n",
       "    'classifier': [103],\n",
       "    'by': [104],\n",
       "    '1.07': [105],\n",
       "    'BLEU': [106],\n",
       "    'points.': [107]}}},\n",
       " {'paper_name': 'an end-to-end discriminative approach to machine translation.',\n",
       "  'citation': 232,\n",
       "  'abstract': {'IndexLength': 120,\n",
       "   'InvertedIndex': {'We': [0, 34, 56],\n",
       "    'present': [1],\n",
       "    'a': [2, 53, 102],\n",
       "    'perceptron-style': [3],\n",
       "    'discriminative': [4, 18, 41],\n",
       "    'approach': [5],\n",
       "    'to': [6, 39, 66, 105],\n",
       "    'machine': [7],\n",
       "    'translation': [8],\n",
       "    'in': [9, 29],\n",
       "    'which': [10, 114],\n",
       "    'large': [11],\n",
       "    'feature': [12, 98],\n",
       "    'sets': [13],\n",
       "    'can': [14, 23],\n",
       "    'be': [15],\n",
       "    'exploited.': [16],\n",
       "    'Unlike': [17],\n",
       "    'reranking': [19],\n",
       "    'approaches,': [20],\n",
       "    'our': [21],\n",
       "    'system': [22],\n",
       "    'take': [24],\n",
       "    'advantage': [25],\n",
       "    'of': [26, 32, 49, 77],\n",
       "    'learned': [27],\n",
       "    'features': [28, 78],\n",
       "    'all': [30],\n",
       "    'stages': [31],\n",
       "    'decoding.': [33],\n",
       "    'first': [35],\n",
       "    'discuss': [36, 74],\n",
       "    'several': [37],\n",
       "    'challenges': [38],\n",
       "    'error-driven': [40],\n",
       "    'approaches.': [42],\n",
       "    'In': [43],\n",
       "    'particular,': [44],\n",
       "    'we': [45, 73, 99],\n",
       "    'explore': [46],\n",
       "    'different': [47],\n",
       "    'ways': [48],\n",
       "    'updating': [50],\n",
       "    'parameters': [51],\n",
       "    'given': [52],\n",
       "    'training': [54],\n",
       "    'example.': [55],\n",
       "    'find': [57],\n",
       "    'that': [58],\n",
       "    'making': [59, 67],\n",
       "    'frequent': [60],\n",
       "    'but': [61, 69],\n",
       "    'smaller': [62],\n",
       "    'updates': [63],\n",
       "    'is': [64, 101],\n",
       "    'preferable': [65],\n",
       "    'fewer': [68],\n",
       "    'larger': [70],\n",
       "    'updates.': [71],\n",
       "    'Then,': [72],\n",
       "    'an': [75],\n",
       "    'array': [76],\n",
       "    'and': [79, 88],\n",
       "    'show': [80],\n",
       "    'both': [81],\n",
       "    'how': [82, 89],\n",
       "    'they': [83, 90],\n",
       "    'quantitatively': [84],\n",
       "    'increase': [85],\n",
       "    'BLEU': [86],\n",
       "    'score': [87],\n",
       "    'qualitatively': [91],\n",
       "    'interact': [92],\n",
       "    'on': [93],\n",
       "    'specific': [94],\n",
       "    'examples.': [95],\n",
       "    'One': [96],\n",
       "    'particular': [97],\n",
       "    'investigate': [100],\n",
       "    'novel': [103],\n",
       "    'way': [104],\n",
       "    'introduce': [106],\n",
       "    'learning': [107],\n",
       "    'into': [108],\n",
       "    'the': [109],\n",
       "    'initial': [110],\n",
       "    'phrase': [111],\n",
       "    'extraction': [112],\n",
       "    'process,': [113],\n",
       "    'has': [115],\n",
       "    'previously': [116],\n",
       "    'been': [117],\n",
       "    'entirely': [118],\n",
       "    'heuristic.': [119]}}},\n",
       " {'paper_name': 'a phrase-based, joint probability model for statistical machine translation.',\n",
       "  'citation': 526,\n",
       "  'abstract': {'IndexLength': 39,\n",
       "   'InvertedIndex': {'We': [0],\n",
       "    'present': [1],\n",
       "    'a': [2],\n",
       "    'joint': [3, 27],\n",
       "    'probability': [4],\n",
       "    'model': [5, 28],\n",
       "    'for': [6],\n",
       "    'statistical': [7],\n",
       "    'machine': [8],\n",
       "    'translation,': [9],\n",
       "    'which': [10],\n",
       "    'automatically': [11],\n",
       "    'learns': [12],\n",
       "    'word': [13],\n",
       "    'and': [14],\n",
       "    'phrase': [15],\n",
       "    'equivalents': [16],\n",
       "    'from': [17],\n",
       "    'bilingual': [18],\n",
       "    'corpora.': [19],\n",
       "    'Translations': [20],\n",
       "    'produced': [21, 34],\n",
       "    'with': [22],\n",
       "    'parameters': [23],\n",
       "    'estimated': [24],\n",
       "    'using': [25, 35],\n",
       "    'the': [26],\n",
       "    'are': [29],\n",
       "    'more': [30],\n",
       "    'accurate': [31],\n",
       "    'than': [32],\n",
       "    'translations': [33],\n",
       "    'IBM': [36],\n",
       "    'Model': [37],\n",
       "    '4.': [38]}}},\n",
       " {'paper_name': 'recurrent neural network based language model.',\n",
       "  'citation': 1293,\n",
       "  'abstract': {'IndexLength': 131,\n",
       "   'InvertedIndex': {'A': [0],\n",
       "    'new': [1],\n",
       "    'recurrent': [2, 126],\n",
       "    'neural': [3, 127],\n",
       "    'network': [4],\n",
       "    'based': [5],\n",
       "    'language': [6, 45, 108, 124],\n",
       "    'model': [7, 88],\n",
       "    '(RNN': [8],\n",
       "    'LM)': [9],\n",
       "    'with': [10],\n",
       "    'applications': [11],\n",
       "    'to': [12, 23, 38, 104, 112],\n",
       "    'speech': [13, 129],\n",
       "    'recognition': [14, 48, 130],\n",
       "    'is': [15, 21, 89],\n",
       "    'presented.': [16],\n",
       "    'Results': [17],\n",
       "    'indicate': [18],\n",
       "    'that': [19, 106],\n",
       "    'it': [20],\n",
       "    'possible': [22],\n",
       "    'obtain': [24],\n",
       "    'around': [25, 51, 75],\n",
       "    '50%': [26],\n",
       "    'reduction': [27, 53],\n",
       "    'of': [28, 33, 41, 54, 72],\n",
       "    'perplexity': [29],\n",
       "    'by': [30],\n",
       "    'using': [31],\n",
       "    'mixture': [32],\n",
       "    'several': [34],\n",
       "    'RNN': [35, 97],\n",
       "    'LMs,': [36],\n",
       "    'compared': [37],\n",
       "    'a': [39],\n",
       "    'state': [40],\n",
       "    'the': [42, 59, 69, 78, 86, 96],\n",
       "    'art': [43],\n",
       "    'backoff': [44, 87],\n",
       "    'model.': [46],\n",
       "    'Speech': [47],\n",
       "    'experiments': [49],\n",
       "    'show': [50],\n",
       "    '18%': [52],\n",
       "    'word': [55],\n",
       "    'error': [56],\n",
       "    'rate': [57],\n",
       "    'on': [58, 68, 77, 91],\n",
       "    'Wall': [60],\n",
       "    'Street': [61],\n",
       "    'Journal': [62],\n",
       "    'task': [63],\n",
       "    'when': [64, 85],\n",
       "    'comparing': [65],\n",
       "    'models': [66, 109],\n",
       "    'trained': [67, 90],\n",
       "    'same': [70],\n",
       "    'amount': [71],\n",
       "    'data,': [73],\n",
       "    'and': [74],\n",
       "    '5%': [76],\n",
       "    'much': [79, 92],\n",
       "    'harder': [80],\n",
       "    'NIST': [81],\n",
       "    'RT05': [82],\n",
       "    'task,': [83],\n",
       "    'even': [84],\n",
       "    'more': [93],\n",
       "    'data': [94],\n",
       "    'than': [95],\n",
       "    'LM.': [98],\n",
       "    'We': [99],\n",
       "    'provide': [100],\n",
       "    'ample': [101],\n",
       "    'empirical': [102],\n",
       "    'evidence': [103],\n",
       "    'suggest': [105],\n",
       "    'connectionist': [107],\n",
       "    'are': [110],\n",
       "    'superior': [111],\n",
       "    'standard': [113],\n",
       "    'n-gram': [114],\n",
       "    'techniques,': [115],\n",
       "    'except': [116],\n",
       "    'their': [117],\n",
       "    'high': [118],\n",
       "    'computational': [119],\n",
       "    '(training)': [120],\n",
       "    'complexity.': [121],\n",
       "    'Index': [122],\n",
       "    'Terms:': [123],\n",
       "    'modeling,': [125],\n",
       "    'networks,': [128]}}},\n",
       " {'paper_name': 'extensions of recurrent neural network language model.',\n",
       "  'citation': 409,\n",
       "  'abstract': {'IndexLength': 115,\n",
       "   'InvertedIndex': {'We': [0],\n",
       "    'present': [1],\n",
       "    'several': [2],\n",
       "    'modifications': [3],\n",
       "    'of': [4, 29, 62, 89],\n",
       "    'the': [5, 31, 35, 79, 87, 92, 112],\n",
       "    'original': [6],\n",
       "    'recurrent': [7],\n",
       "    'neural': [8],\n",
       "    'network': [9],\n",
       "    'language': [10, 24],\n",
       "    'model': [11, 15, 97],\n",
       "    '(RNN': [12],\n",
       "    'LM).While': [13],\n",
       "    'this': [14, 39],\n",
       "    'has': [16],\n",
       "    'been': [17],\n",
       "    'shown': [18],\n",
       "    'to': [19, 46, 85],\n",
       "    'significantly': [20],\n",
       "    'outperform': [21],\n",
       "    'many': [22],\n",
       "    'competitive': [23],\n",
       "    'modeling': [25],\n",
       "    'techniques': [26],\n",
       "    'in': [27, 91],\n",
       "    'terms': [28],\n",
       "    'accuracy,': [30],\n",
       "    'remaining': [32],\n",
       "    'problem': [33],\n",
       "    'is': [34, 75],\n",
       "    'computational': [36],\n",
       "    'complexity.': [37],\n",
       "    'In': [38, 78],\n",
       "    'work,': [40],\n",
       "    'we': [41, 59, 81],\n",
       "    'show': [42, 60],\n",
       "    'approaches': [43],\n",
       "    'that': [44],\n",
       "    'lead': [45],\n",
       "    'more': [47, 109],\n",
       "    'than': [48, 111],\n",
       "    '15': [49],\n",
       "    'times': [50],\n",
       "    'speedup': [51],\n",
       "    'for': [52],\n",
       "    'both': [53, 103],\n",
       "    'training': [54, 105],\n",
       "    'and': [55, 106, 108],\n",
       "    'testing': [56],\n",
       "    'phases.': [57],\n",
       "    'Next,': [58],\n",
       "    'importance': [61],\n",
       "    'using': [63],\n",
       "    'a': [64],\n",
       "    'backpropagation': [65],\n",
       "    'through': [66],\n",
       "    'time': [67],\n",
       "    'algorithm.': [68],\n",
       "    'An': [69],\n",
       "    'empirical': [70],\n",
       "    'comparison': [71],\n",
       "    'with': [72],\n",
       "    'feedforward': [73],\n",
       "    'networks': [74],\n",
       "    'also': [76],\n",
       "    'provided.': [77],\n",
       "    'end,': [80],\n",
       "    'discuss': [82],\n",
       "    'possibilities': [83],\n",
       "    'how': [84],\n",
       "    'reduce': [86],\n",
       "    'amount': [88],\n",
       "    'parameters': [90],\n",
       "    'model.': [93],\n",
       "    'The': [94],\n",
       "    'resulting': [95],\n",
       "    'RNN': [96],\n",
       "    'can': [98],\n",
       "    'thus': [99],\n",
       "    'be': [100],\n",
       "    'smaller,': [101],\n",
       "    'faster': [102],\n",
       "    'during': [104],\n",
       "    'testing,': [107],\n",
       "    'accurate': [110],\n",
       "    'basic': [113],\n",
       "    'one.': [114]}}},\n",
       " {'paper_name': 'exploiting similarities among languages for machine translation.',\n",
       "  'citation': 357,\n",
       "  'abstract': {'IndexLength': 120,\n",
       "   'InvertedIndex': {'Dictionaries': [0],\n",
       "    'and': [1, 25, 28, 37, 49, 63, 93, 110, 113],\n",
       "    'phrase': [2, 29, 38],\n",
       "    'tables': [3, 115],\n",
       "    'are': [4],\n",
       "    'the': [5, 21, 101],\n",
       "    'basis': [6],\n",
       "    'of': [7, 23, 61, 71, 89],\n",
       "    'modern': [8],\n",
       "    'statistical': [9],\n",
       "    'machine': [10],\n",
       "    'translation': [11, 88, 114],\n",
       "    'systems.': [12],\n",
       "    'This': [13, 95],\n",
       "    'paper': [14],\n",
       "    'develops': [15],\n",
       "    'a': [16, 65],\n",
       "    'method': [17, 32, 77, 96],\n",
       "    'that': [18],\n",
       "    'can': [19, 33, 82, 105],\n",
       "    'automate': [20],\n",
       "    'process': [22],\n",
       "    'generating': [24],\n",
       "    'extending': [26],\n",
       "    'dictionaries': [27, 112],\n",
       "    'tables.': [30],\n",
       "    'Our': [31],\n",
       "    'translate': [34],\n",
       "    'missing': [35],\n",
       "    'word': [36],\n",
       "    'entries': [39],\n",
       "    'by': [40],\n",
       "    'learning': [41],\n",
       "    'language': [42, 118],\n",
       "    'structures': [43],\n",
       "    'based': [44],\n",
       "    'on': [45],\n",
       "    'large': [46],\n",
       "    'monolingual': [47],\n",
       "    'data': [48],\n",
       "    'mapping': [50, 67],\n",
       "    'between': [51, 68, 91],\n",
       "    'languages': [52],\n",
       "    'from': [53],\n",
       "    'small': [54],\n",
       "    'bilingual': [55],\n",
       "    'data.': [56],\n",
       "    'It': [57],\n",
       "    'uses': [58],\n",
       "    'distributed': [59],\n",
       "    'representation': [60],\n",
       "    'words': [62, 90],\n",
       "    'learns': [64],\n",
       "    'linear': [66],\n",
       "    'vector': [69],\n",
       "    'spaces': [70],\n",
       "    'languages.': [72],\n",
       "    'Despite': [73],\n",
       "    'its': [74],\n",
       "    'simplicity,': [75],\n",
       "    'our': [76],\n",
       "    'is': [78],\n",
       "    'surprisingly': [79],\n",
       "    'effective:': [80],\n",
       "    'we': [81],\n",
       "    'achieve': [83],\n",
       "    'almost': [84],\n",
       "    '90%': [85],\n",
       "    'precision@5': [86],\n",
       "    'for': [87, 116],\n",
       "    'English': [92],\n",
       "    'Spanish.': [94],\n",
       "    'makes': [97],\n",
       "    'little': [98],\n",
       "    'assumption': [99],\n",
       "    'about': [100],\n",
       "    'languages,': [102],\n",
       "    'so': [103],\n",
       "    'it': [104],\n",
       "    'be': [106],\n",
       "    'used': [107],\n",
       "    'to': [108],\n",
       "    'extend': [109],\n",
       "    'refine': [111],\n",
       "    'any': [117],\n",
       "    'pairs.': [119]}}},\n",
       " {'paper_name': 'linguistic regularities in continuous space word representations.',\n",
       "  'citation': 1040,\n",
       "  'abstract': {'IndexLength': 153,\n",
       "   'InvertedIndex': {'Continuous': [0],\n",
       "    'space': [1],\n",
       "    'language': [2],\n",
       "    'models': [3],\n",
       "    'have': [4],\n",
       "    'recently': [5],\n",
       "    'demonstrated': [6],\n",
       "    'outstanding': [7],\n",
       "    'results': [8, 86],\n",
       "    'across': [9],\n",
       "    'a': [10, 54, 88],\n",
       "    'variety': [11],\n",
       "    'of': [12, 105, 121],\n",
       "    'tasks.': [13],\n",
       "    'In': [14],\n",
       "    'this': [15, 111, 146],\n",
       "    'paper,': [16],\n",
       "    'we': [17],\n",
       "    'examine': [18],\n",
       "    'the': [19, 28, 64, 70, 78, 97, 122, 127, 135, 149],\n",
       "    'vector-space': [20],\n",
       "    'word': [21, 98, 128],\n",
       "    'representations': [22, 35],\n",
       "    'that': [23, 33, 48, 96, 126],\n",
       "    'are': [24, 36, 114],\n",
       "    'implicitly': [25],\n",
       "    'learned': [26],\n",
       "    'by': [27, 53, 103, 133],\n",
       "    'input-layer': [29],\n",
       "    'weights.': [30],\n",
       "    'We': [31, 94, 124],\n",
       "    'find': [32],\n",
       "    'these': [34],\n",
       "    'surprisingly': [37],\n",
       "    'good': [38],\n",
       "    'at': [39],\n",
       "    'capturing': [40],\n",
       "    'syntactic': [41, 101, 106],\n",
       "    'and': [42, 47, 76, 113],\n",
       "    'semantic': [43, 131],\n",
       "    'regularities': [44, 102, 132],\n",
       "    'in': [45, 87],\n",
       "    'language,': [46],\n",
       "    'each': [49],\n",
       "    'relationship': [50, 72],\n",
       "    'is': [51, 73],\n",
       "    'characterized': [52],\n",
       "    'relation-specific': [55],\n",
       "    'vector': [56, 80, 89, 136],\n",
       "    'offset.': [57],\n",
       "    'This': [58],\n",
       "    'allows': [59],\n",
       "    'vector-oriented': [60],\n",
       "    'reasoning': [61],\n",
       "    'based': [62],\n",
       "    'on': [63],\n",
       "    'offsets': [65],\n",
       "    'between': [66],\n",
       "    'words.': [67],\n",
       "    'For': [68],\n",
       "    'example,': [69],\n",
       "    'male/female': [71],\n",
       "    'automatically': [74],\n",
       "    'learned,': [75],\n",
       "    'with': [77, 110],\n",
       "    'induced': [79],\n",
       "    'representations,': [81],\n",
       "    '“King': [82],\n",
       "    'Man': [83],\n",
       "    '+': [84],\n",
       "    'Woman”': [85],\n",
       "    'very': [90],\n",
       "    'close': [91],\n",
       "    'to': [92, 116, 139],\n",
       "    '“Queen.”': [93],\n",
       "    'demonstrate': [95, 125],\n",
       "    'vectors': [99, 129],\n",
       "    'capture': [100, 130],\n",
       "    'means': [104],\n",
       "    'analogy': [107],\n",
       "    'questions': [108],\n",
       "    '(provided': [109],\n",
       "    'paper),': [112],\n",
       "    'able': [115],\n",
       "    'correctly': [117],\n",
       "    'answer': [118, 140],\n",
       "    'almost': [119],\n",
       "    '40%': [120],\n",
       "    'questions.': [123, 144],\n",
       "    'using': [134],\n",
       "    'offset': [137],\n",
       "    'method': [138, 147],\n",
       "    'SemEval-2012': [141],\n",
       "    'Task': [142],\n",
       "    '2': [143],\n",
       "    'Remarkably,': [145],\n",
       "    'outperforms': [148],\n",
       "    'best': [150],\n",
       "    'previous': [151],\n",
       "    'systems.': [152]}}},\n",
       " {'paper_name': 'polylingual topic models.',\n",
       "  'citation': 213,\n",
       "  'abstract': {'IndexLength': 93,\n",
       "   'InvertedIndex': {'Topic': [0],\n",
       "    'models': [1],\n",
       "    'are': [2, 37],\n",
       "    'a': [3, 53],\n",
       "    'useful': [4],\n",
       "    'tool': [5],\n",
       "    'for': [6, 42],\n",
       "    'analyzing': [7],\n",
       "    'large': [8, 71],\n",
       "    'text': [9],\n",
       "    'collections,': [10],\n",
       "    'but': [11],\n",
       "    'have': [12],\n",
       "    'previously': [13],\n",
       "    'been': [14],\n",
       "    'applied': [15],\n",
       "    'in': [16, 30, 48, 83],\n",
       "    'only': [17],\n",
       "    'monolingual,': [18],\n",
       "    'or': [19],\n",
       "    'at': [20],\n",
       "    'most': [21],\n",
       "    'bilingual,': [22],\n",
       "    'contexts.': [23],\n",
       "    'Meanwhile,': [24],\n",
       "    'massive': [25],\n",
       "    'collections': [26],\n",
       "    'of': [27, 32],\n",
       "    'interlinked': [28],\n",
       "    'documents': [29],\n",
       "    'dozens': [31],\n",
       "    'languages,': [33, 78],\n",
       "    'such': [34],\n",
       "    'as': [35],\n",
       "    'Wikipedia,': [36],\n",
       "    'now': [38],\n",
       "    'widely': [39],\n",
       "    'available,': [40],\n",
       "    'calling': [41],\n",
       "    'tools': [43],\n",
       "    'that': [44, 57],\n",
       "    'can': [45],\n",
       "    'characterize': [46],\n",
       "    'content': [47],\n",
       "    'many': [49],\n",
       "    'languages.': [50, 63, 92],\n",
       "    'We': [51, 64],\n",
       "    'introduce': [52],\n",
       "    'polylingual': [54],\n",
       "    'topic': [55, 89],\n",
       "    'model': [56],\n",
       "    'discovers': [58],\n",
       "    'topics': [59],\n",
       "    'aligned': [60],\n",
       "    'across': [61, 91],\n",
       "    'multiple': [62],\n",
       "    'explore': [65],\n",
       "    'the': [66],\n",
       "    \"model's\": [67],\n",
       "    'characteristics': [68],\n",
       "    'using': [69],\n",
       "    'two': [70],\n",
       "    'corpora,': [72],\n",
       "    'each': [73],\n",
       "    'with': [74],\n",
       "    'over': [75],\n",
       "    'ten': [76],\n",
       "    'different': [77],\n",
       "    'and': [79, 87],\n",
       "    'demonstrate': [80],\n",
       "    'its': [81],\n",
       "    'usefulness': [82],\n",
       "    'supporting': [84],\n",
       "    'machine': [85],\n",
       "    'translation': [86],\n",
       "    'tracking': [88],\n",
       "    'trends': [90]}}},\n",
       " {'paper_name': 'wider context by using bilingual language models in machine translation.',\n",
       "  'citation': 46,\n",
       "  'abstract': {'IndexLength': 112,\n",
       "   'InvertedIndex': {'In': [0, 34, 86],\n",
       "    'past': [1],\n",
       "    'Evaluations': [2],\n",
       "    'for': [3, 88],\n",
       "    'Machine': [4],\n",
       "    'Translation': [5],\n",
       "    'of': [6, 17, 49, 59, 79, 103],\n",
       "    'European': [7],\n",
       "    'Languages,': [8],\n",
       "    'it': [9],\n",
       "    'could': [10, 67, 76],\n",
       "    'be': [11, 21],\n",
       "    'shown': [12],\n",
       "    'that': [13],\n",
       "    'the': [14, 35, 47, 57, 72, 89, 99, 104],\n",
       "    'translation': [15, 73, 80],\n",
       "    'performance': [16],\n",
       "    'SMT': [18, 32],\n",
       "    'systems': [19],\n",
       "    'can': [20],\n",
       "    'increased': [22],\n",
       "    'by': [23],\n",
       "    'integrating': [24],\n",
       "    'a': [25, 30],\n",
       "    'bilingual': [26, 36, 60, 95],\n",
       "    'language': [27, 37, 53, 61, 96],\n",
       "    'model': [28, 71, 97],\n",
       "    'into': [29],\n",
       "    'phrase-based': [31],\n",
       "    'system.': [33],\n",
       "    'model,': [38],\n",
       "    'target': [39],\n",
       "    'words': [40, 45],\n",
       "    'with': [41],\n",
       "    'their': [42],\n",
       "    'aligned': [43],\n",
       "    'source': [44],\n",
       "    'build': [46],\n",
       "    'tokens': [48],\n",
       "    'an': [50, 93],\n",
       "    'n-gram': [51],\n",
       "    'based': [52],\n",
       "    'model.': [54],\n",
       "    'We': [55, 75],\n",
       "    'analyzed': [56],\n",
       "    'effect': [58],\n",
       "    'models': [62],\n",
       "    'and': [63, 84],\n",
       "    'show': [64, 77],\n",
       "    'where': [65],\n",
       "    'they': [66],\n",
       "    'help': [68],\n",
       "    'to': [69, 109],\n",
       "    'better': [70],\n",
       "    'process.': [74],\n",
       "    'improvements': [78],\n",
       "    'quality': [81],\n",
       "    'on': [82, 98],\n",
       "    'German-to-English': [83],\n",
       "    'Arabic-to-English.': [85],\n",
       "    'addition,': [87],\n",
       "    'Arabic-to-English': [90],\n",
       "    'task,': [91],\n",
       "    'training': [92],\n",
       "    'extra': [94],\n",
       "    'POS': [100],\n",
       "    'tags': [101],\n",
       "    'instead': [102],\n",
       "    'surface': [105],\n",
       "    'word': [106],\n",
       "    'forms': [107],\n",
       "    'led': [108],\n",
       "    'further': [110],\n",
       "    'improvements.': [111]}}},\n",
       " {'paper_name': 'minimum error rate training in statistical machine translation.',\n",
       "  'citation': 2184,\n",
       "  'abstract': {'IndexLength': 101,\n",
       "   'InvertedIndex': {'Often,': [0],\n",
       "    'the': [1, 32, 86, 98],\n",
       "    'training': [2, 45, 53, 70, 99],\n",
       "    'procedure': [3],\n",
       "    'for': [4, 68],\n",
       "    'statistical': [5],\n",
       "    'machine': [6],\n",
       "    'translation': [7, 34, 50],\n",
       "    'models': [8],\n",
       "    'is': [9, 23, 26, 90],\n",
       "    'based': [10],\n",
       "    'on': [11, 36],\n",
       "    'maximum': [12],\n",
       "    'likelihood': [13],\n",
       "    'or': [14],\n",
       "    'related': [15],\n",
       "    'criteria.': [16],\n",
       "    'A': [17],\n",
       "    'general': [18],\n",
       "    'problem': [19],\n",
       "    'of': [20, 57, 97],\n",
       "    'this': [21, 40],\n",
       "    'approach': [22],\n",
       "    'that': [24, 77],\n",
       "    'there': [25],\n",
       "    'only': [27],\n",
       "    'a': [28, 65],\n",
       "    'loose': [29],\n",
       "    'relation': [30],\n",
       "    'to': [31],\n",
       "    'final': [33, 87],\n",
       "    'quality': [35],\n",
       "    'unseen': [37],\n",
       "    'text.': [38],\n",
       "    'In': [39],\n",
       "    'paper,': [41],\n",
       "    'we': [42],\n",
       "    'analyze': [43],\n",
       "    'various': [44],\n",
       "    'criteria': [46, 54],\n",
       "    'which': [47],\n",
       "    'directly': [48, 92],\n",
       "    'optimize': [49],\n",
       "    'quality.': [51],\n",
       "    'These': [52],\n",
       "    'make': [55],\n",
       "    'use': [56],\n",
       "    'recently': [58],\n",
       "    'proposed': [59],\n",
       "    'automatic': [60],\n",
       "    'evaluation': [61, 88],\n",
       "    'metrics.': [62],\n",
       "    'We': [63, 75],\n",
       "    'describe': [64],\n",
       "    'new': [66],\n",
       "    'algorithm': [67],\n",
       "    'efficient': [69],\n",
       "    'an': [71],\n",
       "    'unsmoothed': [72],\n",
       "    'error': [73],\n",
       "    'count.': [74],\n",
       "    'show': [76],\n",
       "    'significantly': [78],\n",
       "    'better': [79],\n",
       "    'results': [80],\n",
       "    'can': [81],\n",
       "    'often': [82],\n",
       "    'be': [83],\n",
       "    'obtained': [84],\n",
       "    'if': [85],\n",
       "    'criterion': [89],\n",
       "    'taken': [91],\n",
       "    'into': [93],\n",
       "    'account': [94],\n",
       "    'as': [95],\n",
       "    'part': [96],\n",
       "    'procedure.': [100]}}},\n",
       " {'paper_name': 'the alignment template approach to statistical machine translation.',\n",
       "  'citation': 772,\n",
       "  'abstract': {'IndexLength': 175,\n",
       "   'InvertedIndex': {'A': [0],\n",
       "    'phrase-based': [1],\n",
       "    'statistical': [2, 80],\n",
       "    'machine': [3, 81, 157],\n",
       "    'translation': [4, 15, 35, 82, 144, 158, 173],\n",
       "    'approach': [5, 10, 16, 106],\n",
       "    '—': [6, 11],\n",
       "    'the': [7, 25, 34, 66, 72, 88, 94, 99, 114, 121, 128, 133, 147],\n",
       "    'alignment': [8, 134],\n",
       "    'template': [9, 135],\n",
       "    'is': [12, 29, 54, 62, 74, 107],\n",
       "    'described.': [13],\n",
       "    'This': [14],\n",
       "    'allows': [17],\n",
       "    'for': [18, 90],\n",
       "    'general': [19],\n",
       "    'many-to-many': [20],\n",
       "    'relations': [21],\n",
       "    'between': [22],\n",
       "    'words.': [23],\n",
       "    'Thereby,': [24, 71],\n",
       "    'context': [26],\n",
       "    'of': [27, 65, 104, 123, 152],\n",
       "    'words': [28],\n",
       "    'taken': [30],\n",
       "    'into': [31],\n",
       "    'account': [32],\n",
       "    'in': [33, 40, 86],\n",
       "    'model,': [36],\n",
       "    'and': [37, 98, 154, 171],\n",
       "    'local': [38],\n",
       "    'changes': [39],\n",
       "    'word': [41],\n",
       "    'order': [42],\n",
       "    'from': [43],\n",
       "    'source': [44],\n",
       "    'to': [45, 76],\n",
       "    'target': [46],\n",
       "    'language': [47],\n",
       "    'can': [48],\n",
       "    'be': [49],\n",
       "    'learned': [50],\n",
       "    'explicitly.': [51],\n",
       "    'The': [52, 102],\n",
       "    'model': [53, 73],\n",
       "    'described': [55],\n",
       "    'using': [56],\n",
       "    'a': [57, 63, 142],\n",
       "    'log-linear': [58],\n",
       "    'modeling': [59],\n",
       "    'approach,': [60],\n",
       "    'which': [61],\n",
       "    'generalization': [64],\n",
       "    'often': [67],\n",
       "    'used': [68],\n",
       "    'source–channel': [69],\n",
       "    'approach.': [70],\n",
       "    'easier': [75],\n",
       "    'extend': [77],\n",
       "    'than': [78, 141, 167],\n",
       "    'classical': [79],\n",
       "    'systems.': [83, 174],\n",
       "    'We': [84],\n",
       "    'describe': [85],\n",
       "    'detail': [87],\n",
       "    'process': [89],\n",
       "    'learning': [91],\n",
       "    'phrasal': [92],\n",
       "    'translations,': [93],\n",
       "    'feature': [95],\n",
       "    'functions': [96],\n",
       "    'used,': [97],\n",
       "    'search': [100],\n",
       "    'algorithm.': [101],\n",
       "    'evaluation': [103, 159],\n",
       "    'this': [105],\n",
       "    'performed': [108],\n",
       "    'on': [109],\n",
       "    'three': [110],\n",
       "    'different': [111],\n",
       "    'tasks.': [112],\n",
       "    'For': [113],\n",
       "    'German–English': [115],\n",
       "    'speech': [116],\n",
       "    'VERBMOBIL': [117],\n",
       "    'task,': [118, 132],\n",
       "    'we': [119],\n",
       "    'analyze': [120],\n",
       "    'effect': [122],\n",
       "    'various': [124],\n",
       "    'system': [125, 136],\n",
       "    'components.': [126],\n",
       "    'On': [127],\n",
       "    'French–English': [129],\n",
       "    'Canadian': [130],\n",
       "    'HANSARDS': [131],\n",
       "    'obtains': [137],\n",
       "    'significantly': [138, 163],\n",
       "    'better': [139, 164],\n",
       "    'results': [140],\n",
       "    'single-word-based': [143],\n",
       "    'model.': [145],\n",
       "    'In': [146],\n",
       "    'Chinese–English': [148],\n",
       "    '2002': [149],\n",
       "    'National': [150],\n",
       "    'Institute': [151],\n",
       "    'Standards': [153],\n",
       "    'Technology': [155],\n",
       "    '(NIST)': [156],\n",
       "    'it': [160],\n",
       "    'yields': [161],\n",
       "    'statistically': [162],\n",
       "    'NIST': [165],\n",
       "    'scores': [166],\n",
       "    'all': [168],\n",
       "    'competing': [169],\n",
       "    'research': [170],\n",
       "    'commercial': [172]}}},\n",
       " {'paper_name': 'bleu: a method for automatic evaluation of machine translation.',\n",
       "  'citation': 5877,\n",
       "  'abstract': {'IndexLength': 79,\n",
       "   'InvertedIndex': {'Human': [0, 9],\n",
       "    'evaluations': [1, 10],\n",
       "    'of': [2, 29],\n",
       "    'machine': [3, 31],\n",
       "    'translation': [4, 32],\n",
       "    'are': [5],\n",
       "    'extensive': [6],\n",
       "    'but': [7],\n",
       "    'expensive.': [8],\n",
       "    'can': [11, 21],\n",
       "    'take': [12],\n",
       "    'months': [13],\n",
       "    'to': [14, 62],\n",
       "    'finish': [15],\n",
       "    'and': [16, 38, 46],\n",
       "    'involve': [17],\n",
       "    'human': [18, 44, 64],\n",
       "    'labor': [19],\n",
       "    'that': [20, 34, 40, 47],\n",
       "    'not': [22],\n",
       "    'be': [23],\n",
       "    'reused.': [24],\n",
       "    'We': [25, 54],\n",
       "    'propose': [26],\n",
       "    'a': [27],\n",
       "    'method': [28, 57],\n",
       "    'automatic': [30],\n",
       "    'evaluation': [33],\n",
       "    'is': [35, 72],\n",
       "    'quick,': [36],\n",
       "    'inexpensive,': [37],\n",
       "    'language-independent,': [39],\n",
       "    'correlates': [41],\n",
       "    'highly': [42],\n",
       "    'with': [43],\n",
       "    'evaluation,': [45],\n",
       "    'has': [48],\n",
       "    'little': [49],\n",
       "    'marginal': [50],\n",
       "    'cost': [51],\n",
       "    'per': [52],\n",
       "    'run.': [53],\n",
       "    'present': [55],\n",
       "    'this': [56],\n",
       "    'as': [58],\n",
       "    'an': [59],\n",
       "    'automated': [60],\n",
       "    'understudy': [61],\n",
       "    'skilled': [63],\n",
       "    'judges': [65],\n",
       "    'which': [66],\n",
       "    'substitutes': [67],\n",
       "    'for': [68, 74],\n",
       "    'them': [69],\n",
       "    'when': [70],\n",
       "    'there': [71],\n",
       "    'need': [73],\n",
       "    'quick': [75],\n",
       "    'or': [76],\n",
       "    'frequent': [77],\n",
       "    'evaluations.': [78]}}},\n",
       " {'paper_name': 'translingual document representations from discriminative projections.',\n",
       "  'citation': 74,\n",
       "  'abstract': {'IndexLength': 147,\n",
       "   'InvertedIndex': {'Representing': [0],\n",
       "    'documents': [1, 25, 65, 132],\n",
       "    'by': [2, 75],\n",
       "    'vectors': [3],\n",
       "    'that': [4],\n",
       "    'are': [5, 123, 133],\n",
       "    'independent': [6],\n",
       "    'of': [7, 24, 56, 64, 128],\n",
       "    'language': [8],\n",
       "    'enhances': [9],\n",
       "    'machine': [10],\n",
       "    'translation': [11],\n",
       "    'and': [12, 48, 67, 97, 100, 111, 136],\n",
       "    'multilingual': [13],\n",
       "    'text': [14, 102],\n",
       "    'categorization.': [15],\n",
       "    'We': [16, 35, 85],\n",
       "    'use': [17],\n",
       "    'discriminative': [18, 74, 108],\n",
       "    'training': [19],\n",
       "    'to': [20, 39, 80, 144],\n",
       "    'create': [21, 40],\n",
       "    'a': [22, 30, 61],\n",
       "    'projection': [23],\n",
       "    'from': [26],\n",
       "    'multiple': [27],\n",
       "    'languages': [28],\n",
       "    'into': [29],\n",
       "    'single': [31],\n",
       "    'translingual': [32],\n",
       "    'vector': [33, 83],\n",
       "    'space.': [34],\n",
       "    'explore': [36],\n",
       "    'two': [37, 90, 107],\n",
       "    'variants': [38, 58],\n",
       "    'these': [41, 57, 87],\n",
       "    'projections:': [42],\n",
       "    'Oriented': [43],\n",
       "    'Principal': [44],\n",
       "    'Component': [45],\n",
       "    'Analysis': [46, 53],\n",
       "    '(OPCA)': [47],\n",
       "    'Coupled': [49],\n",
       "    'Probabilistic': [50],\n",
       "    'Latent': [51],\n",
       "    'Semantic': [52],\n",
       "    '(CPLSA).': [54],\n",
       "    'Both': [55],\n",
       "    'start': [59],\n",
       "    'with': [60],\n",
       "    'basic': [62],\n",
       "    'model': [63, 70],\n",
       "    '(PCA': [66],\n",
       "    'PLSA).': [68],\n",
       "    'Each': [69],\n",
       "    'is': [71, 142],\n",
       "    'then': [72],\n",
       "    'made': [73],\n",
       "    'encouraging': [76],\n",
       "    'comparable': [77, 135],\n",
       "    'document': [78, 93],\n",
       "    'pairs': [79],\n",
       "    'have': [81],\n",
       "    'similar': [82],\n",
       "    'representations.': [84],\n",
       "    'evaluate': [86],\n",
       "    'algorithms': [88],\n",
       "    'on': [89, 104, 125],\n",
       "    'tasks:': [91],\n",
       "    'parallel': [92],\n",
       "    'retrieval': [94, 129],\n",
       "    'for': [95],\n",
       "    'Wikipedia': [96],\n",
       "    'Europarl': [98],\n",
       "    'documents,': [99],\n",
       "    'cross-lingual': [101],\n",
       "    'classification': [103],\n",
       "    'Reuters.': [105],\n",
       "    'The': [106, 118, 139],\n",
       "    'variants,': [109],\n",
       "    'OPCA': [110, 140],\n",
       "    'CPLSA,': [112],\n",
       "    'significantly': [113],\n",
       "    'outperform': [114],\n",
       "    'their': [115],\n",
       "    'corresponding': [116],\n",
       "    'baselines.': [117],\n",
       "    'largest': [119],\n",
       "    'differences': [120],\n",
       "    'in': [121],\n",
       "    'performance': [122],\n",
       "    'observed': [124],\n",
       "    'the': [126, 131],\n",
       "    'task': [127],\n",
       "    'when': [130],\n",
       "    'only': [134],\n",
       "    'not': [137],\n",
       "    'parallel.': [138],\n",
       "    'method': [141],\n",
       "    'shown': [143],\n",
       "    'perform': [145],\n",
       "    'best.': [146]}}},\n",
       " {'paper_name': 'expected bleu training for graphs: bbn system description for wmt system combination task.',\n",
       "  'citation': 17,\n",
       "  'abstract': {'IndexLength': 139,\n",
       "   'InvertedIndex': {'BBN': [0],\n",
       "    'submitted': [1],\n",
       "    'system': [2, 64, 130],\n",
       "    'combination': [3, 65, 111, 132],\n",
       "    'outputs': [4],\n",
       "    'for': [5],\n",
       "    'Czech-English,': [6],\n",
       "    'German-English,': [7],\n",
       "    'Spanish-English,': [8],\n",
       "    'and': [9, 86, 101],\n",
       "    'French-English': [10],\n",
       "    'language': [11, 126],\n",
       "    'pairs.': [12, 127],\n",
       "    'All': [13],\n",
       "    'combinations': [14],\n",
       "    'were': [15, 24, 67],\n",
       "    'based': [16, 72],\n",
       "    'on': [17, 122],\n",
       "    'confusion': [18, 22],\n",
       "    'network': [19],\n",
       "    'decoding.': [20],\n",
       "    'The': [21, 63, 89, 110],\n",
       "    'networks': [23, 83],\n",
       "    'built': [25],\n",
       "    'using': [26, 69],\n",
       "    'incremental': [27],\n",
       "    'hypothesis': [28],\n",
       "    'alignment': [29],\n",
       "    'algorithm': [30],\n",
       "    'with': [31],\n",
       "    'flexible': [32],\n",
       "    'matching.': [33],\n",
       "    'A': [34, 128],\n",
       "    'novel': [35],\n",
       "    'bi-gram': [36, 85],\n",
       "    'count': [37],\n",
       "    'feature,': [38],\n",
       "    'which': [39],\n",
       "    'can': [40, 102],\n",
       "    'penalize': [41],\n",
       "    'bi-grams': [42],\n",
       "    'not': [43],\n",
       "    'present': [44],\n",
       "    'in': [45, 56, 94],\n",
       "    'the': [46, 59, 76, 82, 118, 123],\n",
       "    'input': [47],\n",
       "    'hypotheses': [48],\n",
       "    'corresponding': [49],\n",
       "    'to': [50, 58, 84, 99, 105],\n",
       "    'a': [51, 70],\n",
       "    'source': [52],\n",
       "    'sentence,': [53],\n",
       "    'was': [54],\n",
       "    'introduced': [55],\n",
       "    'addition': [57],\n",
       "    'usual': [60],\n",
       "    'decoder': [61],\n",
       "    'features.': [62],\n",
       "    'weights': [66],\n",
       "    'tuned': [68],\n",
       "    'graph': [71],\n",
       "    'expected': [73, 90],\n",
       "    'BLEU': [74, 91, 115, 136],\n",
       "    'as': [75],\n",
       "    'objective': [77],\n",
       "    'function': [78],\n",
       "    'while': [79],\n",
       "    'incrementally': [80],\n",
       "    'expanding': [81],\n",
       "    '5-gram': [87],\n",
       "    'contexts.': [88],\n",
       "    'tuning': [92],\n",
       "    'described': [93],\n",
       "    'this': [95],\n",
       "    'paper': [96],\n",
       "    'naturally': [97],\n",
       "    'generalizes': [98],\n",
       "    'hypergraphs': [100],\n",
       "    'be': [103],\n",
       "    'used': [104],\n",
       "    'optimize': [106],\n",
       "    'thousands': [107],\n",
       "    'of': [108],\n",
       "    'weights.': [109],\n",
       "    'gained': [112],\n",
       "    'about': [113],\n",
       "    '0.5-4.0': [114],\n",
       "    'points': [116],\n",
       "    'over': [117],\n",
       "    'best': [119],\n",
       "    'individual': [120],\n",
       "    'systems': [121],\n",
       "    'official': [124],\n",
       "    'WMT11': [125],\n",
       "    '39': [129],\n",
       "    'multi-source': [131],\n",
       "    'achieved': [133],\n",
       "    'an': [134],\n",
       "    '11.1': [135],\n",
       "    'point': [137],\n",
       "    'gain.': [138]}}},\n",
       " {'paper_name': 'continuous space translation models for phrase-based statistical machine translation.',\n",
       "  'citation': 60,\n",
       "  'abstract': {'IndexLength': 147,\n",
       "   'InvertedIndex': {'This': [0],\n",
       "    'paper': [1],\n",
       "    'presents': [2],\n",
       "    'a': [3, 16, 82, 90, 127],\n",
       "    'new': [4, 133],\n",
       "    'approach': [5, 60, 94],\n",
       "    'to': [6, 26, 49, 62, 65, 98],\n",
       "    'perform': [7],\n",
       "    'the': [8, 11, 29, 45, 59, 76, 85, 109, 116, 123, 132],\n",
       "    'estimation': [9],\n",
       "    'of': [10, 15, 32, 84, 142],\n",
       "    'translation': [12, 20, 30, 68],\n",
       "    'model': [13, 134],\n",
       "    'probabilities': [14, 69],\n",
       "    'phrase-based': [17, 52],\n",
       "    'statistical': [18],\n",
       "    'machine': [19],\n",
       "    'system.': [21],\n",
       "    'We': [22, 54],\n",
       "    'use': [23],\n",
       "    'neural': [24],\n",
       "    'networks': [25],\n",
       "    'directly': [27],\n",
       "    'learn': [28],\n",
       "    'probability': [31],\n",
       "    'phrase': [33, 71],\n",
       "    'pairs': [34, 72],\n",
       "    'using': [35],\n",
       "    'continuous': [36],\n",
       "    'representations.': [37],\n",
       "    'The': [38, 93],\n",
       "    'system': [39],\n",
       "    'can': [40, 95],\n",
       "    'be': [41, 63, 96],\n",
       "    'easily': [42],\n",
       "    'trained': [43],\n",
       "    'on': [44, 115],\n",
       "    'same': [46],\n",
       "    'data': [47],\n",
       "    'used': [48, 97],\n",
       "    'build': [50],\n",
       "    'standard': [51],\n",
       "    'systems.': [53],\n",
       "    'provide': [55],\n",
       "    'experimental': [56],\n",
       "    'evidence': [57],\n",
       "    'that': [58, 131],\n",
       "    'seems': [61],\n",
       "    'able': [64],\n",
       "    'infer': [66],\n",
       "    'meaningful': [67],\n",
       "    'for': [70],\n",
       "    'not': [73],\n",
       "    'seen': [74],\n",
       "    'in': [75, 122],\n",
       "    'training': [77],\n",
       "    'data,': [78],\n",
       "    'or': [79],\n",
       "    'even': [80],\n",
       "    'predict': [81],\n",
       "    'list': [83],\n",
       "    'most': [86],\n",
       "    'likely': [87],\n",
       "    'translations': [88],\n",
       "    'given': [89],\n",
       "    'source': [91],\n",
       "    'phrase.': [92],\n",
       "    'rescore': [99],\n",
       "    'n-best': [100],\n",
       "    'lists,': [101],\n",
       "    'but': [102],\n",
       "    'we': [103],\n",
       "    'also': [104],\n",
       "    'discuss': [105],\n",
       "    'an': [106],\n",
       "    'integration': [107],\n",
       "    'into': [108],\n",
       "    'Moses': [110],\n",
       "    'decoder.': [111],\n",
       "    'A': [112],\n",
       "    'preliminary': [113],\n",
       "    'evaluation': [114],\n",
       "    'English/French': [117],\n",
       "    'IWSLT': [118],\n",
       "    'task': [119],\n",
       "    'achieved': [120],\n",
       "    'improvements': [121],\n",
       "    'BLEU': [124],\n",
       "    'score': [125],\n",
       "    'and': [126],\n",
       "    'human': [128],\n",
       "    'analysis': [129],\n",
       "    'showed': [130],\n",
       "    'often': [135],\n",
       "    'chooses': [136],\n",
       "    'semantically': [137],\n",
       "    'better': [138],\n",
       "    'translations.': [139],\n",
       "    'Several': [140],\n",
       "    'extensions': [141],\n",
       "    'this': [143],\n",
       "    'work': [144],\n",
       "    'are': [145],\n",
       "    'discussed.': [146]}}},\n",
       " {'paper_name': 'large, pruned or continuous space language models on a gpu for statistical machine translation.',\n",
       "  'citation': 60,\n",
       "  'abstract': {'IndexLength': 174,\n",
       "   'InvertedIndex': {'Language': [0],\n",
       "    'models': [1, 38, 110],\n",
       "    'play': [2],\n",
       "    'an': [3, 83, 100, 118, 138, 152],\n",
       "    'important': [4],\n",
       "    'role': [5],\n",
       "    'in': [6, 77, 146],\n",
       "    'large': [7, 92, 114],\n",
       "    'vocabulary': [8],\n",
       "    'speech': [9],\n",
       "    'recognition': [10],\n",
       "    'and': [11, 51, 73, 105],\n",
       "    'statistical': [12, 93],\n",
       "    'machine': [13, 94],\n",
       "    'translation': [14, 95],\n",
       "    'systems.': [15],\n",
       "    'The': [16],\n",
       "    'dominant': [17],\n",
       "    'approach': [18],\n",
       "    'since': [19],\n",
       "    'several': [20],\n",
       "    'decades': [21],\n",
       "    'are': [22, 61, 74, 134],\n",
       "    'back-off': [23, 165],\n",
       "    'language': [24, 37, 109, 166],\n",
       "    'models.': [25],\n",
       "    'Some': [26],\n",
       "    'years': [27],\n",
       "    'ago,': [28],\n",
       "    'there': [29],\n",
       "    'was': [30],\n",
       "    'a': [31, 62, 69, 91],\n",
       "    'clear': [32],\n",
       "    'tendency': [33, 48],\n",
       "    'to': [34, 103, 136, 156, 162, 172],\n",
       "    'build': [35],\n",
       "    'huge': [36],\n",
       "    'trained': [39],\n",
       "    'on': [40, 55, 90, 140],\n",
       "    'hundreds': [41],\n",
       "    'of': [42, 44, 86, 121, 154],\n",
       "    'billions': [43],\n",
       "    'words.': [45],\n",
       "    'Lately,': [46],\n",
       "    'this': [47],\n",
       "    'has': [49],\n",
       "    'changed': [50],\n",
       "    'recent': [52],\n",
       "    'works': [53],\n",
       "    'concentrate': [54],\n",
       "    'data': [56],\n",
       "    'selection.': [57],\n",
       "    'Continuous': [58],\n",
       "    'space': [59, 108],\n",
       "    'methods': [60],\n",
       "    'very': [63],\n",
       "    'competitive': [64],\n",
       "    'approach,': [65],\n",
       "    'but': [66],\n",
       "    'they': [67],\n",
       "    'have': [68],\n",
       "    'high': [70],\n",
       "    'computational': [71],\n",
       "    'complexity': [72],\n",
       "    'not': [75],\n",
       "    'yet': [76],\n",
       "    'widespread': [78],\n",
       "    'use.': [79],\n",
       "    'This': [80, 149],\n",
       "    'paper': [81],\n",
       "    'presents': [82],\n",
       "    'experimental': [84],\n",
       "    'comparison': [85],\n",
       "    'all': [87],\n",
       "    'these': [88, 131],\n",
       "    'approaches': [89],\n",
       "    'task.': [96],\n",
       "    'We': [97, 116],\n",
       "    'also': [98],\n",
       "    'describe': [99, 117],\n",
       "    'open-source': [101],\n",
       "    'implementation': [102, 120],\n",
       "    'train': [104, 137],\n",
       "    'use': [106],\n",
       "    'continuous': [107],\n",
       "    '(CSLM)': [111],\n",
       "    'for': [112],\n",
       "    'such': [113],\n",
       "    'tasks.': [115],\n",
       "    'efficient': [119],\n",
       "    'the': [122, 163],\n",
       "    'CSLM': [123, 139, 150],\n",
       "    'using': [124],\n",
       "    'graphical': [125],\n",
       "    'processing': [126],\n",
       "    'units': [127],\n",
       "    'from': [128],\n",
       "    'Nvidia.': [129],\n",
       "    'By': [130],\n",
       "    'means,': [132],\n",
       "    'we': [133, 169],\n",
       "    'able': [135, 171],\n",
       "    'more': [141],\n",
       "    'than': [142],\n",
       "    '500': [143],\n",
       "    'million': [144],\n",
       "    'words': [145],\n",
       "    '20': [147],\n",
       "    'hours.': [148],\n",
       "    'provides': [151],\n",
       "    'improvement': [153],\n",
       "    'up': [155],\n",
       "    '1.8': [157],\n",
       "    'BLEU': [158],\n",
       "    'points': [159],\n",
       "    'with': [160],\n",
       "    'respect': [161],\n",
       "    'best': [164],\n",
       "    'model': [167],\n",
       "    'that': [168],\n",
       "    'were': [170],\n",
       "    'build.': [173]}}},\n",
       " {'paper_name': 'discriminative training of 150 million translation parameters and its application to pruning.',\n",
       "  'citation': 5,\n",
       "  'abstract': {'IndexLength': 101,\n",
       "   'InvertedIndex': {'Until': [0],\n",
       "    'recently,': [1],\n",
       "    'the': [2, 18, 88],\n",
       "    'application': [3],\n",
       "    'of': [4, 20, 24, 33, 45, 61, 90],\n",
       "    'discriminative': [5, 43, 71],\n",
       "    'training': [6, 27, 44, 72],\n",
       "    'to': [7, 16, 40, 50, 69, 73, 81],\n",
       "    'log': [8],\n",
       "    'linear-based': [9],\n",
       "    'statistical': [10],\n",
       "    'machine': [11],\n",
       "    'translation': [12],\n",
       "    'has': [13],\n",
       "    'been': [14],\n",
       "    'limited': [15, 22, 31],\n",
       "    'tuning': [17],\n",
       "    'weights': [19],\n",
       "    'a': [21, 30, 98],\n",
       "    'number': [23, 32],\n",
       "    'features': [25, 28, 52],\n",
       "    'or': [26],\n",
       "    'with': [29, 53],\n",
       "    'parameters.': [34],\n",
       "    'In': [35],\n",
       "    'this': [36],\n",
       "    'paper,': [37],\n",
       "    'we': [38],\n",
       "    'propose': [39],\n",
       "    'scale': [41],\n",
       "    'up': [42],\n",
       "    '(He': [46],\n",
       "    'and': [47, 68],\n",
       "    'Deng,': [48],\n",
       "    '2012)': [49],\n",
       "    'train': [51],\n",
       "    '150': [54],\n",
       "    'million': [55],\n",
       "    'parameters,': [56],\n",
       "    'which': [57],\n",
       "    'is': [58, 78],\n",
       "    'one': [59],\n",
       "    'order': [60],\n",
       "    'magnitude': [62],\n",
       "    'higher': [63],\n",
       "    'than': [64],\n",
       "    'previously': [65],\n",
       "    'published': [66],\n",
       "    'effort,': [67],\n",
       "    'apply': [70],\n",
       "    'redistribute': [74],\n",
       "    'probability': [75],\n",
       "    'mass': [76],\n",
       "    'that': [77],\n",
       "    'lost': [79],\n",
       "    'due': [80],\n",
       "    'model': [82],\n",
       "    'pruning.': [83],\n",
       "    'The': [84],\n",
       "    'experimental': [85],\n",
       "    'results': [86],\n",
       "    'confirm': [87],\n",
       "    'effectiveness': [89],\n",
       "    'our': [91],\n",
       "    'proposals': [92],\n",
       "    'on': [93],\n",
       "    'NIST': [94],\n",
       "    'MT06': [95],\n",
       "    'set': [96],\n",
       "    'over': [97],\n",
       "    'strong': [99],\n",
       "    'baseline.': [100]}}},\n",
       " {'paper_name': 'semantic compositionality through recursive matrix-vector spaces.',\n",
       "  'citation': 586,\n",
       "  'abstract': {'IndexLength': 148,\n",
       "   'InvertedIndex': {'Single-word': [0],\n",
       "    'vector': [1, 41, 57, 69],\n",
       "    'space': [2],\n",
       "    'models': [3],\n",
       "    'have': [4],\n",
       "    'been': [5],\n",
       "    'very': [6],\n",
       "    'successful': [7],\n",
       "    'at': [8],\n",
       "    'learning': [9],\n",
       "    'lexical': [10],\n",
       "    'information.': [11],\n",
       "    'However,': [12],\n",
       "    'they': [13],\n",
       "    'cannot': [14],\n",
       "    'capture': [15],\n",
       "    'the': [16, 68, 71, 75, 78, 84, 96, 111, 143],\n",
       "    'compositional': [17, 40],\n",
       "    'meaning': [18, 73, 85, 97],\n",
       "    'of': [19, 28, 47, 74, 86, 98, 110, 122, 128],\n",
       "    'longer': [20],\n",
       "    'phrases,': [21],\n",
       "    'preventing': [22],\n",
       "    'them': [23],\n",
       "    'from': [24],\n",
       "    'a': [25, 32, 56, 59, 65],\n",
       "    'deeper': [26],\n",
       "    'understanding': [27],\n",
       "    'language.': [29, 105],\n",
       "    'We': [30],\n",
       "    'introduce': [31],\n",
       "    'recursive': [33],\n",
       "    'neural': [34],\n",
       "    'network': [35],\n",
       "    '(RNN)': [36],\n",
       "    'model': [37, 54, 107],\n",
       "    'that': [38],\n",
       "    'learns': [39],\n",
       "    'representations': [42],\n",
       "    'for': [43],\n",
       "    'phrases': [44],\n",
       "    'and': [45, 51, 58, 103, 131],\n",
       "    'sentences': [46],\n",
       "    'arbitrary': [48],\n",
       "    'syntactic': [49, 144],\n",
       "    'type': [50],\n",
       "    'length.': [52],\n",
       "    'Our': [53],\n",
       "    'assigns': [55],\n",
       "    'matrix': [60, 79],\n",
       "    'to': [61],\n",
       "    'every': [62],\n",
       "    'node': [63],\n",
       "    'in': [64, 100],\n",
       "    'parse': [66],\n",
       "    'tree:': [67],\n",
       "    'captures': [70, 80],\n",
       "    'inherent': [72],\n",
       "    'constituent,': [76],\n",
       "    'while': [77],\n",
       "    'how': [81],\n",
       "    'it': [82],\n",
       "    'changes': [83],\n",
       "    'neighboring': [87],\n",
       "    'words': [88],\n",
       "    'or': [89, 138],\n",
       "    'phrases.': [90],\n",
       "    'This': [91],\n",
       "    'matrix-vector': [92],\n",
       "    'RNN': [93],\n",
       "    'can': [94],\n",
       "    'learn': [95],\n",
       "    'operators': [99],\n",
       "    'propositional': [101],\n",
       "    'logic': [102],\n",
       "    'natural': [104],\n",
       "    'The': [106],\n",
       "    'obtains': [108],\n",
       "    'state': [109],\n",
       "    'art': [112],\n",
       "    'performance': [113],\n",
       "    'on': [114],\n",
       "    'three': [115],\n",
       "    'different': [116],\n",
       "    'experiments:': [117],\n",
       "    'predicting': [118],\n",
       "    'fine-grained': [119],\n",
       "    'sentiment': [120, 126],\n",
       "    'distributions': [121],\n",
       "    'adverb-adjective': [123],\n",
       "    'pairs;': [124],\n",
       "    'classifying': [125, 132],\n",
       "    'labels': [127],\n",
       "    'movie': [129],\n",
       "    'reviews': [130],\n",
       "    'semantic': [133],\n",
       "    'relationships': [134],\n",
       "    'such': [135],\n",
       "    'as': [136],\n",
       "    'cause-effect': [137],\n",
       "    'topic-message': [139],\n",
       "    'between': [140, 146],\n",
       "    'nouns': [141],\n",
       "    'using': [142],\n",
       "    'path': [145],\n",
       "    'them.': [147]}}},\n",
       " {'paper_name': 'parsing natural scenes and natural language with recursive neural networks.',\n",
       "  'citation': 572,\n",
       "  'abstract': {'IndexLength': 141,\n",
       "   'InvertedIndex': {'Recursive': [0],\n",
       "    'structure': [1, 23, 51, 64],\n",
       "    'is': [2],\n",
       "    'commonly': [3],\n",
       "    'found': [4],\n",
       "    'in': [5, 66],\n",
       "    'the': [6, 30, 92, 121, 129],\n",
       "    'inputs': [7],\n",
       "    'of': [8, 117],\n",
       "    'different': [9],\n",
       "    'modalities': [10],\n",
       "    'such': [11, 63],\n",
       "    'as': [12, 70, 72],\n",
       "    'natural': [13, 17, 88],\n",
       "    'scene': [14, 68, 102, 137],\n",
       "    'images': [15, 69],\n",
       "    'or': [16, 35],\n",
       "    'language': [18, 89],\n",
       "    'sentences.': [19, 73],\n",
       "    'Discovering': [20],\n",
       "    'this': [21],\n",
       "    'recursive': [22, 56],\n",
       "    'helps': [24],\n",
       "    'us': [25],\n",
       "    'to': [26, 43, 81, 96],\n",
       "    'not': [27],\n",
       "    'only': [28],\n",
       "    'identify': [29],\n",
       "    'units': [31],\n",
       "    'that': [32, 59],\n",
       "    'an': [33],\n",
       "    'image': [34, 130],\n",
       "    'sentence': [36],\n",
       "    'contains': [37],\n",
       "    'but': [38],\n",
       "    'also': [39],\n",
       "    'how': [40],\n",
       "    'they': [41],\n",
       "    'interact': [42],\n",
       "    'form': [44],\n",
       "    'a': [45, 49, 83, 114],\n",
       "    'whole.': [46],\n",
       "    'We': [47],\n",
       "    'introduce': [48],\n",
       "    'max-margin': [50],\n",
       "    'prediction': [52],\n",
       "    'architecture': [53],\n",
       "    'based': [54],\n",
       "    'on': [55, 120],\n",
       "    'neural': [57],\n",
       "    'networks': [58],\n",
       "    'can': [60, 77],\n",
       "    'successfully': [61],\n",
       "    'recover': [62],\n",
       "    'both': [65, 80],\n",
       "    'complex': [67],\n",
       "    'well': [71],\n",
       "    'The': [74, 126],\n",
       "    'same': [75],\n",
       "    'algorithm': [76, 112],\n",
       "    'be': [78],\n",
       "    'used': [79],\n",
       "    'provide': [82],\n",
       "    'competitive': [84],\n",
       "    'syntactic': [85],\n",
       "    'parser': [86],\n",
       "    'for': [87, 100, 136],\n",
       "    'sentences': [90],\n",
       "    'from': [91, 128],\n",
       "    'Penn': [93],\n",
       "    'Treebank': [94],\n",
       "    'and': [95, 105, 109],\n",
       "    'outperform': [97, 133],\n",
       "    'alternative': [98],\n",
       "    'approaches': [99],\n",
       "    'semantic': [101],\n",
       "    'segmentation,': [103],\n",
       "    'annotation': [104, 110],\n",
       "    'classification.': [106],\n",
       "    'For': [107],\n",
       "    'segmentation': [108],\n",
       "    'our': [111],\n",
       "    'obtains': [113],\n",
       "    'new': [115],\n",
       "    'level': [116],\n",
       "    'state-of-the-art': [118],\n",
       "    'performance': [119],\n",
       "    'Stanford': [122],\n",
       "    'background': [123],\n",
       "    'dataset': [124],\n",
       "    '(78.1%).': [125],\n",
       "    'features': [127],\n",
       "    'parse': [131],\n",
       "    'tree': [132],\n",
       "    'Gist': [134],\n",
       "    'descriptors': [135],\n",
       "    'classification': [138],\n",
       "    'by': [139],\n",
       "    '4%.': [140]}}},\n",
       " {'paper_name': 'continuous space translation models with neural networks.',\n",
       "  'citation': 92,\n",
       "  'abstract': {'IndexLength': 122,\n",
       "   'InvertedIndex': {'The': [0],\n",
       "    'use': [1],\n",
       "    'of': [2, 10, 17, 28, 51, 56, 67, 112],\n",
       "    'conventional': [3],\n",
       "    'maximum': [4],\n",
       "    'likelihood': [5],\n",
       "    'estimates': [6, 75],\n",
       "    'hinders': [7],\n",
       "    'the': [8, 73, 101],\n",
       "    'performance': [9],\n",
       "    'existing': [11],\n",
       "    'phrase-based': [12],\n",
       "    'translation': [13, 40, 43, 52, 68, 115],\n",
       "    'models.': [14],\n",
       "    'For': [15],\n",
       "    'lack': [16],\n",
       "    'sufficient': [18],\n",
       "    'training': [19],\n",
       "    'data,': [20],\n",
       "    'most': [21],\n",
       "    'models': [22, 103],\n",
       "    'only': [23],\n",
       "    'consider': [24],\n",
       "    'a': [25, 31, 48, 64, 80, 85, 113],\n",
       "    'small': [26, 89],\n",
       "    'amount': [27],\n",
       "    'context.': [29],\n",
       "    'As': [30],\n",
       "    'partial': [32],\n",
       "    'remedy,': [33],\n",
       "    'we': [34, 98],\n",
       "    'explore': [35],\n",
       "    'here': [36],\n",
       "    'several': [37],\n",
       "    'continuous': [38, 49],\n",
       "    'space': [39],\n",
       "    'models,': [41],\n",
       "    'where': [42],\n",
       "    'probabilities': [44],\n",
       "    'are': [45, 76],\n",
       "    'estimated': [46],\n",
       "    'using': [47, 79],\n",
       "    'representation': [50],\n",
       "    'units': [53],\n",
       "    'in': [54, 120],\n",
       "    'lieu': [55],\n",
       "    'standard': [57],\n",
       "    'discrete': [58],\n",
       "    'representations.': [59],\n",
       "    'In': [60, 88],\n",
       "    'order': [61],\n",
       "    'to': [62, 95],\n",
       "    'handle': [63],\n",
       "    'large': [65, 92],\n",
       "    'set': [66],\n",
       "    'units,': [69],\n",
       "    'these': [70],\n",
       "    'representations': [71],\n",
       "    'and': [72, 91, 108],\n",
       "    'associated': [74],\n",
       "    'jointly': [77],\n",
       "    'computed': [78],\n",
       "    'multi-layer': [81],\n",
       "    'neural': [82],\n",
       "    'network': [83],\n",
       "    'with': [84],\n",
       "    'SOUL': [86],\n",
       "    'architecture.': [87],\n",
       "    'scale': [90, 93],\n",
       "    'English': [94],\n",
       "    'French': [96],\n",
       "    'experiments,': [97],\n",
       "    'show': [99],\n",
       "    'that': [100],\n",
       "    'resulting': [102],\n",
       "    'can': [104],\n",
       "    'effectively': [105],\n",
       "    'be': [106],\n",
       "    'trained': [107],\n",
       "    'used': [109],\n",
       "    'on': [110],\n",
       "    'top': [111],\n",
       "    'n-gram': [114],\n",
       "    'system,': [116],\n",
       "    'delivering': [117],\n",
       "    'significant': [118],\n",
       "    'improvements': [119],\n",
       "    'performance.': [121]}}},\n",
       " {'paper_name': 'comparison of feed forward and recurrent neural network language models.',\n",
       "  'citation': 58,\n",
       "  'abstract': {'IndexLength': 122,\n",
       "   'InvertedIndex': {'Research': [0],\n",
       "    'on': [1, 10, 33, 84],\n",
       "    'language': [2, 102],\n",
       "    'modeling': [3],\n",
       "    'for': [4],\n",
       "    'speech': [5, 75, 88],\n",
       "    'recognition': [6, 89],\n",
       "    'has': [7, 62],\n",
       "    'increasingly': [8],\n",
       "    'focused': [9],\n",
       "    'the': [11, 23, 34, 55],\n",
       "    'application': [12],\n",
       "    'of': [13, 51, 57, 116],\n",
       "    'neural': [14, 27, 38, 118],\n",
       "    'networks.': [15],\n",
       "    'Two': [16],\n",
       "    'competing': [17],\n",
       "    'concepts': [18],\n",
       "    'have': [19],\n",
       "    'been': [20, 63],\n",
       "    'developed:': [21],\n",
       "    'On': [22],\n",
       "    'one': [24],\n",
       "    'hand,': [25],\n",
       "    'feedforward': [26, 67],\n",
       "    'networks': [28, 39, 71, 119],\n",
       "    'representing': [29],\n",
       "    'an': [30],\n",
       "    'n-gram': [31],\n",
       "    'approach,': [32],\n",
       "    'other': [35],\n",
       "    'hand': [36],\n",
       "    'recurrent': [37, 70, 117],\n",
       "    'that': [40],\n",
       "    'may': [41],\n",
       "    'learn': [42],\n",
       "    'context': [43],\n",
       "    'dependencies': [44],\n",
       "    'spanning': [45],\n",
       "    'more': [46],\n",
       "    'than': [47],\n",
       "    'a': [48, 85, 95],\n",
       "    'fixed': [49],\n",
       "    'number': [50],\n",
       "    'predecessor': [52],\n",
       "    'words.': [53],\n",
       "    'To': [54],\n",
       "    'best': [56],\n",
       "    'our': [58],\n",
       "    'knowledge,': [59],\n",
       "    'no': [60],\n",
       "    'comparison': [61],\n",
       "    'carried': [64],\n",
       "    'out': [65],\n",
       "    'between': [66],\n",
       "    'and': [68, 97, 108],\n",
       "    'state-of-the-art': [69],\n",
       "    'when': [72],\n",
       "    'applied': [73],\n",
       "    'to': [74, 100, 112],\n",
       "    'recognition.': [76],\n",
       "    'This': [77],\n",
       "    'paper': [78],\n",
       "    'analyzes': [79],\n",
       "    'this': [80],\n",
       "    'aspect': [81],\n",
       "    'in': [82],\n",
       "    'detail': [83],\n",
       "    'well-tuned': [86],\n",
       "    'French': [87],\n",
       "    'task.': [90],\n",
       "    'In': [91],\n",
       "    'addition,': [92],\n",
       "    'we': [93, 109],\n",
       "    'propose': [94],\n",
       "    'simple': [96],\n",
       "    'efficient': [98],\n",
       "    'method': [99],\n",
       "    'normalize': [101],\n",
       "    'model': [103],\n",
       "    'probabilities': [104],\n",
       "    'across': [105],\n",
       "    'different': [106],\n",
       "    'vocabularies,': [107],\n",
       "    'show': [110],\n",
       "    'how': [111],\n",
       "    'speed': [113],\n",
       "    'up': [114],\n",
       "    'training': [115],\n",
       "    'by': [120],\n",
       "    'parallelization.': [121]}}},\n",
       " {'paper_name': 'towards deeper understanding: deep convex networks for semantic utterance classification.',\n",
       "  'citation': 64,\n",
       "  'abstract': {'IndexLength': 136,\n",
       "   'InvertedIndex': {'Following': [0],\n",
       "    'the': [1, 13, 88, 117, 129],\n",
       "    'recent': [2],\n",
       "    'advances': [3],\n",
       "    'in': [4, 8],\n",
       "    'deep': [5, 19, 22, 40],\n",
       "    'learning': [6],\n",
       "    'techniques,': [7],\n",
       "    'this': [9],\n",
       "    'paper,': [10],\n",
       "    'we': [11, 105],\n",
       "    'present': [12],\n",
       "    'application': [14],\n",
       "    'of': [15, 18, 52, 74, 100, 119],\n",
       "    'special': [16],\n",
       "    'type': [17],\n",
       "    'architecture': [20],\n",
       "    '—': [21, 26],\n",
       "    'convex': [23],\n",
       "    'networks': [24, 42],\n",
       "    '(DCNs)': [25],\n",
       "    'for': [27, 54, 91, 112],\n",
       "    'semantic': [28, 77],\n",
       "    'utterance': [29],\n",
       "    'classification': [30, 45, 110],\n",
       "    '(SUC).': [31],\n",
       "    'DCNs': [32, 53],\n",
       "    'are': [33],\n",
       "    'shown': [34],\n",
       "    'to': [35],\n",
       "    'have': [36],\n",
       "    'several': [37],\n",
       "    'advantages': [38],\n",
       "    'over': [39],\n",
       "    'belief': [41],\n",
       "    '(DBNs)': [43],\n",
       "    'including': [44],\n",
       "    'accuracy': [46, 127],\n",
       "    'and': [47, 76],\n",
       "    'training': [48, 101],\n",
       "    'scalability.': [49],\n",
       "    'However,': [50],\n",
       "    'adoption': [51],\n",
       "    'SUC': [55, 61, 126],\n",
       "    'comes': [56],\n",
       "    'with': [57, 95, 133],\n",
       "    'non-trivial': [58],\n",
       "    'issues.': [59],\n",
       "    'Specifically,': [60],\n",
       "    'has': [62],\n",
       "    'an': [63],\n",
       "    'extremely': [64],\n",
       "    'sparse': [65],\n",
       "    'input': [66],\n",
       "    'feature': [67, 89],\n",
       "    'space': [68, 90],\n",
       "    'encompassing': [69],\n",
       "    'a': [70, 82, 96, 108],\n",
       "    'very': [71],\n",
       "    'large': [72],\n",
       "    'number': [73, 99],\n",
       "    'lexical': [75],\n",
       "    'features.': [78],\n",
       "    'This': [79],\n",
       "    'is': [80],\n",
       "    'about': [81],\n",
       "    'few': [83],\n",
       "    'thousand': [84],\n",
       "    'times': [85],\n",
       "    'larger': [86],\n",
       "    'than': [87, 128],\n",
       "    'acoustic': [92],\n",
       "    'modeling,': [93],\n",
       "    'yet': [94],\n",
       "    'much': [97],\n",
       "    'smaller': [98],\n",
       "    'samples.': [102],\n",
       "    'Experimental': [103],\n",
       "    'results': [104],\n",
       "    'obtained': [106],\n",
       "    'on': [107],\n",
       "    'domain': [109],\n",
       "    'task': [111],\n",
       "    'spoken': [113],\n",
       "    'language': [114],\n",
       "    'understanding': [115],\n",
       "    'demonstrate': [116],\n",
       "    'effectiveness': [118],\n",
       "    'DCNs.': [120],\n",
       "    'The': [121],\n",
       "    'DCN-based': [122],\n",
       "    'method': [123],\n",
       "    'produces': [124],\n",
       "    'higher': [125],\n",
       "    'Boosting-based': [130],\n",
       "    'discriminative': [131],\n",
       "    'classifier': [132],\n",
       "    'word': [134],\n",
       "    'trigrams.': [135]}}},\n",
       " {'paper_name': 'inferring a semantic representation of text via cross-language correlation analysis.',\n",
       "  'citation': 188,\n",
       "  'abstract': {'IndexLength': 239,\n",
       "   'InvertedIndex': {'The': [0, 84],\n",
       "    'problem': [1],\n",
       "    'of': [2, 7, 21, 75, 101, 142, 156, 186],\n",
       "    'learning': [3],\n",
       "    'a': [4, 8, 19, 32, 55, 59, 81, 148, 197],\n",
       "    'semantic': [5, 129, 138, 169, 210],\n",
       "    'representation': [6, 41, 170, 198, 216],\n",
       "    'text': [9],\n",
       "    'document': [10, 35],\n",
       "    'from': [11, 127],\n",
       "    'data': [12],\n",
       "    'is': [13, 25, 78, 103, 228],\n",
       "    'addressed,': [14],\n",
       "    'in': [15, 54, 58, 66, 105, 109, 172, 218, 221],\n",
       "    'the': [16, 76, 87, 106, 110, 120, 128, 161, 165, 168, 179, 183, 187, 236],\n",
       "    'situation': [17],\n",
       "    'where': [18],\n",
       "    'corpus': [20, 77, 188],\n",
       "    'unlabeled': [22],\n",
       "    'paired': [23],\n",
       "    'documents': [24],\n",
       "    'available,': [26],\n",
       "    'each': [27, 73],\n",
       "    'pair': [28],\n",
       "    'being': [29],\n",
       "    'formed': [30],\n",
       "    'by': [31, 93],\n",
       "    'short': [33],\n",
       "    'English': [34, 143],\n",
       "    'and': [36, 57, 108, 194, 220, 230],\n",
       "    'its': [37],\n",
       "    'French': [38, 157],\n",
       "    'translation.': [39],\n",
       "    'This': [40],\n",
       "    'can': [42],\n",
       "    'then': [43, 91],\n",
       "    'be': [44],\n",
       "    'used': [45],\n",
       "    'for': [46],\n",
       "    'any': [47, 131],\n",
       "    'retrieval,': [48],\n",
       "    'categorization': [49],\n",
       "    'or': [50],\n",
       "    'clustering': [51],\n",
       "    'task,': [52],\n",
       "    'both': [53, 217],\n",
       "    'standard': [56],\n",
       "    'cross-lingual': [60],\n",
       "    'setting.': [61],\n",
       "    'By': [62],\n",
       "    'using': [63, 94],\n",
       "    'kernel': [64, 95],\n",
       "    'functions,': [65],\n",
       "    'this': [67, 173],\n",
       "    'case': [68],\n",
       "    'simple': [69],\n",
       "    'bag-of-words': [70],\n",
       "    'inner': [71],\n",
       "    'products,': [72],\n",
       "    'part': [74],\n",
       "    'mapped': [79],\n",
       "    'to': [80, 147, 160, 233],\n",
       "    'high-dimensional': [82],\n",
       "    'space.': [83],\n",
       "    'correlations': [85, 180],\n",
       "    'between': [86, 133, 182],\n",
       "    'two': [88, 121, 184],\n",
       "    'spaces': [89],\n",
       "    'are': [90, 114, 123, 189],\n",
       "    'learnt': [92],\n",
       "    'Canonical': [96],\n",
       "    'Correlation': [97],\n",
       "    'Analysis.': [98],\n",
       "    'A': [99],\n",
       "    'set': [100],\n",
       "    'directions': [102],\n",
       "    'found': [104],\n",
       "    'first': [107, 176],\n",
       "    'second': [111],\n",
       "    'space': [112],\n",
       "    'that': [113, 145, 178, 196, 207, 227],\n",
       "    'maximally': [115],\n",
       "    'correlated.': [116],\n",
       "    'Since': [117],\n",
       "    'we': [118, 175, 213],\n",
       "    'assume': [119],\n",
       "    'representations': [122],\n",
       "    'completely': [124],\n",
       "    'independent': [125],\n",
       "    'apart': [126],\n",
       "    'content,': [130],\n",
       "    'correlation': [132],\n",
       "    'them': [134],\n",
       "    'should': [135, 151, 208],\n",
       "    'reflect': [136, 209],\n",
       "    'some': [137],\n",
       "    'similarity.': [139],\n",
       "    'Certain': [140],\n",
       "    'patterns': [141, 155, 206],\n",
       "    'words': [144, 158],\n",
       "    'relate': [146],\n",
       "    'specific': [149],\n",
       "    'meaning': [150],\n",
       "    'correlate': [152],\n",
       "    'with': [153],\n",
       "    'certain': [154],\n",
       "    'corresponding': [159],\n",
       "    'same': [162, 237],\n",
       "    'meaning,': [163],\n",
       "    'across': [164],\n",
       "    'corpus.': [166],\n",
       "    'Using': [167],\n",
       "    'obtained': [171],\n",
       "    'way': [174],\n",
       "    'demonstrate': [177],\n",
       "    'detected': [181],\n",
       "    'versions': [185],\n",
       "    'significantly': [190, 231],\n",
       "    'higher': [191],\n",
       "    'than': [192],\n",
       "    'random,': [193],\n",
       "    'hence': [195],\n",
       "    'based': [199],\n",
       "    'on': [200, 235],\n",
       "    'such': [201, 215],\n",
       "    'features': [202],\n",
       "    'does': [203],\n",
       "    'capture': [204],\n",
       "    'statistical': [205],\n",
       "    'information.': [211],\n",
       "    'Then': [212],\n",
       "    'use': [214],\n",
       "    'cross-language': [219],\n",
       "    'single-language': [222],\n",
       "    'retrieval': [223],\n",
       "    'tasks,': [224],\n",
       "    'observing': [225],\n",
       "    'performance': [226],\n",
       "    'consistently': [229],\n",
       "    'superior': [232],\n",
       "    'LSI': [234],\n",
       "    'data.': [238]}}},\n",
       " {'paper_name': 'large scale image annotation: learning to rank with joint word-image embeddings.',\n",
       "  'citation': 246,\n",
       "  'abstract': {'IndexLength': 147,\n",
       "   'InvertedIndex': {'Image': [0],\n",
       "    'annotation': [1, 114],\n",
       "    'datasets': [2, 31],\n",
       "    'are': [3, 98],\n",
       "    'becoming': [4],\n",
       "    'larger': [5],\n",
       "    'and': [6, 14, 50, 60, 76],\n",
       "    'larger,': [7],\n",
       "    'with': [8, 92],\n",
       "    'tens': [9, 15],\n",
       "    'of': [10, 12, 16, 18, 40, 44],\n",
       "    'millions': [11],\n",
       "    'images': [13, 59],\n",
       "    'thousands': [17],\n",
       "    'possible': [19],\n",
       "    'annotations.': [20, 61],\n",
       "    'We': [21, 80],\n",
       "    'propose': [22],\n",
       "    'a': [23, 47, 52, 117, 125],\n",
       "    'strongly': [24],\n",
       "    'performing': [25],\n",
       "    'method': [26, 63, 85, 142],\n",
       "    'that': [27, 127],\n",
       "    'scales': [28],\n",
       "    'to': [29, 35, 72, 130],\n",
       "    'such': [30],\n",
       "    'by': [32, 116, 132],\n",
       "    'simultaneously': [33],\n",
       "    'learning': [34, 51],\n",
       "    'optimize': [36],\n",
       "    'precision': [37, 138],\n",
       "    'at': [38],\n",
       "    'k': [39],\n",
       "    'the': [41, 101, 112, 134],\n",
       "    'ranked': [42],\n",
       "    'list': [43],\n",
       "    'annotations': [45, 91],\n",
       "    'for': [46, 57],\n",
       "    'given': [48, 115],\n",
       "    'image': [49],\n",
       "    'low-dimensional': [53],\n",
       "    'joint': [54],\n",
       "    'embedding': [55, 102],\n",
       "    'space': [56],\n",
       "    'both': [58, 64],\n",
       "    'Our': [62],\n",
       "    'outperforms': [65],\n",
       "    'several': [66],\n",
       "    'baseline': [67],\n",
       "    'methods': [68],\n",
       "    'and,': [69],\n",
       "    'in': [70, 100],\n",
       "    'comparison': [71],\n",
       "    'them,': [73],\n",
       "    'is': [74],\n",
       "    'faster': [75],\n",
       "    'consumes': [77],\n",
       "    'less': [78],\n",
       "    'memory.': [79],\n",
       "    'also': [81, 143],\n",
       "    'demonstrate': [82],\n",
       "    'how': [83],\n",
       "    'our': [84, 107, 141],\n",
       "    'learns': [86],\n",
       "    'an': [87],\n",
       "    'interpretable': [88],\n",
       "    'model,': [89],\n",
       "    'where': [90, 140],\n",
       "    'alternate': [93],\n",
       "    'spellings': [94],\n",
       "    'or': [95],\n",
       "    'even': [96, 105],\n",
       "    'languages': [97],\n",
       "    'close': [99],\n",
       "    'space.': [103],\n",
       "    'Hence,': [104],\n",
       "    'when': [106],\n",
       "    'model': [108],\n",
       "    'does': [109],\n",
       "    'not': [110],\n",
       "    'predict': [111],\n",
       "    'exact': [113],\n",
       "    'human': [118],\n",
       "    'labeler,': [119],\n",
       "    'it': [120],\n",
       "    'often': [121],\n",
       "    'predicts': [122],\n",
       "    'similar': [123],\n",
       "    'annotations,': [124],\n",
       "    'fact': [126],\n",
       "    'we': [128],\n",
       "    'try': [129],\n",
       "    'quantify': [131],\n",
       "    'measuring': [133],\n",
       "    'newly': [135],\n",
       "    'introduced': [136],\n",
       "    '\"sibling\"': [137],\n",
       "    'metric,': [139],\n",
       "    'obtains': [144],\n",
       "    'excellent': [145],\n",
       "    'results.': [146]}}},\n",
       " {'paper_name': 'training phrase translation models with leaving-oneout.',\n",
       "  'citation': 67,\n",
       "  'abstract': {'IndexLength': 125,\n",
       "   'InvertedIndex': {'Several': [0],\n",
       "    'attempts': [1],\n",
       "    'have': [2],\n",
       "    'been': [3],\n",
       "    'made': [4],\n",
       "    'to': [5, 38, 44, 61, 101, 106],\n",
       "    'learn': [6],\n",
       "    'phrase': [7, 46, 66, 96, 116],\n",
       "    'translation': [8, 14, 51],\n",
       "    'probabilities': [9],\n",
       "    'for': [10],\n",
       "    'phrase-based': [11],\n",
       "    'statistical': [12],\n",
       "    'machine': [13],\n",
       "    'that': [15, 41, 48],\n",
       "    'go': [16],\n",
       "    'beyond': [17],\n",
       "    'pure': [18],\n",
       "    'counting': [19],\n",
       "    'of': [20, 95, 104],\n",
       "    'phrases': [21],\n",
       "    'in': [22, 75, 89, 109],\n",
       "    'word-aligned': [23],\n",
       "    'training': [24, 94],\n",
       "    'data.': [25],\n",
       "    'Most': [26],\n",
       "    'approaches': [27],\n",
       "    'report': [28],\n",
       "    'problems': [29],\n",
       "    'with': [30],\n",
       "    'over-fitting.': [31],\n",
       "    'We': [32],\n",
       "    'describe': [33],\n",
       "    'a': [34, 112],\n",
       "    'novel': [35],\n",
       "    'leaving-one-out': [36],\n",
       "    'approach': [37],\n",
       "    'prevent': [39],\n",
       "    'over-fitting': [40],\n",
       "    'allows': [42],\n",
       "    'us': [43],\n",
       "    'train': [45],\n",
       "    'models': [47, 67, 73, 88, 97],\n",
       "    'show': [49],\n",
       "    'improved': [50],\n",
       "    'performance': [52],\n",
       "    'on': [53],\n",
       "    'the': [54, 115],\n",
       "    'WMT08': [55],\n",
       "    'Europarl': [56],\n",
       "    'German-English': [57],\n",
       "    'task.': [58],\n",
       "    'In': [59],\n",
       "    'contrast': [60],\n",
       "    'most': [62],\n",
       "    'previous': [63],\n",
       "    'work': [64],\n",
       "    'where': [65],\n",
       "    'were': [68],\n",
       "    'trained': [69],\n",
       "    'separately': [70],\n",
       "    'from': [71],\n",
       "    'other': [72],\n",
       "    'used': [74],\n",
       "    'translation,': [76],\n",
       "    'we': [77, 98],\n",
       "    'include': [78],\n",
       "    'all': [79],\n",
       "    'components': [80],\n",
       "    'such': [81],\n",
       "    'as': [82],\n",
       "    'single': [83],\n",
       "    'word': [84],\n",
       "    'lexica': [85],\n",
       "    'and': [86],\n",
       "    'reordering': [87],\n",
       "    'training.': [90],\n",
       "    'Using': [91],\n",
       "    'this': [92],\n",
       "    'consistent': [93],\n",
       "    'are': [99],\n",
       "    'able': [100],\n",
       "    'achieve': [102],\n",
       "    'improvements': [103],\n",
       "    'up': [105],\n",
       "    '1.4': [107],\n",
       "    'points': [108],\n",
       "    'BLEU.': [110],\n",
       "    'As': [111],\n",
       "    'side': [113],\n",
       "    'effect,': [114],\n",
       "    'table': [117],\n",
       "    'size': [118],\n",
       "    'is': [119],\n",
       "    'reduced': [120],\n",
       "    'by': [121],\n",
       "    'more': [122],\n",
       "    'than': [123],\n",
       "    '80%.': [124]}}},\n",
       " {'paper_name': 'learning discriminative projections for text similarity measures.',\n",
       "  'citation': 95,\n",
       "  'abstract': {'IndexLength': 111,\n",
       "   'InvertedIndex': {'Traditional': [0],\n",
       "    'text': [1],\n",
       "    'similarity': [2, 53],\n",
       "    'measures': [3],\n",
       "    'consider': [4],\n",
       "    'each': [5],\n",
       "    'term': [6, 30],\n",
       "    'similar': [7],\n",
       "    'only': [8, 93],\n",
       "    'to': [9, 46, 64],\n",
       "    'itself': [10],\n",
       "    'and': [11, 61, 86, 106],\n",
       "    'do': [12],\n",
       "    'not': [13, 92],\n",
       "    'model': [14],\n",
       "    'semantic': [15],\n",
       "    'relatedness': [16],\n",
       "    'of': [17, 50, 57, 70],\n",
       "    'terms.': [18],\n",
       "    'We': [19],\n",
       "    'propose': [20],\n",
       "    'a': [21, 33, 67],\n",
       "    'novel': [22],\n",
       "    'discriminative': [23],\n",
       "    'training': [24, 71],\n",
       "    'method': [25, 91],\n",
       "    'that': [26],\n",
       "    'projects': [27],\n",
       "    'the': [28, 43, 48, 51, 58, 74],\n",
       "    'raw': [29],\n",
       "    'vectors': [31],\n",
       "    'into': [32],\n",
       "    'common,': [34],\n",
       "    'low-dimensional': [35],\n",
       "    'vector': [36],\n",
       "    'space.': [37, 76],\n",
       "    'Our': [38],\n",
       "    'approach': [39],\n",
       "    'operates': [40],\n",
       "    'by': [41],\n",
       "    'finding': [42],\n",
       "    'optimal': [44],\n",
       "    'matrix': [45],\n",
       "    'minimize': [47],\n",
       "    'loss': [49],\n",
       "    'pre-selected': [52],\n",
       "    'function': [54],\n",
       "    '(e.g.,': [55],\n",
       "    'cosine)': [56],\n",
       "    'projected': [59],\n",
       "    'vectors,': [60],\n",
       "    'is': [62, 107],\n",
       "    'able': [63],\n",
       "    'efficiently': [65],\n",
       "    'handle': [66],\n",
       "    'large': [68],\n",
       "    'number': [69],\n",
       "    'examples': [72],\n",
       "    'in': [73],\n",
       "    'high-dimensional': [75],\n",
       "    'Evaluated': [77],\n",
       "    'on': [78],\n",
       "    'two': [79],\n",
       "    'very': [80],\n",
       "    'different': [81],\n",
       "    'tasks,': [82],\n",
       "    'cross-lingual': [83],\n",
       "    'document': [84],\n",
       "    'retrieval': [85],\n",
       "    'ad': [87],\n",
       "    'relevance': [88],\n",
       "    'measure,': [89],\n",
       "    'our': [90],\n",
       "    'outperforms': [94],\n",
       "    'existing': [95],\n",
       "    'state-of-the-art': [96],\n",
       "    'approaches,': [97],\n",
       "    'but': [98],\n",
       "    'also': [99],\n",
       "    'achieves': [100],\n",
       "    'high': [101],\n",
       "    'accuracy': [102],\n",
       "    'at': [103],\n",
       "    'low': [104],\n",
       "    'dimensions': [105],\n",
       "    'thus': [108],\n",
       "    'more': [109],\n",
       "    'efficient.': [110]}}},\n",
       " {'paper_name': 'a novel decision function and the associated decision-feedback learning for speech translation.',\n",
       "  'citation': 21,\n",
       "  'abstract': {'IndexLength': 141,\n",
       "   'InvertedIndex': {'In': [0],\n",
       "    'this': [1],\n",
       "    'paper': [2],\n",
       "    'we': [3],\n",
       "    'report': [4],\n",
       "    'our': [5, 46],\n",
       "    'recent': [6],\n",
       "    'development': [7],\n",
       "    'of': [8, 135],\n",
       "    'an': [9],\n",
       "    'end-to-end': [10, 47],\n",
       "    'integrative': [11],\n",
       "    'design': [12, 48],\n",
       "    'methodology': [13, 49],\n",
       "    'for': [14],\n",
       "    'speech': [15, 88, 97],\n",
       "    'translation.': [16],\n",
       "    'Specifically,': [17],\n",
       "    'a': [18, 105],\n",
       "    'novel': [19],\n",
       "    'decision': [20, 43, 73],\n",
       "    'function': [21, 44, 74],\n",
       "    'is': [22, 35, 75],\n",
       "    'proposed': [23, 127],\n",
       "    'based': [24, 37],\n",
       "    'on': [25, 38, 118],\n",
       "    'the': [26, 30, 39, 61, 67, 79, 85, 95, 110, 119, 126, 130],\n",
       "    'Bayesian': [27],\n",
       "    'analysis,': [28],\n",
       "    'and': [29, 56, 64, 90],\n",
       "    'associated': [31],\n",
       "    'discriminative': [32],\n",
       "    'learning': [33, 103],\n",
       "    'technique': [34],\n",
       "    'presented': [36],\n",
       "    'decision-feedback': [40, 102],\n",
       "    'principle.': [41],\n",
       "    'The': [42, 100],\n",
       "    'in': [45, 87, 94, 133],\n",
       "    'integrates': [50],\n",
       "    'acoustic': [51],\n",
       "    'scores,': [52],\n",
       "    'language': [53],\n",
       "    'model': [54],\n",
       "    'scores': [55, 58],\n",
       "    'translation': [57, 62, 69, 92, 98],\n",
       "    'to': [59, 65, 109],\n",
       "    'refine': [60],\n",
       "    'hypotheses': [63],\n",
       "    'determine': [66],\n",
       "    'best': [68],\n",
       "    'candidate.': [70],\n",
       "    'This': [71],\n",
       "    'Bayesian-guided': [72],\n",
       "    'then': [76],\n",
       "    'embedded': [77],\n",
       "    'into': [78],\n",
       "    'training': [80],\n",
       "    'process': [81],\n",
       "    'that': [82, 125],\n",
       "    'jointly': [83],\n",
       "    'learns': [84],\n",
       "    'parameters': [86],\n",
       "    'recognition': [89],\n",
       "    'machine': [91],\n",
       "    'sub-systems': [93],\n",
       "    'overall': [96],\n",
       "    'system.': [99],\n",
       "    'resulting': [101],\n",
       "    'takes': [104],\n",
       "    'functional': [106],\n",
       "    'form': [107],\n",
       "    'similar': [108],\n",
       "    'minimum': [111],\n",
       "    'classification': [112],\n",
       "    'error': [113],\n",
       "    'training.': [114],\n",
       "    'Experimental': [115],\n",
       "    'results': [116],\n",
       "    'obtained': [117],\n",
       "    'IWSLT': [120],\n",
       "    'DIALOG': [121],\n",
       "    '2010': [122],\n",
       "    'database': [123],\n",
       "    'showed': [124],\n",
       "    'system': [128, 132],\n",
       "    'outperformed': [129],\n",
       "    'baseline': [131],\n",
       "    'terms': [134],\n",
       "    'BLEU': [136],\n",
       "    'score': [137],\n",
       "    'by': [138],\n",
       "    '2.3': [139],\n",
       "    'points.': [140]}}},\n",
       " {'paper_name': 'combining heterogeneous models for measuring relational similarity.',\n",
       "  'citation': 26,\n",
       "  'abstract': {'IndexLength': 87,\n",
       "   'InvertedIndex': {'In': [0],\n",
       "    'this': [1],\n",
       "    'work,': [2],\n",
       "    'we': [3, 27],\n",
       "    'study': [4],\n",
       "    'the': [5, 21, 62, 73],\n",
       "    'problem': [6],\n",
       "    'of': [7, 24, 46, 64],\n",
       "    'measuring': [8],\n",
       "    'relational': [9, 50],\n",
       "    'similarity': [10, 51],\n",
       "    'between': [11],\n",
       "    'two': [12, 47],\n",
       "    'word': [13, 56],\n",
       "    'pairs': [14],\n",
       "    '(e.g.,': [15],\n",
       "    'silverware:fork': [16],\n",
       "    'and': [17, 53],\n",
       "    'clothing:shirt).': [18],\n",
       "    'Due': [19],\n",
       "    'to': [20, 33],\n",
       "    'large': [22],\n",
       "    'number': [23],\n",
       "    'possible': [25],\n",
       "    'relations,': [26],\n",
       "    'argue': [28],\n",
       "    'that': [29],\n",
       "    'it': [30],\n",
       "    'is': [31],\n",
       "    'important': [32],\n",
       "    'combine': [34],\n",
       "    'multiple': [35],\n",
       "    'models': [36, 52],\n",
       "    'based': [37],\n",
       "    'on': [38],\n",
       "    'heterogeneous': [39],\n",
       "    'information': [40],\n",
       "    'sources.': [41],\n",
       "    'Our': [42],\n",
       "    'overall': [43],\n",
       "    'system': [44, 76],\n",
       "    'consists': [45],\n",
       "    'novel': [48],\n",
       "    'general-purpose': [49],\n",
       "    'three': [54],\n",
       "    'specific': [55],\n",
       "    'relation': [57],\n",
       "    'models.': [58],\n",
       "    'When': [59],\n",
       "    'evaluated': [60],\n",
       "    'in': [61, 83],\n",
       "    'setting': [63],\n",
       "    'a': [65, 79],\n",
       "    'recently': [66],\n",
       "    'proposed': [67],\n",
       "    'SemEval-2012': [68],\n",
       "    'task,': [69],\n",
       "    'our': [70],\n",
       "    'approach': [71],\n",
       "    'outperforms': [72],\n",
       "    'previous': [74],\n",
       "    'best': [75],\n",
       "    'substantially,': [77],\n",
       "    'achieving': [78],\n",
       "    '54.1%': [80],\n",
       "    'relative': [81],\n",
       "    'increase': [82],\n",
       "    'Spearman’s': [84],\n",
       "    'rank': [85],\n",
       "    'correlation.': [86]}}},\n",
       " {'paper_name': 'bilingual word embeddings for phrase-based machine translation.',\n",
       "  'citation': 237,\n",
       "  'abstract': {'IndexLength': 74,\n",
       "   'InvertedIndex': {'We': [0, 18],\n",
       "    'introduce': [1],\n",
       "    'bilingual': [2, 24, 57],\n",
       "    'word': [3, 34, 47],\n",
       "    'embeddings:': [4],\n",
       "    'semantic': [5, 48, 52],\n",
       "    'embeddings': [6, 25, 42, 58],\n",
       "    'associated': [7],\n",
       "    'across': [8],\n",
       "    'two': [9],\n",
       "    'languages': [10],\n",
       "    'in': [11, 46],\n",
       "    'the': [12, 66],\n",
       "    'context': [13],\n",
       "    'of': [14, 68],\n",
       "    'neural': [15],\n",
       "    'language': [16],\n",
       "    'models.': [17],\n",
       "    'propose': [19],\n",
       "    'a': [20, 27, 62],\n",
       "    'method': [21],\n",
       "    'to': [22, 36, 65],\n",
       "    'learn': [23],\n",
       "    'from': [26],\n",
       "    'large': [28],\n",
       "    'unlabeled': [29],\n",
       "    'corpus,': [30],\n",
       "    'while': [31],\n",
       "    'utilizing': [32],\n",
       "    'MT': [33],\n",
       "    'alignments': [35],\n",
       "    'constrain': [37],\n",
       "    'translational': [38],\n",
       "    'equivalence.': [39],\n",
       "    'The': [40],\n",
       "    'new': [41],\n",
       "    'significantly': [43],\n",
       "    'out-perform': [44],\n",
       "    'baselines': [45],\n",
       "    'similarity.': [49],\n",
       "    'A': [50],\n",
       "    'single': [51],\n",
       "    'similarity': [53],\n",
       "    'feature': [54],\n",
       "    'induced': [55],\n",
       "    'with': [56],\n",
       "    'adds': [59],\n",
       "    'near': [60],\n",
       "    'half': [61],\n",
       "    'BLEU': [63],\n",
       "    'point': [64],\n",
       "    'results': [67],\n",
       "    'NIST08': [69],\n",
       "    'Chinese-English': [70],\n",
       "    'machine': [71],\n",
       "    'translation': [72],\n",
       "    'task.': [73]}}}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paper_info[\"P14-1066\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "18067\n"
     ]
    }
   ],
   "source": [
    "dataset = []\n",
    "c = 0\n",
    "cbert = 0\n",
    "for key in ids_consider :\n",
    "    papers = cit_titles[key]\n",
    "    for paper in papers :\n",
    "        data = {}\n",
    "        data['paper_id'] = key\n",
    "        data['citation_title'] = paper\n",
    "        \n",
    "        if(key in bert_embeddings):\n",
    "            embedding_found = 0\n",
    "            for pap in bert_embeddings[key] :\n",
    "                if(pap['paper_name']==paper) :\n",
    "                    cbert+=1\n",
    "                    data['bert_embed'] = pap['embedding']\n",
    "                    embedding_found = 1\n",
    "                    break\n",
    "                    \n",
    "            if(embedding_found==1) :\n",
    "                info_found = 0\n",
    "                for pap in abs_sim[key] :\n",
    "                    if(pap['paper_name']==paper) :\n",
    "                        data['abs_sim'] = pap['abs_sim']\n",
    "                        info_found = 1\n",
    "                        break\n",
    "                if(info_found==1) :\n",
    "                    for pap in paper_info[key] :\n",
    "                        if(pap['paper_name']==paper) :\n",
    "                            data['citation_count'] = pap['citation']\n",
    "                            try :\n",
    "                                data['citation_count'] = int(data['citation_count'])\n",
    "                            except :\n",
    "                                data['citation_count'] = 0\n",
    "                    for pap in location_feature[key]:\n",
    "                        if(pap['paper_name']==paper) :\n",
    "                            data['location_feature'] = pap['location_feature']\n",
    "                            break\n",
    "\n",
    "                    for pap in num_table[key]:\n",
    "                        if(pap['paper_name']==paper) :\n",
    "                            data['num_table'] = pap['num_table']\n",
    "                            break\n",
    "\n",
    "\n",
    "                    for pap in year_diff[key]:\n",
    "                        if(pap['paper_name']==paper) :\n",
    "                            data['year_diff'] = pap['diff']\n",
    "                            break\n",
    "\n",
    "                    for pap in title_overlap[key]:\n",
    "                        if(pap['paper_name']==paper) :\n",
    "                            data['title_overlap'] = pap['overlap']\n",
    "                            break\n",
    "\n",
    "                    for pap in popularity[key]:\n",
    "                        if(pap['paper_name']==paper) :\n",
    "                            data['popularity'] = pap['popularity']\n",
    "                            break\n",
    "\n",
    "                    for pap in context_count[key]:\n",
    "                        if(pap['paper_name']==paper) :\n",
    "                            data['context_count'] = pap['context_count']\n",
    "                            break\n",
    "\n",
    "                    for pap in contexts[key] :\n",
    "                        if(pap['paper_name']==paper) :\n",
    "                            data['context'] = pap['context']\n",
    "                            break\n",
    "\n",
    "                    for pap in cue_words[key]:\n",
    "                        if(pap['paper_name']==paper) :\n",
    "                            data['cue_count'] = pap['cue_count']\n",
    "                            break\n",
    "\n",
    "                    for pap in weighted_cue[key]:\n",
    "                        if(pap['paper_name']==paper) :\n",
    "                            max_data = pap['cue_weights_max']\n",
    "                            data['wcue_max'] = []\n",
    "                            for key1 in max_data :\n",
    "                                data['wcue_max'].append(max_data[key1])\n",
    "                            add_data = pap['cue_weights_add']\n",
    "                            data['wcue_add'] = []\n",
    "                            for key1 in add_data :\n",
    "                                data['wcue_add'].append(add_data[key1])\n",
    "                            break\n",
    "\n",
    "                    for pap in tags[key]:\n",
    "                        if(pap['paper_name']==paper) :\n",
    "                            if(pap['tag']==1):\n",
    "                                data['label'] = 'baseline'\n",
    "                            else :\n",
    "                                data['label'] = 'non_baseline'\n",
    "                            break\n",
    "\n",
    "                    for pap in fixed_context[key]:\n",
    "                        if(pap['paper_name']==paper) :\n",
    "                            data['fixed_context'] = pap['fixed_context']                   \n",
    "                    dataset.append(data)   \n",
    "        \n",
    "print(c)\n",
    "print(cbert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13166\n"
     ]
    }
   ],
   "source": [
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13160\n"
     ]
    }
   ],
   "source": [
    "final_dataset = []\n",
    "for data in dataset :\n",
    "    if(data['context_count']!=0):\n",
    "        final_dataset.append(data)\n",
    "print(len(final_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = final_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = dataset[:int(0.8*len(dataset))]\n",
    "testset = dataset[int(0.8*len(dataset)):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sanity_check(probs):\n",
    "\n",
    "\tsum = 0\n",
    "\tfor key, value in probs.items():\n",
    "\t\tsum+=value\n",
    "\tsum = round(sum, 7)\n",
    "\treturn sum==1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lm_model(trainset, testset):\n",
    "\n",
    "    word_baseline_frequency = {}\n",
    "    word_non_baseline_frequency = {}\n",
    "    baseline_length = 0\n",
    "    non_baseline_length = 0\n",
    "\n",
    "    for i in trainset:\n",
    "        # if len(i['fixed_context'])>1 and i['label']=='baseline':\n",
    "        # \tcontinue\n",
    "        for context in i['fixed_context']:\n",
    "            if i['label']=='baseline':\n",
    "                baseline_length+=len(context)\n",
    "            else:\n",
    "                non_baseline_length+=len(context)\n",
    "            for word in context:\n",
    "                if word not in word_baseline_frequency:\n",
    "                    word_baseline_frequency[word] = 0\n",
    "                    word_non_baseline_frequency[word] = 0\n",
    "                if i['label']=='baseline':\n",
    "                    word_baseline_frequency[word]+=1\n",
    "                else:\n",
    "                    word_non_baseline_frequency[word]+=1\n",
    "\n",
    "    final_word_baseline_frequency = {}\n",
    "    final_word_baseline_frequency['<unk>'] = 0\n",
    "    word_non_baseline_frequency['<unk>'] = 0\n",
    "\n",
    "    for word in word_baseline_frequency:\n",
    "        if word_baseline_frequency[word]>5:\t\n",
    "            final_word_baseline_frequency[word] = word_baseline_frequency[word]\n",
    "        else:\n",
    "            final_word_baseline_frequency['<unk>'] += word_baseline_frequency[word]\n",
    "            word_non_baseline_frequency['<unk>'] += word_non_baseline_frequency[word]\n",
    "            del word_non_baseline_frequency[word]\n",
    "\n",
    "    word_baseline_frequency = final_word_baseline_frequency\n",
    "\n",
    "    word_baseline_probability = {}\n",
    "    word_non_baseline_probability = {}\n",
    "\n",
    "    for word in word_baseline_frequency:\n",
    "        word_baseline_probability[word] = (word_baseline_frequency[word]+1)/(baseline_length+len(word_baseline_frequency))\n",
    "        word_non_baseline_probability[word] = (word_non_baseline_frequency[word]+1)/(non_baseline_length+len(word_non_baseline_frequency))\n",
    "\n",
    "    # print(word_baseline_probability['<unk>'])\n",
    "    # print(word_non_baseline_probability['<unk>'])\n",
    "\n",
    "    assert sanity_check(word_baseline_probability) and sanity_check(word_non_baseline_probability)\n",
    "\n",
    "    conf_mat1 = np.zeros((2,2))\n",
    "    conf_mat2 = np.zeros((2,2))\n",
    "\n",
    "    min_p = 1\n",
    "\n",
    "    for i in trainset+testset:\n",
    "        P_b = 0\n",
    "        P_nb = 0\n",
    "        maxP_b = 0\n",
    "        minP_nb = 1\n",
    "        n_better = 0\n",
    "        for context in i['fixed_context']:\n",
    "            \n",
    "            P_b_con = 1\n",
    "            P_nb_con = 1\n",
    "            for word in context:\n",
    "                if word not in word_baseline_probability:\n",
    "                    P_b_con*=word_baseline_probability['<unk>']\n",
    "                    P_nb_con*=word_non_baseline_probability['<unk>']\n",
    "                else:\n",
    "                    P_b_con*=word_baseline_probability[word]\n",
    "                    P_nb_con*=word_non_baseline_probability[word]\n",
    "            if P_b_con>P_nb_con:\n",
    "                n_better+=1\n",
    "            P_b+=P_b_con\n",
    "            P_nb+=P_nb_con\n",
    "            maxP_b = max(P_b, P_b_con)\n",
    "            minP_nb = min(P_nb, P_nb_con)\n",
    "            P_b/=len(i['fixed_context'])\n",
    "            P_nb/=len(i['fixed_context'])\n",
    "\n",
    "        # if P_b>P_nb:\n",
    "        # \tprint('yes')\n",
    "\n",
    "        # i['P_b'] = P_b\n",
    "        # i['P_nb'] = P_nb\n",
    "        min_p = min(min_p, P_b, P_nb)\n",
    "        i['lmp'] = [P_b, P_nb, maxP_b, minP_nb, P_b/P_nb, maxP_b/minP_nb, n_better]\n",
    "\n",
    "    for i in trainset:\t\n",
    "        # if len(i['fixed_context'])>1 and i['label']=='baseline':\n",
    "        # \ttestset.append(i)\n",
    "        # \tcontinue\n",
    "        i['lmp'][0]/=min_p\n",
    "        i['lmp'][1]/=min_p\n",
    "        i['lmp'][2]/=min_p\n",
    "        i['lmp'][3]/=min_p\n",
    "        if i['lmp'][0]>i['lmp'][1]:\n",
    "            if i['label']=='baseline':\n",
    "                conf_mat1[0, 0]+=1\n",
    "            else:\n",
    "                conf_mat1[0, 1]+=1\n",
    "        else:\n",
    "            if i['label']=='baseline':\n",
    "                conf_mat1[1, 0]+=1\n",
    "            else:\n",
    "                conf_mat1[1, 1]+=1\n",
    "        if i['lmp'][2]>i['lmp'][3]:\n",
    "            if i['label']=='baseline':\n",
    "                conf_mat2[0, 0]+=1\n",
    "            else:\n",
    "                conf_mat2[0, 1]+=1\n",
    "        else:\n",
    "            if i['label']=='baseline':\n",
    "                conf_mat2[1, 0]+=1\n",
    "            else:\n",
    "                conf_mat2[1, 1]+=1\n",
    "\n",
    "    # print(conf_mat1)\n",
    "    prec = conf_mat1[0,0]/(conf_mat1[0,0]+conf_mat1[0,1])\n",
    "    rec = conf_mat1[0,0]/(conf_mat1[0,0]+conf_mat1[1,0])\n",
    "    print(prec, rec, 2*prec*rec/(prec+rec))\n",
    "    conf_mat1 = np.zeros((2,2))\n",
    "\n",
    "    # print(conf_mat2)\n",
    "    prec = conf_mat2[0,0]/(conf_mat2[0,0]+conf_mat2[0,1])\n",
    "    rec = conf_mat2[0,0]/(conf_mat2[0,0]+conf_mat2[1,0])\n",
    "    print(prec, rec, 2*prec*rec/(prec+rec))\n",
    "#     conf_mat2 = np.zeros((2,2))\n",
    "\n",
    "    for i in testset:\n",
    "        i['lmp'][0]/=min_p\n",
    "        i['lmp'][1]/=min_p\n",
    "        i['lmp'][2]/=min_p\n",
    "        i['lmp'][3]/=min_p\n",
    "        if i['lmp'][0]>i['lmp'][1]:\n",
    "            if i['label']=='baseline':\n",
    "                conf_mat1[0, 0]+=1\n",
    "            else:\n",
    "                conf_mat1[0, 1]+=1\n",
    "        else:\n",
    "            if i['label']=='baseline':\n",
    "                conf_mat1[1, 0]+=1\n",
    "            else:\n",
    "                conf_mat1[1, 1]+=1\n",
    "        if i['lmp'][2]>i['lmp'][3]:\n",
    "            if i['label']=='baseline':\n",
    "                conf_mat2[0, 0]+=1\n",
    "            else:\n",
    "                conf_mat2[0, 1]+=1\n",
    "        else:\n",
    "            if i['label']=='baseline':\n",
    "                conf_mat2[1, 0]+=1\n",
    "            else:\n",
    "                conf_mat2[1, 1]+=1\n",
    "\n",
    "    # print(conf_mat1)\n",
    "    prec = conf_mat1[0,0]/(conf_mat1[0,0]+conf_mat1[0,1])\n",
    "    rec = conf_mat1[0,0]/(conf_mat1[0,0]+conf_mat1[1,0])\n",
    "    print(prec, rec, 2*prec*rec/(prec+rec))\n",
    "    conf_mat1 = np.zeros((2,2))\n",
    "\n",
    "    # print(conf_mat2)\n",
    "    prec = conf_mat2[0,0]/(conf_mat2[0,0]+conf_mat2[0,1])\n",
    "    rec = conf_mat2[0,0]/(conf_mat2[0,0]+conf_mat2[1,0])\n",
    "    print(prec, rec, 2*prec*rec/(prec+rec))\n",
    "    conf_mat2 = np.zeros((2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3067484662576687 0.7005253940455342 0.4266666666666666\n",
      "0.26787648970747563 0.8660245183887916 0.4091849400082747\n",
      "0.2803030303030303 0.6006493506493507 0.38223140495867763\n",
      "0.2671277285498163 0.8524137931034482 0.4067796610169492\n"
     ]
    }
   ],
   "source": [
    "lm_model(trainset,testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def context_feature(trainset, testset) :\n",
    "#     total_counts = {}\n",
    "#     citation_frequency = {}\n",
    "#     paper_frequency = {}\n",
    "#     curr_doc = trainset[0]['paper_id']\n",
    "#     paper_words = set([])\n",
    "\n",
    "#     for i in trainset:\n",
    "#         if i['paper_id']!=curr_doc:\n",
    "#             for word in paper_words:\n",
    "#                 if word not in paper_frequency:\n",
    "#                     paper_frequency[word] = 0\n",
    "#                 paper_frequency[word]+=1\n",
    "#             paper_words = set([])\n",
    "#             curr_doc = i['paper_id']\n",
    "#         words = set(i['context'])\n",
    "#         paper_words = paper_words.union(words)\n",
    "#         for word in words:\n",
    "#             if word not in total_counts:\n",
    "#                 total_counts[word] = 0\n",
    "#                 citation_frequency[word] = 0\n",
    "#             citation_frequency[word]+=1\n",
    "#         counts = {word:0 for word in words}\n",
    "#         for word in i['context']:\n",
    "#             counts[word]+=1\n",
    "#             total_counts[word]+=1\n",
    "\n",
    "#     for word in paper_words:\n",
    "#         if word not in paper_frequency:\n",
    "#             paper_frequency[word] = 0\n",
    "#         paper_frequency[word]+=1\n",
    "\n",
    "#     final_citation_frequency = {word:count for word, count in citation_frequency.items()}\n",
    "#     for i in citation_frequency:\n",
    "#         if paper_frequency[i]<=20:\n",
    "#             del total_counts[i]\n",
    "#             del final_citation_frequency[i]\n",
    "\n",
    "#     citation_frequency = final_citation_frequency\n",
    "    \n",
    "#     dataset = trainset+testset\n",
    "    \n",
    "#     idfs = {}\n",
    "\n",
    "#     for word in citation_frequency:\n",
    "#         idfs[word] = math.log10(len(dataset)*0.8/citation_frequency[word])\n",
    "    \n",
    "#     total_counts['<unk>'] = 0\n",
    "    \n",
    "#     for i in range(len(dataset)):\n",
    "#         words = set(dataset[i]['context']) & set(total_counts.keys())\n",
    "#         unigram_counts = {word:0 for word in words}\n",
    "#         try:\t\n",
    "#             del unigram_counts['<SOS>']\n",
    "#             del unigram_counts['<EOS>']\n",
    "#         except:\n",
    "#             pass\n",
    "\n",
    "#         for j in range(len(dataset[i]['context'])):\n",
    "#             word = dataset[i]['context'][j]\n",
    "#             if word not in unigram_counts:\n",
    "#                 continue\n",
    "#             else:\n",
    "#                 unigram_counts[word]+=1-dataset[i]['distances'][j]\n",
    "\n",
    "\n",
    "#         dataset[i]['unigrams'] = unigram_counts\n",
    "\n",
    "\n",
    "#     total_unigram_counts = total_counts\n",
    "#     features = list(total_unigram_counts.keys())\n",
    "#     ngram_to_idx = {features[i]:i for i in range(len(features))}\n",
    "    \n",
    "#     pickle.dump(total_counts, open('pickles/total_counts.pkl', 'wb'))\n",
    "#     pickle.dump(dataset, open('pickles/data_ngram.pkl', 'wb'))\n",
    "#     pickle.dump(ngram_to_idx, open('pickles/ngram_to_idx.pkl', 'wb'))\n",
    "#     pickle.dump(idfs, open('pickles/idfs.pkl', 'wb'))\n",
    "    \n",
    "#     data_mat = np.zeros((len(dataset), len(ngram_to_idx)+35+1+5+1))\n",
    "\n",
    "#     for i in range(len(dataset)):\n",
    "#         context_counts = {}\n",
    "#         for word in dataset[i]['unigrams']:\n",
    "#             if word not in context_counts:\n",
    "#                 context_counts[word] = 0\n",
    "#             context_counts[word]+=dataset[i]['unigrams'][word]\n",
    "#             if word in idfs:\n",
    "#                 data_mat[i, ngram_to_idx[word]] = dataset[i]['unigrams'][word]\n",
    "\n",
    "#         dataset[i]['context_feature'] = data_mat[i, :len(ngram_to_idx)]\n",
    "        \n",
    "#     return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = context_feature(trainset, testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = trainset+testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = []\n",
    "output = []\n",
    "for data in dataset :\n",
    "    ar = []\n",
    "    ar.append(data['context_count'])\n",
    "    ar.append(data['title_overlap'])\n",
    "    ar.append(data['citation_count'])\n",
    "#     ar.append(data['abs_sim'])\n",
    "#     ar.append(data['cue_count'])\n",
    "#     ar.append(sum(data['location_feature']))\n",
    "#     ar.append(data['popularity'])\n",
    "    ar.append(data['num_table'])\n",
    "    ar.extend(data['location_feature'])\n",
    "    ar.extend(data['lmp'])\n",
    "    ar.extend(data['wcue_max'])\n",
    "    ar.extend(data['bert_embed'])\n",
    "    values.append(ar)\n",
    "    if(data['label']=='baseline'):\n",
    "        output.append(1)\n",
    "    else :\n",
    "        output.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = np.array(values)\n",
    "output = np.array(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13160, 317)\n"
     ]
    }
   ],
   "source": [
    "print(values.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# std_scale = MinMaxScaler((0,1))\n",
    "# values[:,0:-6] = std_scale.fit_transform(values[:,0:-6])\n",
    "scaler = MinMaxScaler((0,1))\n",
    "values = scaler.fit_transform(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(data, output):\n",
    "    n = len(data)\n",
    "    last = int(0.8*n)\n",
    "    train_data = data[:last]\n",
    "    train_output = output[:last]\n",
    "    test_data = data[last:]\n",
    "    test_output = output[last:]\n",
    "    return train_data, test_data, train_output, test_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data, train_output, test_output = split(values, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle(train_data, train_output) :\n",
    "    baselines = []\n",
    "    non_baselines = []\n",
    "    for i in range(len(train_output)) :\n",
    "        if(train_output[i]==1) :\n",
    "            baselines.append(train_data[i])\n",
    "        else :\n",
    "            non_baselines.append(train_data[i])\n",
    "    \n",
    "    n = len(baselines)\n",
    "    ar = np.random.choice(len(non_baselines), len(baselines))\n",
    "    nb_ar = []\n",
    "    for x in ar :\n",
    "        nb_ar.append(non_baselines[x])\n",
    "        \n",
    "    data = []\n",
    "    data.extend(nb_ar)\n",
    "    output = []\n",
    "    for i in range(len(data)):\n",
    "        output.append(0)\n",
    "    \n",
    "    data.extend(baselines)\n",
    "    for i in range(n) :\n",
    "        output.append(1)\n",
    "        \n",
    "    total_data = []\n",
    "    for i in range(len(data)):\n",
    "        ar = []\n",
    "        ar.append(data[i])\n",
    "        ar.append(output[i])\n",
    "        total_data.append(ar)\n",
    "        \n",
    "    total_data = np.array(total_data)\n",
    "    np.random.shuffle(total_data)\n",
    "    \n",
    "    data = []\n",
    "    output = []\n",
    "    for ar in total_data :\n",
    "        data.append(ar[0])\n",
    "        output.append(ar[1])\n",
    "        \n",
    "    data = np.array(data)\n",
    "    output = np.array(output)\n",
    "    \n",
    "    return data, output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, train_output = shuffle(train_data, train_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.88      0.92      2324\n",
      "           1       0.47      0.82      0.60       308\n",
      "\n",
      "    accuracy                           0.87      2632\n",
      "   macro avg       0.72      0.85      0.76      2632\n",
      "weighted avg       0.92      0.87      0.89      2632\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.93      0.92      1142\n",
      "           1       0.93      0.91      0.92      1142\n",
      "\n",
      "    accuracy                           0.92      2284\n",
      "   macro avg       0.92      0.92      0.92      2284\n",
      "weighted avg       0.92      0.92      0.92      2284\n",
      "\n",
      "{'C': 2, 'fit_intercept': True}\n"
     ]
    }
   ],
   "source": [
    "params = {'C':[0.1, 0.5, 1, 2], 'fit_intercept':[True, False]}\n",
    "modelin = LogisticRegression(solver='lbfgs', max_iter=1e4, n_jobs=5, random_state=1, warm_start=False, C=1)\n",
    "model = GridSearchCV(modelin, params, cv=2, n_jobs=5)\n",
    "#model = LogisticRegression(solver='lbfgs',max_iter=1e4, n_jobs=5, random_state=1, warm_start=False, C=1, fit_intercept=True)\n",
    "clf = model.fit(train_data, train_output)\n",
    "predict_test = clf.predict(test_data)\n",
    "print(classification_report(test_output, predict_test))\n",
    "predictions = clf.predict(train_data)\n",
    "print(classification_report(train_output, predictions))\n",
    "print(model.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sum(test_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sum(train_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
