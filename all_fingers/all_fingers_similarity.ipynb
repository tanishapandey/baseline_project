{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pickle\n",
    "import json\n",
    "import xml.etree.ElementTree as ET\n",
    "from nltk.corpus import stopwords, wordnet as wn\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "import os\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "import numpy as np\n",
    "import math\n",
    "from difflib import SequenceMatcher\n",
    "import pandas as pd\n",
    "from statistics import stdev\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "section_labels = pickle.load(open(\"../pickles_data/section_labels.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_citations(folder) :\n",
    "    citation_list = {}\n",
    "    for file in os.listdir(folder) :\n",
    "        tree = ET.parse(folder+file)\n",
    "        root = tree.getroot()\n",
    "        id = file[:8]\n",
    "        for element in root.iterfind(\"algorithm\"):\n",
    "            if(element.attrib['name']==\"ParsCit\"):\n",
    "                citlist = element.getchildren()\n",
    "                cits = citlist[0].getchildren()\n",
    "                citations = []\n",
    "                for cit in cits:\n",
    "                    cit_dict = {}\n",
    "                    if(cit.attrib['valid']==\"true\"):\n",
    "                        try :\n",
    "                            title = cit.find('title').text.lower()\n",
    "                        except :\n",
    "                            title = cit.find('rawString').text.lower()\n",
    "                        cit_dict['title'] = title\n",
    "                        cit_dict['cit'] = cit\n",
    "                        cit_dict['context'] = \" \".join([context.text.lower() for context in cit.findall('contexts/context')])\n",
    "                        citations.append(cit_dict)\n",
    "                \n",
    "                citation_list[id] = citations\n",
    "            \n",
    "    return citation_list \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "citations = get_citations(\"../xmls/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_to_pap = {}\n",
    "pap_to_ind = {}\n",
    "contexts = []\n",
    "title = []\n",
    "paper_title = []\n",
    "paper_abs = []\n",
    "paper_conc = []\n",
    "paper_rest = []\n",
    "paper_intro = []\n",
    "\n",
    "count = 0\n",
    "for key in citations :\n",
    "    papers = citations[key]\n",
    "    section = section_labels[key]\n",
    "    for paper in papers :\n",
    "        contexts.append(paper['context'])\n",
    "        title.append(paper['title'])\n",
    "        abstract = section['abstract']['overall'].lower()\n",
    "        conc = section['conclusion']['overall'].lower()\n",
    "        intro = section['introduction']['overall'].lower()\n",
    "        paper_abs.append(abstract)\n",
    "        paper_conc.append(conc)\n",
    "        paper_intro.append(intro)\n",
    "        full_text = section['overall']\n",
    "        full_text = full_text.replace(abstract, \"\")\n",
    "        full_text = full_text.replace(conc, \"\")\n",
    "        full_text = full_text.replace(intro, \"\")\n",
    "        paper_rest.append(full_text)\n",
    "        ind_to_pap[count] = key+\"_\"+paper['title']\n",
    "        pap_to_ind[key+\"_\"+paper['title']]=count\n",
    "        count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31943\n",
      "31943\n",
      "31943\n",
      "31943\n",
      "31943\n",
      "31943\n"
     ]
    }
   ],
   "source": [
    "print(count)\n",
    "print(len(contexts))\n",
    "print(len(title))\n",
    "print(len(paper_abs))\n",
    "print(len(paper_conc))\n",
    "print(len(paper_rest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P10-1026\n"
     ]
    }
   ],
   "source": [
    "print(list(section_labels.keys())[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['overall', 'experiment', 'conclusion', 'discussion', 'other_sections', 'related_work', 'abstract', 'introduction'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "section_labels['P10-1026'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_matrix = TfidfVectorizer(stop_words = 'english', min_df = 0.01, token_pattern='[a-zA-Z]+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63886\n"
     ]
    }
   ],
   "source": [
    "corpus = []\n",
    "corpus.extend(contexts)\n",
    "corpus.extend(paper_rest)\n",
    "print(len(corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = raw_matrix.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31943\n"
     ]
    }
   ],
   "source": [
    "outputs = []\n",
    "for i in range(31943) :\n",
    "    outputs.append(cosine_similarity(matrix[i],matrix[i+31943]))\n",
    "\n",
    "print(len(outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(outputs, open(\"pickles/alf_sim_con_rest_out.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n"
     ]
    }
   ],
   "source": [
    "dataset = {}\n",
    "count = 0\n",
    "for i in range(len(outputs)) :\n",
    "    pap = ind_to_pap[i]\n",
    "    key = pap.split(\"_\")[0]\n",
    "    name = pap.split(\"_\")[1]\n",
    "    dict1 = {}\n",
    "    dict1['paper_name'] = name\n",
    "    dict1['data'] = outputs[i]\n",
    "    if(key not in dataset) :\n",
    "        dataset[key] = []\n",
    "    dataset[key].append(dict1)\n",
    "    count+=1\n",
    "    if(count%1000==0) :\n",
    "        print(count) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1172\n"
     ]
    }
   ],
   "source": [
    "print(len(dataset.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1181\n"
     ]
    }
   ],
   "source": [
    "print(len(citations.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(dataset, open(\"pickles/alf_sim_con_rest_data.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
