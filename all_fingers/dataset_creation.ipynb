{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, ComplementNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import svm\n",
    "import random\n",
    "import math\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_feat = pickle.load(open(\"pickles/alf_context_feat.pkl\", \"rb\"))\n",
    "location_feat = pickle.load(open(\"pickles/alf_location.pkl\", \"rb\"))\n",
    "pos_feat = pickle.load(open(\"pickles/alf_pos_feat.pkl\", \"rb\"))\n",
    "year_diff = pickle.load(open(\"pickles/year_diff.pkl\", \"rb\"))\n",
    "sync = pickle.load(open(\"pickles/en_synctatic_feat.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1 = pickle.load(open(\"pickles/alf_sim_con_abs_data.pkl\", \"rb\"))\n",
    "a2 = pickle.load(open(\"pickles/alf_sim_con_intro_data.pkl\", \"rb\"))\n",
    "a3 = pickle.load(open(\"pickles/alf_sim_con_conc_data.pkl\", \"rb\"))\n",
    "a4 = pickle.load(open(\"pickles/alf_sim_con_rest_data.pkl\", \"rb\"))\n",
    "a5 = pickle.load(open(\"pickles/alf_sim_title_abs_data.pkl\", \"rb\"))\n",
    "a6 = pickle.load(open(\"pickles/alf_sim_title_intro_data.pkl\", \"rb\"))\n",
    "a7 = pickle.load(open(\"pickles/alf_sim_title_conc_data.pkl\", \"rb\"))\n",
    "a8 = pickle.load(open(\"pickles/alf_sim_title_rest_data.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = pickle.load(open(\"../pickles_data/baseline_tags.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = []\n",
    "output = []\n",
    "for key in tags :\n",
    "    if key in a1 :\n",
    "        papers = tags[key]\n",
    "        for pap1 in papers :\n",
    "            paper = pap1['paper_name']\n",
    "            data = []\n",
    "\n",
    "            for pap in context_feat[key]:\n",
    "                if(pap['paper_name']==paper) :\n",
    "                    data.extend(pap['context_feat'])\n",
    "                    break\n",
    "\n",
    "            for pap in location_feat[key]:\n",
    "                if(pap['paper_name']==paper) :\n",
    "                    data.append(pap['whole'])\n",
    "                    data.append(pap['intro'])\n",
    "                    data.append(pap['relwork'])\n",
    "                    data.append(pap['rest'])\n",
    "                    break\n",
    "\n",
    "            for pap in pos_feat[key] :\n",
    "                if(pap['paper_name']==paper) :\n",
    "                    data.extend(pap['position_feat'])\n",
    "                    break\n",
    "\n",
    "\n",
    "            for pap in year_diff[key] :\n",
    "                if(pap['paper_name']==paper) :\n",
    "                    data.append(pap['diff'])\n",
    "                    break\n",
    "\n",
    "            for pap in a2[key] :\n",
    "                if(pap['paper_name']==paper) :\n",
    "                    for key1 in pap :\n",
    "                        if(key1!='paper_name') :\n",
    "                            data.append(pap[key1])\n",
    "                    break\n",
    "\n",
    "            for pap in a3[key] :\n",
    "                if(pap['paper_name']==paper) :\n",
    "                    for key1 in pap :\n",
    "                        if(key1!='paper_name') :\n",
    "                            data.append(pap[key1])\n",
    "                    break\n",
    "\n",
    "            for pap in a4[key] :\n",
    "                if(pap['paper_name']==paper) :\n",
    "                    for key1 in pap :\n",
    "                        if(key1!='paper_name') :\n",
    "                            data.append(pap[key1])\n",
    "                    break\n",
    "\n",
    "\n",
    "            for pap in a5[key] :\n",
    "                if(pap['paper_name']==paper) :\n",
    "                    for key1 in pap :\n",
    "                        if(key1!='paper_name') :\n",
    "                            data.append(pap[key1])\n",
    "                    break\n",
    "\n",
    "\n",
    "\n",
    "            for pap in a6[key] :\n",
    "                if(pap['paper_name']==paper) :\n",
    "                    for key1 in pap :\n",
    "                        if(key1!='paper_name') :\n",
    "                            data.append(pap[key1])\n",
    "                    break\n",
    "\n",
    "\n",
    "            for pap in a7[key] :\n",
    "                if(pap['paper_name']==paper) :\n",
    "                    for key1 in pap :\n",
    "                        if(key1!='paper_name') :\n",
    "                            data.append(pap[key1])\n",
    "                    break\n",
    "\n",
    "\n",
    "            for pap in a8[key] :\n",
    "                if(pap['paper_name']==paper) :\n",
    "                    for key1 in pap :\n",
    "                        if(key1!='paper_name') :\n",
    "                            data.append(pap[key1])\n",
    "                    break\n",
    "\n",
    "            for pap in a1[key] :\n",
    "                if(pap['paper_name']==paper) :\n",
    "                    for key1 in pap :\n",
    "                        if(key1!='paper_name') :\n",
    "                            data.append(pap[key1])\n",
    "                    break\n",
    "                    \n",
    "            for pap in sync[key] :\n",
    "                if(pap['paper_name']==paper) :\n",
    "                    bool_list = pap['pos_feat']\n",
    "                    feat_list = []\n",
    "                    for val in bool_list :\n",
    "                        if(val):\n",
    "                            feat_list.append(1)\n",
    "                        else :\n",
    "                            feat_list.append(0)\n",
    "                    data.extend(feat_list)\n",
    "                    break\n",
    "                    \n",
    "            if(len(data)==30) :\n",
    "                dataset.append(data)  \n",
    "                output.append(pap1['tag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27600\n",
      "27600\n"
     ]
    }
   ],
   "source": [
    "print(len(dataset))\n",
    "print(len(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, out = shuffle(dataset, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5474\n",
      "5474\n"
     ]
    }
   ],
   "source": [
    "print(len(out))\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = np.array(data)\n",
    "output = np.array(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5474, 30)\n",
      "(5474,)\n"
     ]
    }
   ],
   "source": [
    "print(values.shape)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler((0,1))\n",
    "values = scaler.fit_transform(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(data, output):\n",
    "    n = len(data)\n",
    "    last = int(0.8*n)\n",
    "    train_data = data[:last]\n",
    "    train_output = output[:last]\n",
    "    test_data = data[last:]\n",
    "    test_output = output[last:]\n",
    "    return train_data, test_data, train_output, test_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data, train_output, test_output = split(values, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle(train_data, train_output) :\n",
    "    baselines = []\n",
    "    non_baselines = []\n",
    "    for i in range(len(train_output)) :\n",
    "        if(train_output[i]==1) :\n",
    "            baselines.append(train_data[i])\n",
    "        else :\n",
    "            non_baselines.append(train_data[i])\n",
    "    \n",
    "    n = len(baselines)\n",
    "    ar = np.random.choice(len(non_baselines), len(baselines))\n",
    "    nb_ar = []\n",
    "    for x in ar :\n",
    "        nb_ar.append(non_baselines[x])\n",
    "        \n",
    "    data = []\n",
    "    data.extend(nb_ar)\n",
    "    output = []\n",
    "    for i in range(len(data)):\n",
    "        output.append(0)\n",
    "    \n",
    "    data.extend(baselines)\n",
    "    for i in range(n) :\n",
    "        output.append(1)\n",
    "        \n",
    "    total_data = []\n",
    "    for i in range(len(data)):\n",
    "        ar = []\n",
    "        ar.append(data[i])\n",
    "        ar.append(output[i])\n",
    "        total_data.append(ar)\n",
    "        \n",
    "    total_data = np.array(total_data)\n",
    "    np.random.shuffle(total_data)\n",
    "    \n",
    "    data = []\n",
    "    output = []\n",
    "    for ar in total_data :\n",
    "        data.append(ar[0])\n",
    "        output.append(ar[1])\n",
    "        \n",
    "    data = np.array(data)\n",
    "    output = np.array(output)\n",
    "    \n",
    "    return data, output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data, train_output = shuffle(train_data, train_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82       568\n",
      "           1       0.80      0.81      0.81       527\n",
      "\n",
      "    accuracy                           0.81      1095\n",
      "   macro avg       0.81      0.81      0.81      1095\n",
      "weighted avg       0.81      0.81      0.81      1095\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      2169\n",
      "           1       0.82      0.82      0.82      2210\n",
      "\n",
      "    accuracy                           0.81      4379\n",
      "   macro avg       0.81      0.81      0.81      4379\n",
      "weighted avg       0.81      0.81      0.81      4379\n",
      "\n",
      "{'C': 2}\n"
     ]
    }
   ],
   "source": [
    "params = {'C':[0.1, 0.5, 1, 2]}\n",
    "modelin = svm.SVC(kernel='rbf', max_iter=1e4, gamma='scale')\n",
    "model = GridSearchCV(modelin, params, cv=2, n_jobs=5)\n",
    "# model = LogisticRegression(solver='lbfgs',max_iter=1e4, n_jobs=5, random_state=1, warm_start=False, C=1, fit_intercept=True)\n",
    "clf = model.fit(train_data, train_output)\n",
    "predict_test = clf.predict(test_data)\n",
    "print(classification_report(test_output, predict_test))\n",
    "predictions = clf.predict(train_data)\n",
    "print(classification_report(train_output, predictions))\n",
    "print(model.best_params_)\n",
    "# print(type(model.best_estimator_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.         1.         1.         0.         0.         0.\n",
      " 0.02857143 0.125      0.         0.         1.         0.\n",
      " 0.02622169 0.         0.         0.74040879 0.27238365 0.2394133\n",
      " 0.         0.05875921 0.         0.04543682 0.35801768 0.\n",
      " 0.         0.         0.         1.         0.         0.        ]\n"
     ]
    }
   ],
   "source": [
    "print(values[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GraLap\n",
    "W = np.zeros((len(values),len(values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9940\n",
      "9940\n",
      "(9940, 30)\n",
      "(9940,)\n"
     ]
    }
   ],
   "source": [
    "td = list(train_data)\n",
    "testd = list(test_data)\n",
    "outd = list(train_output)\n",
    "outtd = list(test_output)\n",
    "td.extend(testd)\n",
    "outd.extend(outtd)\n",
    "print(len(td))\n",
    "print(len(outd))\n",
    "data = np.array(td)\n",
    "out = np.array(outd)\n",
    "print(data.shape)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "power_val = np.power(data, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "a =  power_val[np.newaxis,:,:]\n",
    "b = power_val[:,np.newaxis,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9940, 9940, 30)\n"
     ]
    }
   ],
   "source": [
    "# count = 0\n",
    "# power_val = np.power(values,len(values[0]))\n",
    "# diff = power_val[np.newaxis,:,:]-power_val[:,np.newaxis,:]\n",
    "# print(diff.shape)\n",
    "diff = a-b\n",
    "print(diff.shape)\n",
    "# for i in range(len(values)) :\n",
    "#     for j in range(len(values)) :\n",
    "#         sum1 = 0\n",
    "#         vi = power_val[i]\n",
    "#         vj = power_val[j]\n",
    "#         v = vi-vj\n",
    "#         v = np.sum(v)\n",
    "#         v = -1*v\n",
    "#         W[i][j] = np.exp(v)\n",
    "#     count+=1\n",
    "#     if(count%100==0) :\n",
    "#         print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9940, 9940)\n"
     ]
    }
   ],
   "source": [
    "diff = np.sum(diff, axis=2)\n",
    "print(diff.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = -1*diff\n",
    "diff = diff/9\n",
    "W = np.exp(diff)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9940, 9940)\n"
     ]
    }
   ],
   "source": [
    "print(W.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = np.zeros((len(values), len(values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = W/np.sum(W,axis=0, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.912564266225619e-05\n"
     ]
    }
   ],
   "source": [
    "print(T[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.912564266225701e-05\n"
     ]
    }
   ],
   "source": [
    "print(W[0][0]/np.sum(W[:,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlb = []\n",
    "for i in range(len(out)) :\n",
    "    if(i<len(train_data)) :\n",
    "        if(out[i]==0) :\n",
    "            outlb.append([1,0])\n",
    "        else :\n",
    "            outlb.append([0,1])\n",
    "    else :\n",
    "        outlb.append([0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9940, 2)\n"
     ]
    }
   ],
   "source": [
    "outlb = np.array(outlb)\n",
    "print(outlb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100) :\n",
    "    outlb = np.matmul(T, outlb)\n",
    "    outlb = outlb/np.sum(outlb, axis=1, keepdims=True)\n",
    "    for j in range(len(train_data)) :\n",
    "        if(out[j]==0) :\n",
    "            outlb[j][0]=1\n",
    "            outlb[j][1]=0\n",
    "        else :\n",
    "            outlb[j][0]=0\n",
    "            outlb[j][1]=1     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5520, 2)\n"
     ]
    }
   ],
   "source": [
    "test_out = outlb[len(train_data):]\n",
    "print(test_out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = []\n",
    "for i in range(len(test_out)):\n",
    "    if(test_out[i][0]>test_out[i][1]) :\n",
    "        test.append(0)\n",
    "    else :\n",
    "        test.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5077\n"
     ]
    }
   ],
   "source": [
    "print(sum(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.08      0.15      4993\n",
      "           1       0.10      0.92      0.17       527\n",
      "\n",
      "    accuracy                           0.16      5520\n",
      "   macro avg       0.50      0.50      0.16      5520\n",
      "weighted avg       0.83      0.16      0.15      5520\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_output, np.array(test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " ...\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]]\n"
     ]
    }
   ],
   "source": [
    "print(test_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
