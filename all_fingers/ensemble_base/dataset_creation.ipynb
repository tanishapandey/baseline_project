{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import random\n",
    "import math\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "section_feat = pickle.load(open(\"../pickles/en_section_feature.pkl\", \"rb\"))\n",
    "popular = pickle.load(open(\"../pickles/en_popularity.pkl\", \"rb\"))\n",
    "dens = pickle.load(open(\"../pickles/en_density.pkl\", \"rb\"))\n",
    "sync = pickle.load(open(\"../pickles/en_synctatic_feat.pkl\",\"rb\"))\n",
    "text_feat = pickle.load(open(\"../pickles/en_text_feat.pkl\", \"rb\"))\n",
    "tags = pickle.load(open(\"../../pickles_data/baseline_tags.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = list(section_feat.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1181"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = []\n",
    "for key in ids :\n",
    "    papers = section_feat[key]\n",
    "    for paper1 in papers :\n",
    "        data = {}\n",
    "        section_list = []\n",
    "        for section in paper1['section_feature'] :\n",
    "            section_list.append(paper1['section_feature'][section])\n",
    "        data['section_feat'] = section_list\n",
    "        \n",
    "        paper = paper1['paper_name']\n",
    "        for pap in sync[key] :\n",
    "            if(pap['paper_name']==paper) :\n",
    "                bool_list = pap['pos_feat']\n",
    "                feat_list = []\n",
    "                for val in bool_list :\n",
    "                    if(val):\n",
    "                        feat_list.append(1)\n",
    "                    else :\n",
    "                        feat_list.append(0)\n",
    "                data['sync_feat'] = feat_list\n",
    "                break\n",
    "        \n",
    "        for pap in popular[key] :\n",
    "            if(pap['paper_name']==paper) :\n",
    "                data['popularity'] = pap['popularity']\n",
    "                break\n",
    "                \n",
    "        for pap in dens[key] :\n",
    "            if(pap['paper_name']==paper) :\n",
    "                data['density'] = pap['density']\n",
    "                break\n",
    "            \n",
    "        for pap in text_feat[key] :\n",
    "            if(pap['paper_name']==paper) :\n",
    "                data['text_feat'] = []\n",
    "                if(pap['weight_comp']>0):\n",
    "                    data['text_feat'].append(1)\n",
    "                else :\n",
    "                    data['text_feat'].append(0)\n",
    "                \n",
    "                if(pap['weight_result']>0):\n",
    "                    data['text_feat'].append(1)\n",
    "                else :\n",
    "                    data['text_feat'].append(0)\n",
    "                    \n",
    "                    \n",
    "                if(pap['weight_subject']>0):\n",
    "                    data['text_feat'].append(1)\n",
    "                else :\n",
    "                    data['text_feat'].append(0)\n",
    "                    \n",
    "                data['text_feat'].append(pap['weight_comp'])\n",
    "                data['text_feat'].append(pap['weight_result'])\n",
    "                data['text_feat'].append(pap['weight_subject'])\n",
    "                break\n",
    "                \n",
    "        for pap in tags[key]:\n",
    "            if(pap['paper_name']==paper) :\n",
    "                if(pap['tag']==1):\n",
    "                    data['label'] = 'baseline'\n",
    "                else :\n",
    "                    data['label'] = 'non_baseline'\n",
    "                break\n",
    "                \n",
    "        dataset.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31943"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "for data in dataset :\n",
    "    print(len(data.keys()))\n",
    "    break\n",
    "    if(len(data.keys())!=6) :\n",
    "        print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = []\n",
    "output = []\n",
    "for data in dataset :\n",
    "    ar = []\n",
    "    ar.append(data['density'])\n",
    "    ar.append(data['popularity'])    \n",
    "    ar.extend(data['section_feat'])\n",
    "    ar.extend(data['text_feat'])\n",
    "    ar.extend(data['sync_feat'])\n",
    "    values.append(ar)\n",
    "    if(data['label']=='baseline'):\n",
    "        output.append(1)\n",
    "    else :\n",
    "        output.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "values, output = shuffle(values, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = np.array(values)\n",
    "output = np.array(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5906, 22)\n"
     ]
    }
   ],
   "source": [
    "print(values.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler((0,1))\n",
    "values = scaler.fit_transform(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(data, output):\n",
    "    n = len(data)\n",
    "    last = int(0.8*n)\n",
    "    train_data = data[:last]\n",
    "    train_output = output[:last]\n",
    "    test_data = data[last:]\n",
    "    test_output = output[last:]\n",
    "    return train_data, test_data, train_output, test_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data, train_output, test_output = split(values, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle(train_data, train_output) :\n",
    "    baselines = []\n",
    "    non_baselines = []\n",
    "    for i in range(len(train_output)) :\n",
    "        if(train_output[i]==1) :\n",
    "            baselines.append(train_data[i])\n",
    "        else :\n",
    "            non_baselines.append(train_data[i])\n",
    "    \n",
    "    n = len(baselines)\n",
    "    ar = np.random.choice(len(non_baselines), len(baselines))\n",
    "    nb_ar = []\n",
    "    for x in ar :\n",
    "        nb_ar.append(non_baselines[x])\n",
    "        \n",
    "    data = []\n",
    "    data.extend(nb_ar)\n",
    "    output = []\n",
    "    for i in range(len(data)):\n",
    "        output.append(0)\n",
    "    \n",
    "    data.extend(baselines)\n",
    "    for i in range(n) :\n",
    "        output.append(1)\n",
    "        \n",
    "    total_data = []\n",
    "    for i in range(len(data)):\n",
    "        ar = []\n",
    "        ar.append(data[i])\n",
    "        ar.append(output[i])\n",
    "        total_data.append(ar)\n",
    "        \n",
    "    total_data = np.array(total_data)\n",
    "    np.random.shuffle(total_data)\n",
    "    \n",
    "    data = []\n",
    "    output = []\n",
    "    for ar in total_data :\n",
    "        data.append(ar[0])\n",
    "        output.append(ar[1])\n",
    "        \n",
    "    data = np.array(data)\n",
    "    output = np.array(output)\n",
    "    \n",
    "    return data, output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data, train_output = shuffle(train_data, train_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.86      0.79       586\n",
      "           1       0.84      0.69      0.76       596\n",
      "\n",
      "    accuracy                           0.78      1182\n",
      "   macro avg       0.79      0.78      0.78      1182\n",
      "weighted avg       0.79      0.78      0.78      1182\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.87      0.81      2367\n",
      "           1       0.85      0.72      0.78      2357\n",
      "\n",
      "    accuracy                           0.80      4724\n",
      "   macro avg       0.80      0.80      0.79      4724\n",
      "weighted avg       0.80      0.80      0.79      4724\n",
      "\n",
      "{'C': 2}\n"
     ]
    }
   ],
   "source": [
    "params = {'C':[0.1, 0.5, 1, 2]}\n",
    "modelin = SVC(kernel='rbf', max_iter=1e4, gamma='scale')\n",
    "model = GridSearchCV(modelin, params, cv=2, n_jobs=5)\n",
    "# model = LogisticRegression(solver='lbfgs',max_iter=1e4, n_jobs=5, random_state=1, warm_start=False, C=1, fit_intercept=True)\n",
    "clf = model.fit(train_data, train_output)\n",
    "predict_test = clf.predict(test_data)\n",
    "print(classification_report(test_output, predict_test))\n",
    "predictions = clf.predict(train_data)\n",
    "print(classification_report(train_output, predictions))\n",
    "print(model.best_params_)\n",
    "# print(type(model.best_estimator_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3334\n",
      "1430\n",
      "4764\n"
     ]
    }
   ],
   "source": [
    "xtrain, xval, ytrain, yval = train_test_split(train_data, train_output, test_size=0.3, random_state=42)\n",
    "print(len(xtrain))\n",
    "print(len(xval))\n",
    "print(len(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3334, 22)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(xtrain.shape)\n",
    "print(type(ytrain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "(3477, 22)\n",
      "(3477,)\n",
      "(1287, 22)\n",
      "(1287,)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.86      0.91      5818\n",
      "           1       0.32      0.68      0.44       571\n",
      "\n",
      "    accuracy                           0.84      6389\n",
      "   macro avg       0.64      0.77      0.67      6389\n",
      "weighted avg       0.91      0.84      0.87      6389\n",
      "\n",
      "1\n",
      "(3620, 22)\n",
      "(3620,)\n",
      "(1144, 22)\n",
      "(1144,)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.86      0.91      5818\n",
      "           1       0.32      0.68      0.43       571\n",
      "\n",
      "    accuracy                           0.84      6389\n",
      "   macro avg       0.64      0.77      0.67      6389\n",
      "weighted avg       0.91      0.84      0.87      6389\n",
      "\n",
      "2\n",
      "(3763, 22)\n",
      "(3763,)\n",
      "(1001, 22)\n",
      "(1001,)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.86      0.91      5818\n",
      "           1       0.32      0.68      0.43       571\n",
      "\n",
      "    accuracy                           0.84      6389\n",
      "   macro avg       0.64      0.77      0.67      6389\n",
      "weighted avg       0.91      0.84      0.86      6389\n",
      "\n",
      "3\n",
      "(3906, 22)\n",
      "(3906,)\n",
      "(858, 22)\n",
      "(858,)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.86      0.91      5818\n",
      "           1       0.32      0.67      0.43       571\n",
      "\n",
      "    accuracy                           0.84      6389\n",
      "   macro avg       0.64      0.77      0.67      6389\n",
      "weighted avg       0.91      0.84      0.86      6389\n",
      "\n",
      "4\n",
      "(4049, 22)\n",
      "(4049,)\n",
      "(715, 22)\n",
      "(715,)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.85      0.91      5818\n",
      "           1       0.31      0.67      0.43       571\n",
      "\n",
      "    accuracy                           0.84      6389\n",
      "   macro avg       0.64      0.76      0.67      6389\n",
      "weighted avg       0.91      0.84      0.86      6389\n",
      "\n",
      "5\n",
      "(4049, 22)\n",
      "(4049,)\n",
      "(572, 22)\n",
      "(572,)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.86      0.91      5818\n",
      "           1       0.31      0.67      0.43       571\n",
      "\n",
      "    accuracy                           0.84      6389\n",
      "   macro avg       0.64      0.76      0.67      6389\n",
      "weighted avg       0.91      0.84      0.86      6389\n",
      "\n",
      "6\n",
      "(4049, 22)\n",
      "(4049,)\n",
      "(429, 22)\n",
      "(429,)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.86      0.91      5818\n",
      "           1       0.31      0.67      0.43       571\n",
      "\n",
      "    accuracy                           0.84      6389\n",
      "   macro avg       0.64      0.76      0.67      6389\n",
      "weighted avg       0.91      0.84      0.86      6389\n",
      "\n",
      "7\n",
      "(4049, 22)\n",
      "(4049,)\n",
      "(286, 22)\n",
      "(286,)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.86      0.91      5818\n",
      "           1       0.31      0.67      0.43       571\n",
      "\n",
      "    accuracy                           0.84      6389\n",
      "   macro avg       0.64      0.76      0.67      6389\n",
      "weighted avg       0.91      0.84      0.86      6389\n",
      "\n",
      "8\n",
      "(4049, 22)\n",
      "(4049,)\n",
      "(143, 22)\n",
      "(143,)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.86      0.91      5818\n",
      "           1       0.31      0.67      0.43       571\n",
      "\n",
      "    accuracy                           0.84      6389\n",
      "   macro avg       0.64      0.76      0.67      6389\n",
      "weighted avg       0.91      0.84      0.86      6389\n",
      "\n",
      "9\n",
      "(4049, 22)\n",
      "(4049,)\n",
      "(0, 22)\n",
      "(0,)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.86      0.91      5818\n",
      "           1       0.31      0.67      0.43       571\n",
      "\n",
      "    accuracy                           0.84      6389\n",
      "   macro avg       0.64      0.76      0.67      6389\n",
      "weighted avg       0.91      0.84      0.86      6389\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(10) :\n",
    "    model1 = GaussianNB()\n",
    "    model2 = SVC()\n",
    "    model3 = LogisticRegression()\n",
    "    print(i)\n",
    "    model1.fit(xtrain, ytrain)\n",
    "    model2.fit(xtrain, ytrain)\n",
    "    model3.fit(xtrain, ytrain)\n",
    "    pred1 = model1.predict(xval)\n",
    "    pred2 = model2.predict(xval)\n",
    "    pred3 = model3.predict(xval)\n",
    "    final_pred = []\n",
    "    for j in range(len(xval)) :\n",
    "        if(pred1[j]+pred2[j]+pred3[j]>=2) :\n",
    "            final_pred.append(1)\n",
    "        else :\n",
    "            final_pred.append(0)\n",
    "            \n",
    "    extra1 = xval[143*i:143*(i+1)]\n",
    "    extra2 = final_pred[143*i:143*(i+1)]\n",
    "    xtrain = list(xtrain)\n",
    "    ytrain = list(ytrain)\n",
    "    for val in extra1 :\n",
    "        xtrain.append(val)\n",
    "    for val in extra2 :\n",
    "        ytrain.append(val)\n",
    "    xtrain = np.array(xtrain)\n",
    "    ytrain = np.array(ytrain)\n",
    "    print(xtrain.shape)\n",
    "    print(ytrain.shape)\n",
    "    xval = xval[143:]\n",
    "    yval = yval[143:]\n",
    "    print(xval.shape)\n",
    "    print(yval.shape)\n",
    "    \n",
    "    \n",
    "    predt1 = model1.predict(test_data)\n",
    "    predt2 = model2.predict(test_data)\n",
    "    predt3 = model3.predict(test_data)\n",
    "    final_predt = []\n",
    "    for k in range(len(test_data)) :\n",
    "        if(predt1[k]+predt2[k]+predt3[k]>=2) :\n",
    "            final_predt.append(1)\n",
    "        else :\n",
    "            final_predt.append(0)\n",
    "    \n",
    "    print(classification_report(test_output, final_predt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
